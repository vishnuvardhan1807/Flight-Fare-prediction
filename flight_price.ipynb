{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Price Prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_excel(r\"Data\\Data_Train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>1/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>9/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19h</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → NAG → BLR</td>\n",
       "      <td>18:05</td>\n",
       "      <td>23:30</td>\n",
       "      <td>5h 25m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → NAG → DEL</td>\n",
       "      <td>16:50</td>\n",
       "      <td>21:35</td>\n",
       "      <td>4h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline Date_of_Journey    Source Destination                  Route  \\\n",
       "0       IndiGo      24/03/2019  Banglore   New Delhi              BLR → DEL   \n",
       "1    Air India       1/05/2019   Kolkata    Banglore  CCU → IXR → BBI → BLR   \n",
       "2  Jet Airways       9/06/2019     Delhi      Cochin  DEL → LKO → BOM → COK   \n",
       "3       IndiGo      12/05/2019   Kolkata    Banglore        CCU → NAG → BLR   \n",
       "4       IndiGo      01/03/2019  Banglore   New Delhi        BLR → NAG → DEL   \n",
       "\n",
       "  Dep_Time  Arrival_Time Duration Total_Stops Additional_Info  Price  \n",
       "0    22:20  01:10 22 Mar   2h 50m    non-stop         No info   3897  \n",
       "1    05:50         13:15   7h 25m     2 stops         No info   7662  \n",
       "2    09:25  04:25 10 Jun      19h     2 stops         No info  13882  \n",
       "3    18:05         23:30   5h 25m      1 stop         No info   6218  \n",
       "4    16:50         21:35   4h 45m      1 stop         No info  13302  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10683 entries, 0 to 10682\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Airline          10683 non-null  object\n",
      " 1   Date_of_Journey  10683 non-null  object\n",
      " 2   Source           10683 non-null  object\n",
      " 3   Destination      10683 non-null  object\n",
      " 4   Route            10682 non-null  object\n",
      " 5   Dep_Time         10683 non-null  object\n",
      " 6   Arrival_Time     10683 non-null  object\n",
      " 7   Duration         10683 non-null  object\n",
      " 8   Total_Stops      10682 non-null  object\n",
      " 9   Additional_Info  10683 non-null  object\n",
      " 10  Price            10683 non-null  int64 \n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 918.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2h 50m     550\n",
       "1h 30m     386\n",
       "2h 45m     337\n",
       "2h 55m     337\n",
       "2h 35m     329\n",
       "          ... \n",
       "35h 35m      1\n",
       "36h 25m      1\n",
       "42h 5m       1\n",
       "47h 40m      1\n",
       "31h 50m      1\n",
       "Name: Duration, Length: 368, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Duration\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airline            0\n",
       "Date_of_Journey    0\n",
       "Source             0\n",
       "Destination        0\n",
       "Route              0\n",
       "Dep_Time           0\n",
       "Arrival_Time       0\n",
       "Duration           0\n",
       "Total_Stops        0\n",
       "Additional_Info    0\n",
       "Price              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Journey_day\"] = pd.to_datetime(train_data.Date_of_Journey, format=\"%d/%m/%Y\").dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Journey_month\"] = pd.to_datetime(train_data[\"Date_of_Journey\"], format = \"%d/%m/%Y\").dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>1/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>9/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19h</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → NAG → BLR</td>\n",
       "      <td>18:05</td>\n",
       "      <td>23:30</td>\n",
       "      <td>5h 25m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → NAG → DEL</td>\n",
       "      <td>16:50</td>\n",
       "      <td>21:35</td>\n",
       "      <td>4h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline Date_of_Journey    Source Destination                  Route  \\\n",
       "0       IndiGo      24/03/2019  Banglore   New Delhi              BLR → DEL   \n",
       "1    Air India       1/05/2019   Kolkata    Banglore  CCU → IXR → BBI → BLR   \n",
       "2  Jet Airways       9/06/2019     Delhi      Cochin  DEL → LKO → BOM → COK   \n",
       "3       IndiGo      12/05/2019   Kolkata    Banglore        CCU → NAG → BLR   \n",
       "4       IndiGo      01/03/2019  Banglore   New Delhi        BLR → NAG → DEL   \n",
       "\n",
       "  Dep_Time  Arrival_Time Duration Total_Stops Additional_Info  Price  \\\n",
       "0    22:20  01:10 22 Mar   2h 50m    non-stop         No info   3897   \n",
       "1    05:50         13:15   7h 25m     2 stops         No info   7662   \n",
       "2    09:25  04:25 10 Jun      19h     2 stops         No info  13882   \n",
       "3    18:05         23:30   5h 25m      1 stop         No info   6218   \n",
       "4    16:50         21:35   4h 45m      1 stop         No info  13302   \n",
       "\n",
       "   Journey_day  Journey_month  \n",
       "0           24              3  \n",
       "1            1              5  \n",
       "2            9              6  \n",
       "3           12              5  \n",
       "4            1              3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have converted Date_of_Journey column into integers, Now we can drop as it is of no use.\n",
    "\n",
    "train_data.drop([\"Date_of_Journey\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Departure time is when a plane leaves the gate. \n",
    "# Similar to Date_of_Journey we can extract values from Dep_Time\n",
    "\n",
    "# Extracting Hours\n",
    "train_data[\"Dep_hour\"] = pd.to_datetime(train_data[\"Dep_Time\"]).dt.hour\n",
    "\n",
    "# Extracting Minutes\n",
    "train_data[\"Dep_min\"] = pd.to_datetime(train_data[\"Dep_Time\"]).dt.minute\n",
    "\n",
    "# Now we can drop Dep_Time as it is of no use\n",
    "train_data.drop([\"Dep_Time\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "      <th>Dep_hour</th>\n",
       "      <th>Dep_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19h</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → NAG → BLR</td>\n",
       "      <td>23:30</td>\n",
       "      <td>5h 25m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → NAG → DEL</td>\n",
       "      <td>21:35</td>\n",
       "      <td>4h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline    Source Destination                  Route  Arrival_Time  \\\n",
       "0       IndiGo  Banglore   New Delhi              BLR → DEL  01:10 22 Mar   \n",
       "1    Air India   Kolkata    Banglore  CCU → IXR → BBI → BLR         13:15   \n",
       "2  Jet Airways     Delhi      Cochin  DEL → LKO → BOM → COK  04:25 10 Jun   \n",
       "3       IndiGo   Kolkata    Banglore        CCU → NAG → BLR         23:30   \n",
       "4       IndiGo  Banglore   New Delhi        BLR → NAG → DEL         21:35   \n",
       "\n",
       "  Duration Total_Stops Additional_Info  Price  Journey_day  Journey_month  \\\n",
       "0   2h 50m    non-stop         No info   3897           24              3   \n",
       "1   7h 25m     2 stops         No info   7662            1              5   \n",
       "2      19h     2 stops         No info  13882            9              6   \n",
       "3   5h 25m      1 stop         No info   6218           12              5   \n",
       "4   4h 45m      1 stop         No info  13302            1              3   \n",
       "\n",
       "   Dep_hour  Dep_min  \n",
       "0        22       20  \n",
       "1         5       50  \n",
       "2         9       25  \n",
       "3        18        5  \n",
       "4        16       50  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrival time is when the plane pulls up to the gate.\n",
    "# Similar to Date_of_Journey we can extract values from Arrival_Time\n",
    "\n",
    "# Extracting Hours\n",
    "train_data[\"Arrival_hour\"] = pd.to_datetime(train_data.Arrival_Time).dt.hour\n",
    "\n",
    "# Extracting Minutes\n",
    "train_data[\"Arrival_min\"] = pd.to_datetime(train_data.Arrival_Time).dt.minute\n",
    "\n",
    "# Now we can drop Arrival_Time as it is of no use\n",
    "train_data.drop([\"Arrival_Time\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "      <th>Dep_hour</th>\n",
       "      <th>Dep_min</th>\n",
       "      <th>Arrival_hour</th>\n",
       "      <th>Arrival_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>19h</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → NAG → BLR</td>\n",
       "      <td>5h 25m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → NAG → DEL</td>\n",
       "      <td>4h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline    Source Destination                  Route Duration  \\\n",
       "0       IndiGo  Banglore   New Delhi              BLR → DEL   2h 50m   \n",
       "1    Air India   Kolkata    Banglore  CCU → IXR → BBI → BLR   7h 25m   \n",
       "2  Jet Airways     Delhi      Cochin  DEL → LKO → BOM → COK      19h   \n",
       "3       IndiGo   Kolkata    Banglore        CCU → NAG → BLR   5h 25m   \n",
       "4       IndiGo  Banglore   New Delhi        BLR → NAG → DEL   4h 45m   \n",
       "\n",
       "  Total_Stops Additional_Info  Price  Journey_day  Journey_month  Dep_hour  \\\n",
       "0    non-stop         No info   3897           24              3        22   \n",
       "1     2 stops         No info   7662            1              5         5   \n",
       "2     2 stops         No info  13882            9              6         9   \n",
       "3      1 stop         No info   6218           12              5        18   \n",
       "4      1 stop         No info  13302            1              3        16   \n",
       "\n",
       "   Dep_min  Arrival_hour  Arrival_min  \n",
       "0       20             1           10  \n",
       "1       50            13           15  \n",
       "2       25             4           25  \n",
       "3        5            23           30  \n",
       "4       50            21           35  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time taken by plane to reach destination is called Duration\n",
    "# It is the differnce betwwen Departure Time and Arrival time\n",
    "\n",
    "\n",
    "# Assigning and converting Duration column into list\n",
    "duration = list(train_data[\"Duration\"])\n",
    "\n",
    "for i in range(len(duration)):\n",
    "    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n",
    "        if \"h\" in duration[i]:\n",
    "            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n",
    "        else:\n",
    "            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n",
    "\n",
    "duration_hours = []\n",
    "duration_mins = []\n",
    "for i in range(len(duration)):\n",
    "    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n",
    "    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding duration_hours and duration_mins list to train_data dataframe\n",
    "\n",
    "train_data[\"Duration_hours\"] = duration_hours\n",
    "train_data[\"Duration_mins\"] = duration_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop([\"Duration\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "      <th>Dep_hour</th>\n",
       "      <th>Dep_min</th>\n",
       "      <th>Arrival_hour</th>\n",
       "      <th>Arrival_min</th>\n",
       "      <th>Duration_hours</th>\n",
       "      <th>Duration_mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → NAG → BLR</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → NAG → DEL</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline    Source Destination                  Route Total_Stops  \\\n",
       "0       IndiGo  Banglore   New Delhi              BLR → DEL    non-stop   \n",
       "1    Air India   Kolkata    Banglore  CCU → IXR → BBI → BLR     2 stops   \n",
       "2  Jet Airways     Delhi      Cochin  DEL → LKO → BOM → COK     2 stops   \n",
       "3       IndiGo   Kolkata    Banglore        CCU → NAG → BLR      1 stop   \n",
       "4       IndiGo  Banglore   New Delhi        BLR → NAG → DEL      1 stop   \n",
       "\n",
       "  Additional_Info  Price  Journey_day  Journey_month  Dep_hour  Dep_min  \\\n",
       "0         No info   3897           24              3        22       20   \n",
       "1         No info   7662            1              5         5       50   \n",
       "2         No info  13882            9              6         9       25   \n",
       "3         No info   6218           12              5        18        5   \n",
       "4         No info  13302            1              3        16       50   \n",
       "\n",
       "   Arrival_hour  Arrival_min  Duration_hours  Duration_mins  \n",
       "0             1           10               2             50  \n",
       "1            13           15               7             25  \n",
       "2             4           25              19              0  \n",
       "3            23           30               5             25  \n",
       "4            21           35               4             45  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Categorical Data\n",
    "\n",
    "One can find many ways to handle categorical data. Some of them categorical data are,\n",
    "1. <span style=\"color: blue;\">**Nominal data**</span> --> data are not in any order --> <span style=\"color: green;\">**OneHotEncoder**</span> is used in this case\n",
    "2. <span style=\"color: blue;\">**Ordinal data**</span> --> data are in order --> <span style=\"color: green;\">**LabelEncoder**</span> is used in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jet Airways                          3849\n",
       "IndiGo                               2053\n",
       "Air India                            1751\n",
       "Multiple carriers                    1196\n",
       "SpiceJet                              818\n",
       "Vistara                               479\n",
       "Air Asia                              319\n",
       "GoAir                                 194\n",
       "Multiple carriers Premium economy      13\n",
       "Jet Airways Business                    6\n",
       "Vistara Premium economy                 3\n",
       "Trujet                                  1\n",
       "Name: Airline, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Airline\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# From graph we can see that Jet Airways Business have the highest Price.\n",
    "# Apart from the first Airline almost all are having similar median\n",
    "\n",
    "# Airline vs Price\n",
    "sns.catplot(y = \"Price\", x = \"Airline\", data = train_data.sort_values(\"Price\", ascending = False), kind=\"boxen\", height = 6, aspect = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline_Air India</th>\n",
       "      <th>Airline_GoAir</th>\n",
       "      <th>Airline_IndiGo</th>\n",
       "      <th>Airline_Jet Airways</th>\n",
       "      <th>Airline_Jet Airways Business</th>\n",
       "      <th>Airline_Multiple carriers</th>\n",
       "      <th>Airline_Multiple carriers Premium economy</th>\n",
       "      <th>Airline_SpiceJet</th>\n",
       "      <th>Airline_Trujet</th>\n",
       "      <th>Airline_Vistara</th>\n",
       "      <th>Airline_Vistara Premium economy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Airline_Air India  Airline_GoAir  Airline_IndiGo  Airline_Jet Airways  \\\n",
       "0                  0              0               1                    0   \n",
       "1                  1              0               0                    0   \n",
       "2                  0              0               0                    1   \n",
       "3                  0              0               1                    0   \n",
       "4                  0              0               1                    0   \n",
       "\n",
       "   Airline_Jet Airways Business  Airline_Multiple carriers  \\\n",
       "0                             0                          0   \n",
       "1                             0                          0   \n",
       "2                             0                          0   \n",
       "3                             0                          0   \n",
       "4                             0                          0   \n",
       "\n",
       "   Airline_Multiple carriers Premium economy  Airline_SpiceJet  \\\n",
       "0                                          0                 0   \n",
       "1                                          0                 0   \n",
       "2                                          0                 0   \n",
       "3                                          0                 0   \n",
       "4                                          0                 0   \n",
       "\n",
       "   Airline_Trujet  Airline_Vistara  Airline_Vistara Premium economy  \n",
       "0               0                0                                0  \n",
       "1               0                0                                0  \n",
       "2               0                0                                0  \n",
       "3               0                0                                0  \n",
       "4               0                0                                0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As Airline is Nominal Categorical data we will perform OneHotEncoding\n",
    "\n",
    "Airline = train_data[[\"Airline\"]]\n",
    "\n",
    "Airline = pd.get_dummies(Airline, drop_first= True)\n",
    "\n",
    "Airline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delhi       4536\n",
       "Kolkata     2871\n",
       "Banglore    2197\n",
       "Mumbai       697\n",
       "Chennai      381\n",
       "Name: Source, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Source\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Source vs Price\n",
    "\n",
    "sns.catplot(y = \"Price\", x = \"Source\", data = train_data.sort_values(\"Price\", ascending = False), kind=\"boxen\", height = 4, aspect = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source_Chennai</th>\n",
       "      <th>Source_Delhi</th>\n",
       "      <th>Source_Kolkata</th>\n",
       "      <th>Source_Mumbai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source_Chennai  Source_Delhi  Source_Kolkata  Source_Mumbai\n",
       "0               0             0               0              0\n",
       "1               0             0               1              0\n",
       "2               0             1               0              0\n",
       "3               0             0               1              0\n",
       "4               0             0               0              0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As Source is Nominal Categorical data we will perform OneHotEncoding\n",
    "\n",
    "Source = train_data[[\"Source\"]]\n",
    "\n",
    "Source = pd.get_dummies(Source, drop_first= True)\n",
    "\n",
    "Source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cochin       4536\n",
       "Banglore     2871\n",
       "Delhi        1265\n",
       "New Delhi     932\n",
       "Hyderabad     697\n",
       "Kolkata       381\n",
       "Name: Destination, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Destination\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination_Cochin</th>\n",
       "      <th>Destination_Delhi</th>\n",
       "      <th>Destination_Hyderabad</th>\n",
       "      <th>Destination_Kolkata</th>\n",
       "      <th>Destination_New Delhi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Destination_Cochin  Destination_Delhi  Destination_Hyderabad  \\\n",
       "0                   0                  0                      0   \n",
       "1                   0                  0                      0   \n",
       "2                   1                  0                      0   \n",
       "3                   0                  0                      0   \n",
       "4                   0                  0                      0   \n",
       "\n",
       "   Destination_Kolkata  Destination_New Delhi  \n",
       "0                    0                      1  \n",
       "1                    0                      0  \n",
       "2                    0                      0  \n",
       "3                    0                      0  \n",
       "4                    0                      1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As Destination is Nominal Categorical data we will perform OneHotEncoding\n",
    "\n",
    "Destination = train_data[[\"Destination\"]]\n",
    "\n",
    "Destination = pd.get_dummies(Destination, drop_first = True)\n",
    "\n",
    "Destination.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    BLR → DEL\n",
       "1        CCU → IXR → BBI → BLR\n",
       "2        DEL → LKO → BOM → COK\n",
       "3              CCU → NAG → BLR\n",
       "4              BLR → NAG → DEL\n",
       "                 ...          \n",
       "10678                CCU → BLR\n",
       "10679                CCU → BLR\n",
       "10680                BLR → DEL\n",
       "10681                BLR → DEL\n",
       "10682    DEL → GOI → BOM → COK\n",
       "Name: Route, Length: 10682, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Route\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional_Info contains almost 80% no_info\n",
    "# Route and Total_Stops are related to each other\n",
    "\n",
    "train_data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 stop      5625\n",
       "non-stop    3491\n",
       "2 stops     1520\n",
       "3 stops       45\n",
       "4 stops        1\n",
       "Name: Total_Stops, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Total_Stops\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this is case of Ordinal Categorical type we perform LabelEncoder\n",
    "# Here Values are assigned with corresponding keys\n",
    "\n",
    "train_data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Price</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "      <th>Dep_hour</th>\n",
       "      <th>Dep_min</th>\n",
       "      <th>Arrival_hour</th>\n",
       "      <th>Arrival_min</th>\n",
       "      <th>Duration_hours</th>\n",
       "      <th>Duration_mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>0</td>\n",
       "      <td>3897</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>2</td>\n",
       "      <td>7662</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>2</td>\n",
       "      <td>13882</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>1</td>\n",
       "      <td>6218</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>1</td>\n",
       "      <td>13302</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline    Source Destination  Total_Stops  Price  Journey_day  \\\n",
       "0       IndiGo  Banglore   New Delhi            0   3897           24   \n",
       "1    Air India   Kolkata    Banglore            2   7662            1   \n",
       "2  Jet Airways     Delhi      Cochin            2  13882            9   \n",
       "3       IndiGo   Kolkata    Banglore            1   6218           12   \n",
       "4       IndiGo  Banglore   New Delhi            1  13302            1   \n",
       "\n",
       "   Journey_month  Dep_hour  Dep_min  Arrival_hour  Arrival_min  \\\n",
       "0              3        22       20             1           10   \n",
       "1              5         5       50            13           15   \n",
       "2              6         9       25             4           25   \n",
       "3              5        18        5            23           30   \n",
       "4              3        16       50            21           35   \n",
       "\n",
       "   Duration_hours  Duration_mins  \n",
       "0               2             50  \n",
       "1               7             25  \n",
       "2              19              0  \n",
       "3               5             25  \n",
       "4               4             45  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframe --> train_data + Airline + Source + Destination\n",
    "\n",
    "data_train = pd.concat([train_data, Airline, Source, Destination], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Price</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "      <th>Dep_hour</th>\n",
       "      <th>Dep_min</th>\n",
       "      <th>Arrival_hour</th>\n",
       "      <th>Arrival_min</th>\n",
       "      <th>Duration_hours</th>\n",
       "      <th>Duration_mins</th>\n",
       "      <th>Airline_Air India</th>\n",
       "      <th>Airline_GoAir</th>\n",
       "      <th>Airline_IndiGo</th>\n",
       "      <th>Airline_Jet Airways</th>\n",
       "      <th>Airline_Jet Airways Business</th>\n",
       "      <th>Airline_Multiple carriers</th>\n",
       "      <th>Airline_Multiple carriers Premium economy</th>\n",
       "      <th>Airline_SpiceJet</th>\n",
       "      <th>Airline_Trujet</th>\n",
       "      <th>Airline_Vistara</th>\n",
       "      <th>Airline_Vistara Premium economy</th>\n",
       "      <th>Source_Chennai</th>\n",
       "      <th>Source_Delhi</th>\n",
       "      <th>Source_Kolkata</th>\n",
       "      <th>Source_Mumbai</th>\n",
       "      <th>Destination_Cochin</th>\n",
       "      <th>Destination_Delhi</th>\n",
       "      <th>Destination_Hyderabad</th>\n",
       "      <th>Destination_Kolkata</th>\n",
       "      <th>Destination_New Delhi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>0</td>\n",
       "      <td>3897</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>2</td>\n",
       "      <td>7662</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>2</td>\n",
       "      <td>13882</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>1</td>\n",
       "      <td>6218</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>1</td>\n",
       "      <td>13302</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline    Source Destination  Total_Stops  Price  Journey_day  \\\n",
       "0       IndiGo  Banglore   New Delhi            0   3897           24   \n",
       "1    Air India   Kolkata    Banglore            2   7662            1   \n",
       "2  Jet Airways     Delhi      Cochin            2  13882            9   \n",
       "3       IndiGo   Kolkata    Banglore            1   6218           12   \n",
       "4       IndiGo  Banglore   New Delhi            1  13302            1   \n",
       "\n",
       "   Journey_month  Dep_hour  Dep_min  Arrival_hour  Arrival_min  \\\n",
       "0              3        22       20             1           10   \n",
       "1              5         5       50            13           15   \n",
       "2              6         9       25             4           25   \n",
       "3              5        18        5            23           30   \n",
       "4              3        16       50            21           35   \n",
       "\n",
       "   Duration_hours  Duration_mins  Airline_Air India  Airline_GoAir  \\\n",
       "0               2             50                  0              0   \n",
       "1               7             25                  1              0   \n",
       "2              19              0                  0              0   \n",
       "3               5             25                  0              0   \n",
       "4               4             45                  0              0   \n",
       "\n",
       "   Airline_IndiGo  Airline_Jet Airways  Airline_Jet Airways Business  \\\n",
       "0               1                    0                             0   \n",
       "1               0                    0                             0   \n",
       "2               0                    1                             0   \n",
       "3               1                    0                             0   \n",
       "4               1                    0                             0   \n",
       "\n",
       "   Airline_Multiple carriers  Airline_Multiple carriers Premium economy  \\\n",
       "0                          0                                          0   \n",
       "1                          0                                          0   \n",
       "2                          0                                          0   \n",
       "3                          0                                          0   \n",
       "4                          0                                          0   \n",
       "\n",
       "   Airline_SpiceJet  Airline_Trujet  Airline_Vistara  \\\n",
       "0                 0               0                0   \n",
       "1                 0               0                0   \n",
       "2                 0               0                0   \n",
       "3                 0               0                0   \n",
       "4                 0               0                0   \n",
       "\n",
       "   Airline_Vistara Premium economy  Source_Chennai  Source_Delhi  \\\n",
       "0                                0               0             0   \n",
       "1                                0               0             0   \n",
       "2                                0               0             1   \n",
       "3                                0               0             0   \n",
       "4                                0               0             0   \n",
       "\n",
       "   Source_Kolkata  Source_Mumbai  Destination_Cochin  Destination_Delhi  \\\n",
       "0               0              0                   0                  0   \n",
       "1               1              0                   0                  0   \n",
       "2               0              0                   1                  0   \n",
       "3               1              0                   0                  0   \n",
       "4               0              0                   0                  0   \n",
       "\n",
       "   Destination_Hyderabad  Destination_Kolkata  Destination_New Delhi  \n",
       "0                      0                    0                      1  \n",
       "1                      0                    0                      0  \n",
       "2                      0                    0                      0  \n",
       "3                      0                    0                      0  \n",
       "4                      0                    0                      1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop([\"Airline\", \"Source\", \"Destination\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Price</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "      <th>Dep_hour</th>\n",
       "      <th>Dep_min</th>\n",
       "      <th>Arrival_hour</th>\n",
       "      <th>Arrival_min</th>\n",
       "      <th>Duration_hours</th>\n",
       "      <th>Duration_mins</th>\n",
       "      <th>Airline_Air India</th>\n",
       "      <th>Airline_GoAir</th>\n",
       "      <th>Airline_IndiGo</th>\n",
       "      <th>Airline_Jet Airways</th>\n",
       "      <th>Airline_Jet Airways Business</th>\n",
       "      <th>Airline_Multiple carriers</th>\n",
       "      <th>Airline_Multiple carriers Premium economy</th>\n",
       "      <th>Airline_SpiceJet</th>\n",
       "      <th>Airline_Trujet</th>\n",
       "      <th>Airline_Vistara</th>\n",
       "      <th>Airline_Vistara Premium economy</th>\n",
       "      <th>Source_Chennai</th>\n",
       "      <th>Source_Delhi</th>\n",
       "      <th>Source_Kolkata</th>\n",
       "      <th>Source_Mumbai</th>\n",
       "      <th>Destination_Cochin</th>\n",
       "      <th>Destination_Delhi</th>\n",
       "      <th>Destination_Hyderabad</th>\n",
       "      <th>Destination_Kolkata</th>\n",
       "      <th>Destination_New Delhi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3897</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7662</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13882</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6218</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13302</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_Stops  Price  Journey_day  Journey_month  Dep_hour  Dep_min  \\\n",
       "0            0   3897           24              3        22       20   \n",
       "1            2   7662            1              5         5       50   \n",
       "2            2  13882            9              6         9       25   \n",
       "3            1   6218           12              5        18        5   \n",
       "4            1  13302            1              3        16       50   \n",
       "\n",
       "   Arrival_hour  Arrival_min  Duration_hours  Duration_mins  \\\n",
       "0             1           10               2             50   \n",
       "1            13           15               7             25   \n",
       "2             4           25              19              0   \n",
       "3            23           30               5             25   \n",
       "4            21           35               4             45   \n",
       "\n",
       "   Airline_Air India  Airline_GoAir  Airline_IndiGo  Airline_Jet Airways  \\\n",
       "0                  0              0               1                    0   \n",
       "1                  1              0               0                    0   \n",
       "2                  0              0               0                    1   \n",
       "3                  0              0               1                    0   \n",
       "4                  0              0               1                    0   \n",
       "\n",
       "   Airline_Jet Airways Business  Airline_Multiple carriers  \\\n",
       "0                             0                          0   \n",
       "1                             0                          0   \n",
       "2                             0                          0   \n",
       "3                             0                          0   \n",
       "4                             0                          0   \n",
       "\n",
       "   Airline_Multiple carriers Premium economy  Airline_SpiceJet  \\\n",
       "0                                          0                 0   \n",
       "1                                          0                 0   \n",
       "2                                          0                 0   \n",
       "3                                          0                 0   \n",
       "4                                          0                 0   \n",
       "\n",
       "   Airline_Trujet  Airline_Vistara  Airline_Vistara Premium economy  \\\n",
       "0               0                0                                0   \n",
       "1               0                0                                0   \n",
       "2               0                0                                0   \n",
       "3               0                0                                0   \n",
       "4               0                0                                0   \n",
       "\n",
       "   Source_Chennai  Source_Delhi  Source_Kolkata  Source_Mumbai  \\\n",
       "0               0             0               0              0   \n",
       "1               0             0               1              0   \n",
       "2               0             1               0              0   \n",
       "3               0             0               1              0   \n",
       "4               0             0               0              0   \n",
       "\n",
       "   Destination_Cochin  Destination_Delhi  Destination_Hyderabad  \\\n",
       "0                   0                  0                      0   \n",
       "1                   0                  0                      0   \n",
       "2                   1                  0                      0   \n",
       "3                   0                  0                      0   \n",
       "4                   0                  0                      0   \n",
       "\n",
       "   Destination_Kolkata  Destination_New Delhi  \n",
       "0                    0                      1  \n",
       "1                    0                      0  \n",
       "2                    0                      0  \n",
       "3                    0                      0  \n",
       "4                    0                      1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10682, 30)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_excel(r\"Data\\Test_set.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>6/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → BOM → COK</td>\n",
       "      <td>17:30</td>\n",
       "      <td>04:25 07 Jun</td>\n",
       "      <td>10h 55m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → MAA → BLR</td>\n",
       "      <td>06:20</td>\n",
       "      <td>10:20</td>\n",
       "      <td>4h</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>21/05/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → BOM → COK</td>\n",
       "      <td>19:15</td>\n",
       "      <td>19:00 22 May</td>\n",
       "      <td>23h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multiple carriers</td>\n",
       "      <td>21/05/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → BOM → COK</td>\n",
       "      <td>08:00</td>\n",
       "      <td>21:00</td>\n",
       "      <td>13h</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Asia</td>\n",
       "      <td>24/06/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>23:55</td>\n",
       "      <td>02:45 25 Jun</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Airline Date_of_Journey    Source Destination            Route  \\\n",
       "0        Jet Airways       6/06/2019     Delhi      Cochin  DEL → BOM → COK   \n",
       "1             IndiGo      12/05/2019   Kolkata    Banglore  CCU → MAA → BLR   \n",
       "2        Jet Airways      21/05/2019     Delhi      Cochin  DEL → BOM → COK   \n",
       "3  Multiple carriers      21/05/2019     Delhi      Cochin  DEL → BOM → COK   \n",
       "4           Air Asia      24/06/2019  Banglore       Delhi        BLR → DEL   \n",
       "\n",
       "  Dep_Time  Arrival_Time Duration Total_Stops              Additional_Info  \n",
       "0    17:30  04:25 07 Jun  10h 55m      1 stop                      No info  \n",
       "1    06:20         10:20       4h      1 stop                      No info  \n",
       "2    19:15  19:00 22 May  23h 45m      1 stop  In-flight meal not included  \n",
       "3    08:00         21:00      13h      1 stop                      No info  \n",
       "4    23:55  02:45 25 Jun   2h 50m    non-stop                      No info  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data Info\n",
      "---------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2671 entries, 0 to 2670\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Airline          2671 non-null   object\n",
      " 1   Date_of_Journey  2671 non-null   object\n",
      " 2   Source           2671 non-null   object\n",
      " 3   Destination      2671 non-null   object\n",
      " 4   Route            2671 non-null   object\n",
      " 5   Dep_Time         2671 non-null   object\n",
      " 6   Arrival_Time     2671 non-null   object\n",
      " 7   Duration         2671 non-null   object\n",
      " 8   Total_Stops      2671 non-null   object\n",
      " 9   Additional_Info  2671 non-null   object\n",
      "dtypes: object(10)\n",
      "memory usage: 208.8+ KB\n",
      "None\n",
      "\n",
      "\n",
      "Null values :\n",
      "---------------------------------------------------------------------------\n",
      "Airline            0\n",
      "Date_of_Journey    0\n",
      "Source             0\n",
      "Destination        0\n",
      "Route              0\n",
      "Dep_Time           0\n",
      "Arrival_Time       0\n",
      "Duration           0\n",
      "Total_Stops        0\n",
      "Additional_Info    0\n",
      "dtype: int64\n",
      "Airline\n",
      "---------------------------------------------------------------------------\n",
      "Jet Airways                          897\n",
      "IndiGo                               511\n",
      "Air India                            440\n",
      "Multiple carriers                    347\n",
      "SpiceJet                             208\n",
      "Vistara                              129\n",
      "Air Asia                              86\n",
      "GoAir                                 46\n",
      "Multiple carriers Premium economy      3\n",
      "Vistara Premium economy                2\n",
      "Jet Airways Business                   2\n",
      "Name: Airline, dtype: int64\n",
      "\n",
      "Source\n",
      "---------------------------------------------------------------------------\n",
      "Delhi       1145\n",
      "Kolkata      710\n",
      "Banglore     555\n",
      "Mumbai       186\n",
      "Chennai       75\n",
      "Name: Source, dtype: int64\n",
      "\n",
      "Destination\n",
      "---------------------------------------------------------------------------\n",
      "Cochin       1145\n",
      "Banglore      710\n",
      "Delhi         317\n",
      "New Delhi     238\n",
      "Hyderabad     186\n",
      "Kolkata        75\n",
      "Name: Destination, dtype: int64\n",
      "\n",
      "\n",
      "Shape of test data :  (2671, 28)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "\n",
    "print(\"Test data Info\")\n",
    "print(\"-\"*75)\n",
    "print(test_data.info())\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Null values :\")\n",
    "print(\"-\"*75)\n",
    "test_data.dropna(inplace = True)\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "# EDA\n",
    "\n",
    "# Date_of_Journey\n",
    "test_data[\"Journey_day\"] = pd.to_datetime(test_data.Date_of_Journey, format=\"%d/%m/%Y\").dt.day\n",
    "test_data[\"Journey_month\"] = pd.to_datetime(test_data[\"Date_of_Journey\"], format = \"%d/%m/%Y\").dt.month\n",
    "test_data.drop([\"Date_of_Journey\"], axis = 1, inplace = True)\n",
    "\n",
    "# Dep_Time\n",
    "test_data[\"Dep_hour\"] = pd.to_datetime(test_data[\"Dep_Time\"]).dt.hour\n",
    "test_data[\"Dep_min\"] = pd.to_datetime(test_data[\"Dep_Time\"]).dt.minute\n",
    "test_data.drop([\"Dep_Time\"], axis = 1, inplace = True)\n",
    "\n",
    "# Arrival_Time\n",
    "test_data[\"Arrival_hour\"] = pd.to_datetime(test_data.Arrival_Time).dt.hour\n",
    "test_data[\"Arrival_min\"] = pd.to_datetime(test_data.Arrival_Time).dt.minute\n",
    "test_data.drop([\"Arrival_Time\"], axis = 1, inplace = True)\n",
    "\n",
    "# Duration\n",
    "duration = list(test_data[\"Duration\"])\n",
    "\n",
    "for i in range(len(duration)):\n",
    "    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n",
    "        if \"h\" in duration[i]:\n",
    "            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n",
    "        else:\n",
    "            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n",
    "\n",
    "duration_hours = []\n",
    "duration_mins = []\n",
    "for i in range(len(duration)):\n",
    "    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n",
    "    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration\n",
    "\n",
    "# Adding Duration column to test set\n",
    "test_data[\"Duration_hours\"] = duration_hours\n",
    "test_data[\"Duration_mins\"] = duration_mins\n",
    "test_data.drop([\"Duration\"], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# Categorical data\n",
    "\n",
    "print(\"Airline\")\n",
    "print(\"-\"*75)\n",
    "print(test_data[\"Airline\"].value_counts())\n",
    "Airline = pd.get_dummies(test_data[\"Airline\"], drop_first= True)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Source\")\n",
    "print(\"-\"*75)\n",
    "print(test_data[\"Source\"].value_counts())\n",
    "Source = pd.get_dummies(test_data[\"Source\"], drop_first= True)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Destination\")\n",
    "print(\"-\"*75)\n",
    "print(test_data[\"Destination\"].value_counts())\n",
    "Destination = pd.get_dummies(test_data[\"Destination\"], drop_first = True)\n",
    "\n",
    "# Additional_Info contains almost 80% no_info\n",
    "# Route and Total_Stops are related to each other\n",
    "test_data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)\n",
    "\n",
    "# Replacing Total_Stops\n",
    "test_data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)\n",
    "\n",
    "# Concatenate dataframe --> test_data + Airline + Source + Destination\n",
    "data_test = pd.concat([test_data, Airline, Source, Destination], axis = 1)\n",
    "\n",
    "data_test.drop([\"Airline\", \"Source\", \"Destination\"], axis = 1, inplace = True)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Shape of test data : \", data_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "      <th>Dep_hour</th>\n",
       "      <th>Dep_min</th>\n",
       "      <th>Arrival_hour</th>\n",
       "      <th>Arrival_min</th>\n",
       "      <th>Duration_hours</th>\n",
       "      <th>Duration_mins</th>\n",
       "      <th>Air India</th>\n",
       "      <th>GoAir</th>\n",
       "      <th>IndiGo</th>\n",
       "      <th>Jet Airways</th>\n",
       "      <th>Jet Airways Business</th>\n",
       "      <th>Multiple carriers</th>\n",
       "      <th>Multiple carriers Premium economy</th>\n",
       "      <th>SpiceJet</th>\n",
       "      <th>Vistara</th>\n",
       "      <th>Vistara Premium economy</th>\n",
       "      <th>Chennai</th>\n",
       "      <th>Delhi</th>\n",
       "      <th>Kolkata</th>\n",
       "      <th>Mumbai</th>\n",
       "      <th>Cochin</th>\n",
       "      <th>Delhi</th>\n",
       "      <th>Hyderabad</th>\n",
       "      <th>Kolkata</th>\n",
       "      <th>New Delhi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_Stops  Journey_day  Journey_month  Dep_hour  Dep_min  Arrival_hour  \\\n",
       "0            1            6              6        17       30             4   \n",
       "1            1           12              5         6       20            10   \n",
       "2            1           21              5        19       15            19   \n",
       "3            1           21              5         8        0            21   \n",
       "4            0           24              6        23       55             2   \n",
       "\n",
       "   Arrival_min  Duration_hours  Duration_mins  Air India  GoAir  IndiGo  \\\n",
       "0           25              10             55          0      0       0   \n",
       "1           20               4              0          0      0       1   \n",
       "2            0              23             45          0      0       0   \n",
       "3            0              13              0          0      0       0   \n",
       "4           45               2             50          0      0       0   \n",
       "\n",
       "   Jet Airways  Jet Airways Business  Multiple carriers  \\\n",
       "0            1                     0                  0   \n",
       "1            0                     0                  0   \n",
       "2            1                     0                  0   \n",
       "3            0                     0                  1   \n",
       "4            0                     0                  0   \n",
       "\n",
       "   Multiple carriers Premium economy  SpiceJet  Vistara  \\\n",
       "0                                  0         0        0   \n",
       "1                                  0         0        0   \n",
       "2                                  0         0        0   \n",
       "3                                  0         0        0   \n",
       "4                                  0         0        0   \n",
       "\n",
       "   Vistara Premium economy  Chennai  Delhi  Kolkata  Mumbai  Cochin  Delhi  \\\n",
       "0                        0        0      1        0       0       1      0   \n",
       "1                        0        0      0        1       0       0      0   \n",
       "2                        0        0      1        0       0       1      0   \n",
       "3                        0        0      1        0       0       1      0   \n",
       "4                        0        0      0        0       0       0      1   \n",
       "\n",
       "   Hyderabad  Kolkata  New Delhi  \n",
       "0          0        0          0  \n",
       "1          0        0          0  \n",
       "2          0        0          0  \n",
       "3          0        0          0  \n",
       "4          0        0          0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Finding out the best feature which will contribute and have good relation with target variable.\n",
    "Following are some of the feature selection methods,\n",
    "\n",
    "\n",
    "1. <span style=\"color: purple;\">**heatmap**</span>\n",
    "2. <span style=\"color: purple;\">**feature_importance_**</span>\n",
    "3. <span style=\"color: purple;\">**SelectKBest**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10682, 30)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Total_Stops', 'Price', 'Journey_day', 'Journey_month', 'Dep_hour',\n",
       "       'Dep_min', 'Arrival_hour', 'Arrival_min', 'Duration_hours',\n",
       "       'Duration_mins', 'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n",
       "       'Airline_Jet Airways', 'Airline_Jet Airways Business',\n",
       "       'Airline_Multiple carriers',\n",
       "       'Airline_Multiple carriers Premium economy', 'Airline_SpiceJet',\n",
       "       'Airline_Trujet', 'Airline_Vistara', 'Airline_Vistara Premium economy',\n",
       "       'Source_Chennai', 'Source_Delhi', 'Source_Kolkata', 'Source_Mumbai',\n",
       "       'Destination_Cochin', 'Destination_Delhi', 'Destination_Hyderabad',\n",
       "       'Destination_Kolkata', 'Destination_New Delhi'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "      <th>Dep_hour</th>\n",
       "      <th>Dep_min</th>\n",
       "      <th>Arrival_hour</th>\n",
       "      <th>Arrival_min</th>\n",
       "      <th>Duration_hours</th>\n",
       "      <th>Duration_mins</th>\n",
       "      <th>Airline_Air India</th>\n",
       "      <th>Airline_GoAir</th>\n",
       "      <th>Airline_IndiGo</th>\n",
       "      <th>Airline_Jet Airways</th>\n",
       "      <th>Airline_Jet Airways Business</th>\n",
       "      <th>Airline_Multiple carriers</th>\n",
       "      <th>Airline_Multiple carriers Premium economy</th>\n",
       "      <th>Airline_SpiceJet</th>\n",
       "      <th>Airline_Trujet</th>\n",
       "      <th>Airline_Vistara</th>\n",
       "      <th>Airline_Vistara Premium economy</th>\n",
       "      <th>Source_Chennai</th>\n",
       "      <th>Source_Delhi</th>\n",
       "      <th>Source_Kolkata</th>\n",
       "      <th>Source_Mumbai</th>\n",
       "      <th>Destination_Cochin</th>\n",
       "      <th>Destination_Delhi</th>\n",
       "      <th>Destination_Hyderabad</th>\n",
       "      <th>Destination_Kolkata</th>\n",
       "      <th>Destination_New Delhi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_Stops  Journey_day  Journey_month  Dep_hour  Dep_min  Arrival_hour  \\\n",
       "0            0           24              3        22       20             1   \n",
       "1            2            1              5         5       50            13   \n",
       "2            2            9              6         9       25             4   \n",
       "3            1           12              5        18        5            23   \n",
       "4            1            1              3        16       50            21   \n",
       "\n",
       "   Arrival_min  Duration_hours  Duration_mins  Airline_Air India  \\\n",
       "0           10               2             50                  0   \n",
       "1           15               7             25                  1   \n",
       "2           25              19              0                  0   \n",
       "3           30               5             25                  0   \n",
       "4           35               4             45                  0   \n",
       "\n",
       "   Airline_GoAir  Airline_IndiGo  Airline_Jet Airways  \\\n",
       "0              0               1                    0   \n",
       "1              0               0                    0   \n",
       "2              0               0                    1   \n",
       "3              0               1                    0   \n",
       "4              0               1                    0   \n",
       "\n",
       "   Airline_Jet Airways Business  Airline_Multiple carriers  \\\n",
       "0                             0                          0   \n",
       "1                             0                          0   \n",
       "2                             0                          0   \n",
       "3                             0                          0   \n",
       "4                             0                          0   \n",
       "\n",
       "   Airline_Multiple carriers Premium economy  Airline_SpiceJet  \\\n",
       "0                                          0                 0   \n",
       "1                                          0                 0   \n",
       "2                                          0                 0   \n",
       "3                                          0                 0   \n",
       "4                                          0                 0   \n",
       "\n",
       "   Airline_Trujet  Airline_Vistara  Airline_Vistara Premium economy  \\\n",
       "0               0                0                                0   \n",
       "1               0                0                                0   \n",
       "2               0                0                                0   \n",
       "3               0                0                                0   \n",
       "4               0                0                                0   \n",
       "\n",
       "   Source_Chennai  Source_Delhi  Source_Kolkata  Source_Mumbai  \\\n",
       "0               0             0               0              0   \n",
       "1               0             0               1              0   \n",
       "2               0             1               0              0   \n",
       "3               0             0               1              0   \n",
       "4               0             0               0              0   \n",
       "\n",
       "   Destination_Cochin  Destination_Delhi  Destination_Hyderabad  \\\n",
       "0                   0                  0                      0   \n",
       "1                   0                  0                      0   \n",
       "2                   1                  0                      0   \n",
       "3                   0                  0                      0   \n",
       "4                   0                  0                      0   \n",
       "\n",
       "   Destination_Kolkata  Destination_New Delhi  \n",
       "0                    0                      1  \n",
       "1                    0                      0  \n",
       "2                    0                      0  \n",
       "3                    0                      0  \n",
       "4                    0                      1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_train.loc[:, ['Total_Stops', 'Journey_day', 'Journey_month', 'Dep_hour',\n",
    "       'Dep_min', 'Arrival_hour', 'Arrival_min', 'Duration_hours',\n",
    "       'Duration_mins', 'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n",
    "       'Airline_Jet Airways', 'Airline_Jet Airways Business',\n",
    "       'Airline_Multiple carriers',\n",
    "       'Airline_Multiple carriers Premium economy', 'Airline_SpiceJet',\n",
    "       'Airline_Trujet', 'Airline_Vistara', 'Airline_Vistara Premium economy',\n",
    "       'Source_Chennai', 'Source_Delhi', 'Source_Kolkata', 'Source_Mumbai',\n",
    "       'Destination_Cochin', 'Destination_Delhi', 'Destination_Hyderabad',\n",
    "       'Destination_Kolkata', 'Destination_New Delhi']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3897\n",
       "1     7662\n",
       "2    13882\n",
       "3     6218\n",
       "4    13302\n",
       "Name: Price, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_train.iloc[:, 1]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1296 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finds correlation between Independent and dependent attributes\n",
    "\n",
    "plt.figure(figsize = (18,18))\n",
    "sns.heatmap(train_data.corr(), annot = True, cmap = \"RdYlGn\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important feature using ExtraTreesRegressor\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "selection = ExtraTreesRegressor()\n",
    "selection.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.15972428e-01 1.43878305e-01 5.32730567e-02 2.49033458e-02\n",
      " 2.11739914e-02 2.76816194e-02 1.92875685e-02 1.37941296e-01\n",
      " 1.74696088e-02 9.99439789e-03 1.85947503e-03 1.64876068e-02\n",
      " 1.35918579e-01 6.72510639e-02 1.94342811e-02 8.83180028e-04\n",
      " 2.52163370e-03 1.23557372e-04 5.23357955e-03 7.99440270e-05\n",
      " 4.59891275e-04 9.42894021e-03 3.35358175e-03 5.37580677e-03\n",
      " 1.26743147e-02 1.44725474e-02 7.45304406e-03 5.02771213e-04\n",
      " 2.49105840e-02]\n"
     ]
    }
   ],
   "source": [
    "print(selection.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot graph of feature importances for better visualization\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "feat_importances = pd.Series(selection.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting model using Random Forest\n",
    "\n",
    "1. Split dataset into train and test set in order to prediction w.r.t X_test\n",
    "2. If needed do scaling of data\n",
    "    * Scaling is not done in Random forest\n",
    "3. Import model\n",
    "4. Fit the data\n",
    "5. Predict w.r.t X_test\n",
    "6. In regression check **RSME** Score\n",
    "7. Plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg_rf = RandomForestRegressor()\n",
    "reg_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.953772541287897"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.795826451430447"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\seaborn\\distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(y_test-y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.scatter(y_test, y_pred, alpha = 0.5)\n",
    "plt.xlabel(\"y_test\")\n",
    "plt.ylabel(\"y_pred\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1182.5926219474643\n",
      "MSE: 4402401.554160684\n",
      "RMSE: 2098.1900662620355\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026887077025966846"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE/(max(DV)-min(DV))\n",
    "\n",
    "2090.5509/(max(y)-min(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.795826451430447"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "\n",
    "* Choose following method for hyperparameter tuning\n",
    "    1. **RandomizedSearchCV** --> Fast\n",
    "    2. **GridSearchCV**\n",
    "* Assign hyperparameters in form of dictionery\n",
    "* Fit the model\n",
    "* Check best paramters and best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized Search CV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search of parameters, using 5 fold cross validation, \n",
    "# search across 100 different combinations\n",
    "rf_random = RandomizedSearchCV(estimator = reg_rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time=   2.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time=   2.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time=   2.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time=   3.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time=   2.9s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100; total time=   4.6s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100; total time=   4.7s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100; total time=   4.3s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100; total time=   4.7s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100; total time=   4.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300; total time=   2.8s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300; total time=   2.7s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300; total time=   3.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300; total time=   2.6s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300; total time=   2.7s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400; total time=   5.3s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400; total time=   5.2s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400; total time=   5.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700; total time=   8.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700; total time=   8.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700; total time=   8.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700; total time=   7.5s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700; total time=   8.0s\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=   7.1s\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=   7.1s\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=  11.3s\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=  12.4s\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=   9.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time=   2.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time=   2.5s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time=   2.5s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time=   2.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time=   2.2s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.0s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.1s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.0s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.0s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time=   1.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700; total time=   1.3s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700; total time=   1.3s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700; total time=   1.4s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700; total time=   9.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700; total time=   9.3s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700; total time=   8.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700; total time=   8.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700; total time=   9.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=1,\n",
       "                   param_distributions={'max_depth': [5, 10, 15, 20, 25, 30],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 5, 10],\n",
       "                                        'min_samples_split': [2, 5, 10, 15,\n",
       "                                                              100],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000, 1100,\n",
       "                                                         1200]},\n",
       "                   random_state=42, scoring='neg_mean_squared_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 700,\n",
       " 'min_samples_split': 15,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 20}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\seaborn\\distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "sns.distplot(y_test-prediction)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.scatter(y_test, prediction, alpha = 0.5)\n",
    "plt.xlabel(\"y_test\")\n",
    "plt.ylabel(\"y_pred\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1167.2792881262324\n",
      "MSE: 4062014.208361596\n",
      "RMSE: 2015.4439233979188\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model to reuse it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# open a file, where you ant to store the data\n",
    "file = open('flight_rf.pkl', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(reg_rf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = open('flight_rf.pkl','rb')\n",
    "forest = pickle.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7980341156008706"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets Build a Ann Regressot to solve the problem\n",
    "\n",
    "1. Start with a base model\n",
    "2. Increase layers\n",
    "3. Tune learning rates\n",
    "4. TRy to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(X_train)\n",
    "x_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('scaling.pickle', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 9041.9697 - mae: 9041.9697 - val_loss: 8927.2217 - val_mae: 8927.2217\n",
      "Epoch 2/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 5737.2778 - mae: 5737.2778 - val_loss: 2107.1111 - val_mae: 2107.1111\n",
      "Epoch 3/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1937.0775 - mae: 1937.0775 - val_loss: 1946.5442 - val_mae: 1946.5442\n",
      "Epoch 4/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1859.1489 - mae: 1859.1489 - val_loss: 1916.9305 - val_mae: 1916.9305\n",
      "Epoch 5/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1830.3103 - mae: 1830.3103 - val_loss: 1920.6847 - val_mae: 1920.6847\n",
      "Epoch 6/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1813.5771 - mae: 1813.5771 - val_loss: 1864.8041 - val_mae: 1864.8041\n",
      "Epoch 7/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1800.8201 - mae: 1800.8201 - val_loss: 1870.1158 - val_mae: 1870.1158\n",
      "Epoch 8/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1791.2843 - mae: 1791.2843 - val_loss: 1859.2008 - val_mae: 1859.2008\n",
      "Epoch 9/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1778.6855 - mae: 1778.6855 - val_loss: 1845.5414 - val_mae: 1845.5414\n",
      "Epoch 10/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1766.9674 - mae: 1766.9674 - val_loss: 1813.2631 - val_mae: 1813.2631\n",
      "Epoch 11/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1753.3298 - mae: 1753.3298 - val_loss: 1834.9895 - val_mae: 1834.9895\n",
      "Epoch 12/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1741.7151 - mae: 1741.7151 - val_loss: 1837.4142 - val_mae: 1837.4142\n",
      "Epoch 13/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1725.4943 - mae: 1725.4943 - val_loss: 1812.7292 - val_mae: 1812.7292\n",
      "Epoch 14/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1712.6594 - mae: 1712.6594 - val_loss: 1784.9280 - val_mae: 1784.9280\n",
      "Epoch 15/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1704.4209 - mae: 1704.4209 - val_loss: 1758.4552 - val_mae: 1758.4552\n",
      "Epoch 16/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1686.9462 - mae: 1686.9462 - val_loss: 1752.3993 - val_mae: 1752.3993\n",
      "Epoch 17/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1678.4442 - mae: 1678.4442 - val_loss: 1777.7180 - val_mae: 1777.7180\n",
      "Epoch 18/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1667.2321 - mae: 1667.2321 - val_loss: 1751.9142 - val_mae: 1751.9142\n",
      "Epoch 19/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1655.9650 - mae: 1655.9650 - val_loss: 1749.6450 - val_mae: 1749.6450\n",
      "Epoch 20/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1649.1055 - mae: 1649.1055 - val_loss: 1706.9573 - val_mae: 1706.9573\n",
      "Epoch 21/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1642.1650 - mae: 1642.1650 - val_loss: 1706.1731 - val_mae: 1706.1731\n",
      "Epoch 22/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1635.9816 - mae: 1635.9816 - val_loss: 1715.9736 - val_mae: 1715.9736\n",
      "Epoch 23/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1628.6050 - mae: 1628.6050 - val_loss: 1718.4270 - val_mae: 1718.4270\n",
      "Epoch 24/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1626.1124 - mae: 1626.1124 - val_loss: 1725.5907 - val_mae: 1725.5907\n",
      "Epoch 25/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1621.8916 - mae: 1621.8916 - val_loss: 1740.9797 - val_mae: 1740.9797\n",
      "Epoch 26/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1615.9310 - mae: 1615.9310 - val_loss: 1714.6123 - val_mae: 1714.6123\n",
      "Epoch 27/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1612.8838 - mae: 1612.8838 - val_loss: 1698.8989 - val_mae: 1698.8989\n",
      "Epoch 28/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1613.7384 - mae: 1613.7384 - val_loss: 1718.0089 - val_mae: 1718.0089\n",
      "Epoch 29/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1609.3428 - mae: 1609.3428 - val_loss: 1738.1726 - val_mae: 1738.1726\n",
      "Epoch 30/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1605.6305 - mae: 1605.6305 - val_loss: 1726.5011 - val_mae: 1726.5011\n",
      "Epoch 31/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1604.4097 - mae: 1604.4097 - val_loss: 1676.4761 - val_mae: 1676.4761\n",
      "Epoch 32/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1602.0549 - mae: 1602.0549 - val_loss: 1751.2828 - val_mae: 1751.2828\n",
      "Epoch 33/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1599.2512 - mae: 1599.2512 - val_loss: 1717.8943 - val_mae: 1717.8943\n",
      "Epoch 34/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1601.0856 - mae: 1601.0856 - val_loss: 1687.2284 - val_mae: 1687.2284\n",
      "Epoch 35/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1598.3843 - mae: 1598.3843 - val_loss: 1672.9363 - val_mae: 1672.9363\n",
      "Epoch 36/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1594.0487 - mae: 1594.0487 - val_loss: 1676.7625 - val_mae: 1676.7625\n",
      "Epoch 37/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1595.3264 - mae: 1595.3264 - val_loss: 1686.2688 - val_mae: 1686.2688\n",
      "Epoch 38/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1592.9261 - mae: 1592.9261 - val_loss: 1701.2753 - val_mae: 1701.2753\n",
      "Epoch 39/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1591.3424 - mae: 1591.3424 - val_loss: 1718.4900 - val_mae: 1718.4900\n",
      "Epoch 40/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1589.7675 - mae: 1589.7675 - val_loss: 1719.9425 - val_mae: 1719.9425\n",
      "Epoch 41/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1590.1744 - mae: 1590.1744 - val_loss: 1702.1957 - val_mae: 1702.1957\n",
      "Epoch 42/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1586.7410 - mae: 1586.7410 - val_loss: 1684.6633 - val_mae: 1684.6633\n",
      "Epoch 43/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1586.4883 - mae: 1586.4883 - val_loss: 1728.5515 - val_mae: 1728.5515\n",
      "Epoch 44/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1584.2443 - mae: 1584.2443 - val_loss: 1674.2426 - val_mae: 1674.2426\n",
      "Epoch 45/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1585.1902 - mae: 1585.1902 - val_loss: 1675.1672 - val_mae: 1675.1672\n",
      "Epoch 46/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1582.4260 - mae: 1582.4260 - val_loss: 1658.0046 - val_mae: 1658.0046\n",
      "Epoch 47/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1579.9376 - mae: 1579.9376 - val_loss: 1684.9342 - val_mae: 1684.9342\n",
      "Epoch 48/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1578.5172 - mae: 1578.5172 - val_loss: 1671.7751 - val_mae: 1671.7751\n",
      "Epoch 49/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1578.5685 - mae: 1578.5685 - val_loss: 1699.8483 - val_mae: 1699.8483\n",
      "Epoch 50/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1576.3954 - mae: 1576.3954 - val_loss: 1711.2954 - val_mae: 1711.2954\n",
      "Epoch 51/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1576.0256 - mae: 1576.0256 - val_loss: 1663.3054 - val_mae: 1663.3054\n",
      "Epoch 52/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1574.7267 - mae: 1574.7267 - val_loss: 1681.0497 - val_mae: 1681.0497\n",
      "Epoch 53/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1573.6843 - mae: 1573.6843 - val_loss: 1666.0015 - val_mae: 1666.0015\n",
      "Epoch 54/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1570.6228 - mae: 1570.6228 - val_loss: 1672.7032 - val_mae: 1672.7032\n",
      "Epoch 55/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1567.5878 - mae: 1567.5878 - val_loss: 1720.0507 - val_mae: 1720.0507\n",
      "Epoch 56/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1571.5082 - mae: 1571.5082 - val_loss: 1693.2380 - val_mae: 1693.2380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1565.3705 - mae: 1565.3705 - val_loss: 1708.3593 - val_mae: 1708.3593\n",
      "Epoch 58/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1564.0466 - mae: 1564.0466 - val_loss: 1708.8921 - val_mae: 1708.8921\n",
      "Epoch 59/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1562.4495 - mae: 1562.4495 - val_loss: 1717.4136 - val_mae: 1717.4136\n",
      "Epoch 60/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1561.5798 - mae: 1561.5798 - val_loss: 1681.7639 - val_mae: 1681.7639\n",
      "Epoch 61/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1561.6534 - mae: 1561.6534 - val_loss: 1694.9926 - val_mae: 1694.9926\n",
      "Epoch 62/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1561.5883 - mae: 1561.5883 - val_loss: 1654.7812 - val_mae: 1654.7812\n",
      "Epoch 63/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1560.4803 - mae: 1560.4803 - val_loss: 1693.2487 - val_mae: 1693.2487\n",
      "Epoch 64/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1555.5773 - mae: 1555.5773 - val_loss: 1693.0940 - val_mae: 1693.0940\n",
      "Epoch 65/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1557.6134 - mae: 1557.6134 - val_loss: 1683.0599 - val_mae: 1683.0599\n",
      "Epoch 66/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1555.0962 - mae: 1555.0962 - val_loss: 1667.2925 - val_mae: 1667.2925\n",
      "Epoch 67/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1552.4323 - mae: 1552.4323 - val_loss: 1708.7739 - val_mae: 1708.7739\n",
      "Epoch 68/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1550.8523 - mae: 1550.8523 - val_loss: 1668.5640 - val_mae: 1668.5640\n",
      "Epoch 69/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1550.9169 - mae: 1550.9169 - val_loss: 1657.0492 - val_mae: 1657.0492\n",
      "Epoch 70/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1545.4196 - mae: 1545.4196 - val_loss: 1702.2109 - val_mae: 1702.2109\n",
      "Epoch 71/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1548.2976 - mae: 1548.2976 - val_loss: 1658.1259 - val_mae: 1658.1259\n",
      "Epoch 72/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1544.0593 - mae: 1544.0593 - val_loss: 1657.4696 - val_mae: 1657.4696\n",
      "Epoch 73/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1544.0422 - mae: 1544.0422 - val_loss: 1654.8165 - val_mae: 1654.8165\n",
      "Epoch 74/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1544.2576 - mae: 1544.2576 - val_loss: 1651.0618 - val_mae: 1651.0618\n",
      "Epoch 75/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1543.1488 - mae: 1543.1488 - val_loss: 1696.6237 - val_mae: 1696.6237\n",
      "Epoch 76/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1542.0343 - mae: 1542.0343 - val_loss: 1635.9348 - val_mae: 1635.9348\n",
      "Epoch 77/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1541.1062 - mae: 1541.1062 - val_loss: 1663.2544 - val_mae: 1663.2544\n",
      "Epoch 78/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1538.7209 - mae: 1538.7209 - val_loss: 1659.8020 - val_mae: 1659.8020\n",
      "Epoch 79/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1537.4515 - mae: 1537.4515 - val_loss: 1672.4332 - val_mae: 1672.4332\n",
      "Epoch 80/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1537.4381 - mae: 1537.4381 - val_loss: 1667.9027 - val_mae: 1667.9027\n",
      "Epoch 81/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1534.6671 - mae: 1534.6671 - val_loss: 1651.8127 - val_mae: 1651.8127\n",
      "Epoch 82/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1533.8842 - mae: 1533.8842 - val_loss: 1642.8965 - val_mae: 1642.8965\n",
      "Epoch 83/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1532.6508 - mae: 1532.6508 - val_loss: 1681.0709 - val_mae: 1681.0709\n",
      "Epoch 84/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1534.4647 - mae: 1534.4647 - val_loss: 1640.1637 - val_mae: 1640.1637\n",
      "Epoch 85/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1529.4374 - mae: 1529.4374 - val_loss: 1694.3643 - val_mae: 1694.3643\n",
      "Epoch 86/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1531.2334 - mae: 1531.2334 - val_loss: 1674.2373 - val_mae: 1674.2373\n",
      "Epoch 87/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1529.0804 - mae: 1529.0804 - val_loss: 1640.6891 - val_mae: 1640.6891\n",
      "Epoch 88/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1526.1169 - mae: 1526.1169 - val_loss: 1630.3822 - val_mae: 1630.3822\n",
      "Epoch 89/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1525.5985 - mae: 1525.5985 - val_loss: 1653.0845 - val_mae: 1653.0845\n",
      "Epoch 90/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1525.5638 - mae: 1525.5638 - val_loss: 1644.9227 - val_mae: 1644.9227\n",
      "Epoch 91/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1522.3728 - mae: 1522.3728 - val_loss: 1642.5498 - val_mae: 1642.5498\n",
      "Epoch 92/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1523.6285 - mae: 1523.6285 - val_loss: 1658.8203 - val_mae: 1658.8203\n",
      "Epoch 93/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1521.4713 - mae: 1521.4713 - val_loss: 1690.4131 - val_mae: 1690.4131\n",
      "Epoch 94/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1520.8635 - mae: 1520.8635 - val_loss: 1629.8701 - val_mae: 1629.8701\n",
      "Epoch 95/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1516.5793 - mae: 1516.5793 - val_loss: 1649.1656 - val_mae: 1649.1656\n",
      "Epoch 96/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1520.0613 - mae: 1520.0613 - val_loss: 1678.6888 - val_mae: 1678.6888\n",
      "Epoch 97/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1519.9586 - mae: 1519.9586 - val_loss: 1637.3667 - val_mae: 1637.3667\n",
      "Epoch 98/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1518.0503 - mae: 1518.0503 - val_loss: 1652.1841 - val_mae: 1652.1841\n",
      "Epoch 99/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1517.6344 - mae: 1517.6344 - val_loss: 1629.4493 - val_mae: 1629.4493\n",
      "Epoch 100/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1516.5604 - mae: 1516.5604 - val_loss: 1631.7892 - val_mae: 1631.7892\n",
      "Epoch 101/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1513.5267 - mae: 1513.5267 - val_loss: 1652.5728 - val_mae: 1652.5728\n",
      "Epoch 102/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1516.5300 - mae: 1516.5300 - val_loss: 1643.8798 - val_mae: 1643.8798\n",
      "Epoch 103/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1511.3064 - mae: 1511.3064 - val_loss: 1632.8107 - val_mae: 1632.8107\n",
      "Epoch 104/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1513.5063 - mae: 1513.5063 - val_loss: 1640.4437 - val_mae: 1640.4437\n",
      "Epoch 105/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1509.8235 - mae: 1509.8235 - val_loss: 1621.2030 - val_mae: 1621.2030\n",
      "Epoch 106/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1509.0316 - mae: 1509.0316 - val_loss: 1663.2084 - val_mae: 1663.2084\n",
      "Epoch 107/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1506.6349 - mae: 1506.6349 - val_loss: 1628.8729 - val_mae: 1628.8729\n",
      "Epoch 108/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1506.0492 - mae: 1506.0492 - val_loss: 1620.0850 - val_mae: 1620.0850\n",
      "Epoch 109/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1507.5339 - mae: 1507.5339 - val_loss: 1628.1265 - val_mae: 1628.1265\n",
      "Epoch 110/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1504.0253 - mae: 1504.0253 - val_loss: 1632.5409 - val_mae: 1632.5409\n",
      "Epoch 111/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1501.7346 - mae: 1501.7346 - val_loss: 1625.8645 - val_mae: 1625.8645\n",
      "Epoch 112/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1506.1156 - mae: 1506.1156 - val_loss: 1614.7094 - val_mae: 1614.7094\n",
      "Epoch 113/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1498.2059 - mae: 1498.2059 - val_loss: 1615.3101 - val_mae: 1615.3101\n",
      "Epoch 114/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1501.7318 - mae: 1501.7318 - val_loss: 1605.5294 - val_mae: 1605.5294\n",
      "Epoch 115/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1500.1720 - mae: 1500.1720 - val_loss: 1643.8472 - val_mae: 1643.8472\n",
      "Epoch 116/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1496.0344 - mae: 1496.0344 - val_loss: 1639.6980 - val_mae: 1639.6980\n",
      "Epoch 117/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1501.3596 - mae: 1501.3596 - val_loss: 1625.8931 - val_mae: 1625.8931\n",
      "Epoch 118/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1495.7874 - mae: 1495.7874 - val_loss: 1609.2095 - val_mae: 1609.2095\n",
      "Epoch 119/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1495.1079 - mae: 1495.1079 - val_loss: 1602.9473 - val_mae: 1602.9473\n",
      "Epoch 120/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1494.3267 - mae: 1494.3267 - val_loss: 1602.1680 - val_mae: 1602.1680\n",
      "Epoch 121/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1492.8815 - mae: 1492.8815 - val_loss: 1629.5524 - val_mae: 1629.5524\n",
      "Epoch 122/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1490.9950 - mae: 1490.9950 - val_loss: 1617.2954 - val_mae: 1617.2954\n",
      "Epoch 123/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1491.1104 - mae: 1491.1104 - val_loss: 1593.6588 - val_mae: 1593.6588\n",
      "Epoch 124/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1489.9733 - mae: 1489.9733 - val_loss: 1600.8396 - val_mae: 1600.8396\n",
      "Epoch 125/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1488.2936 - mae: 1488.2936 - val_loss: 1611.5787 - val_mae: 1611.5787\n",
      "Epoch 126/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1484.4358 - mae: 1484.4358 - val_loss: 1608.7971 - val_mae: 1608.7971\n",
      "Epoch 127/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1486.1730 - mae: 1486.1730 - val_loss: 1576.9171 - val_mae: 1576.9171\n",
      "Epoch 128/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1486.0216 - mae: 1486.0216 - val_loss: 1617.3383 - val_mae: 1617.3383\n",
      "Epoch 129/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1485.1498 - mae: 1485.1498 - val_loss: 1602.0435 - val_mae: 1602.0435\n",
      "Epoch 130/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1483.3829 - mae: 1483.3829 - val_loss: 1593.1088 - val_mae: 1593.1088\n",
      "Epoch 131/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1480.3121 - mae: 1480.3121 - val_loss: 1594.0323 - val_mae: 1594.0323\n",
      "Epoch 132/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1479.9073 - mae: 1479.9073 - val_loss: 1581.2162 - val_mae: 1581.2162\n",
      "Epoch 133/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1479.5687 - mae: 1479.5687 - val_loss: 1600.2053 - val_mae: 1600.2053\n",
      "Epoch 134/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1478.0085 - mae: 1478.0085 - val_loss: 1595.2372 - val_mae: 1595.2372\n",
      "Epoch 135/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1479.1188 - mae: 1479.1188 - val_loss: 1600.4150 - val_mae: 1600.4150\n",
      "Epoch 136/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1477.6295 - mae: 1477.6295 - val_loss: 1598.7400 - val_mae: 1598.7400\n",
      "Epoch 137/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1476.2922 - mae: 1476.2922 - val_loss: 1572.7999 - val_mae: 1572.7999\n",
      "Epoch 138/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1473.3314 - mae: 1473.3314 - val_loss: 1579.7518 - val_mae: 1579.7518\n",
      "Epoch 139/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1472.0540 - mae: 1472.0540 - val_loss: 1567.0508 - val_mae: 1567.0508\n",
      "Epoch 140/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1472.4110 - mae: 1472.4110 - val_loss: 1574.0848 - val_mae: 1574.0848\n",
      "Epoch 141/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1472.3649 - mae: 1472.3649 - val_loss: 1570.7904 - val_mae: 1570.7904\n",
      "Epoch 142/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1471.4104 - mae: 1471.4104 - val_loss: 1599.8469 - val_mae: 1599.8469\n",
      "Epoch 143/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1470.3550 - mae: 1470.3550 - val_loss: 1563.5052 - val_mae: 1563.5052\n",
      "Epoch 144/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1469.6917 - mae: 1469.6917 - val_loss: 1581.8092 - val_mae: 1581.8092\n",
      "Epoch 145/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1466.6342 - mae: 1466.6342 - val_loss: 1625.1934 - val_mae: 1625.1934\n",
      "Epoch 146/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1466.9197 - mae: 1466.9197 - val_loss: 1574.5306 - val_mae: 1574.5306\n",
      "Epoch 147/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1469.0453 - mae: 1469.0453 - val_loss: 1565.0991 - val_mae: 1565.0991\n",
      "Epoch 148/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1466.2961 - mae: 1466.2961 - val_loss: 1558.1041 - val_mae: 1558.1041\n",
      "Epoch 149/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1464.8655 - mae: 1464.8655 - val_loss: 1583.8558 - val_mae: 1583.8558\n",
      "Epoch 150/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1466.7458 - mae: 1466.7458 - val_loss: 1582.8536 - val_mae: 1582.8536\n",
      "Epoch 151/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1466.5773 - mae: 1466.5773 - val_loss: 1581.0260 - val_mae: 1581.0260\n",
      "Epoch 152/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1464.9417 - mae: 1464.9417 - val_loss: 1596.9277 - val_mae: 1596.9277\n",
      "Epoch 153/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1462.8492 - mae: 1462.8492 - val_loss: 1633.7415 - val_mae: 1633.7415\n",
      "Epoch 154/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1464.9971 - mae: 1464.9971 - val_loss: 1593.3613 - val_mae: 1593.3613\n",
      "Epoch 155/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1460.6676 - mae: 1460.6676 - val_loss: 1566.3583 - val_mae: 1566.3583\n",
      "Epoch 156/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1462.0842 - mae: 1462.0842 - val_loss: 1572.8712 - val_mae: 1572.8712\n",
      "Epoch 157/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1461.8621 - mae: 1461.8621 - val_loss: 1555.0392 - val_mae: 1555.0392\n",
      "Epoch 158/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1459.3079 - mae: 1459.3079 - val_loss: 1564.1025 - val_mae: 1564.1025\n",
      "Epoch 159/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1461.0881 - mae: 1461.0881 - val_loss: 1566.1404 - val_mae: 1566.1404\n",
      "Epoch 160/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1457.6182 - mae: 1457.6182 - val_loss: 1563.5743 - val_mae: 1563.5743\n",
      "Epoch 161/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1458.7179 - mae: 1458.7179 - val_loss: 1568.8846 - val_mae: 1568.8846\n",
      "Epoch 162/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1458.1047 - mae: 1458.1047 - val_loss: 1568.5223 - val_mae: 1568.5223\n",
      "Epoch 163/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1456.4916 - mae: 1456.4916 - val_loss: 1569.2628 - val_mae: 1569.2628\n",
      "Epoch 164/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1457.7313 - mae: 1457.7313 - val_loss: 1553.3772 - val_mae: 1553.3772\n",
      "Epoch 165/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1455.5035 - mae: 1455.5035 - val_loss: 1560.6788 - val_mae: 1560.6788\n",
      "Epoch 166/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1454.7665 - mae: 1454.7665 - val_loss: 1570.5807 - val_mae: 1570.5807\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 2ms/step - loss: 1453.7961 - mae: 1453.7961 - val_loss: 1574.6526 - val_mae: 1574.6526\n",
      "Epoch 168/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1453.8633 - mae: 1453.8633 - val_loss: 1551.5840 - val_mae: 1551.5840\n",
      "Epoch 169/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1452.8202 - mae: 1452.8202 - val_loss: 1559.8975 - val_mae: 1559.8975\n",
      "Epoch 170/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1452.6665 - mae: 1452.6665 - val_loss: 1551.7937 - val_mae: 1551.7937\n",
      "Epoch 171/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1452.6962 - mae: 1452.6962 - val_loss: 1565.1151 - val_mae: 1565.1151\n",
      "Epoch 172/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1451.2113 - mae: 1451.2113 - val_loss: 1590.3416 - val_mae: 1590.3416\n",
      "Epoch 173/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1450.2385 - mae: 1450.2385 - val_loss: 1550.8865 - val_mae: 1550.8865\n",
      "Epoch 174/1000\n",
      "268/268 [==============================] - 3s 12ms/step - loss: 1449.5776 - mae: 1449.5776 - val_loss: 1536.1278 - val_mae: 1536.1278\n",
      "Epoch 175/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1448.8102 - mae: 1448.8102 - val_loss: 1547.9432 - val_mae: 1547.9432\n",
      "Epoch 176/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1445.7614 - mae: 1445.7614 - val_loss: 1570.8492 - val_mae: 1570.8492\n",
      "Epoch 177/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1446.6454 - mae: 1446.6454 - val_loss: 1569.1783 - val_mae: 1569.1783\n",
      "Epoch 178/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1446.7526 - mae: 1446.7526 - val_loss: 1575.3993 - val_mae: 1575.3993\n",
      "Epoch 179/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1444.1515 - mae: 1444.1515 - val_loss: 1597.6094 - val_mae: 1597.6094\n",
      "Epoch 180/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1445.4060 - mae: 1445.4060 - val_loss: 1557.3103 - val_mae: 1557.3103\n",
      "Epoch 181/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1445.8668 - mae: 1445.8668 - val_loss: 1535.3505 - val_mae: 1535.3505\n",
      "Epoch 182/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1442.6237 - mae: 1442.6237 - val_loss: 1600.9224 - val_mae: 1600.9224\n",
      "Epoch 183/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1446.1964 - mae: 1446.1964 - val_loss: 1576.6049 - val_mae: 1576.6049\n",
      "Epoch 184/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1444.2517 - mae: 1444.2517 - val_loss: 1559.7489 - val_mae: 1559.7489\n",
      "Epoch 185/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1441.9120 - mae: 1441.9120 - val_loss: 1572.0928 - val_mae: 1572.0928\n",
      "Epoch 186/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1442.2917 - mae: 1442.2917 - val_loss: 1569.7532 - val_mae: 1569.7532\n",
      "Epoch 187/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1440.7543 - mae: 1440.7543 - val_loss: 1602.6085 - val_mae: 1602.6085\n",
      "Epoch 188/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1439.8055 - mae: 1439.8055 - val_loss: 1554.4031 - val_mae: 1554.4031\n",
      "Epoch 189/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1439.1631 - mae: 1439.1631 - val_loss: 1545.4843 - val_mae: 1545.4843\n",
      "Epoch 190/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1436.0215 - mae: 1436.0215 - val_loss: 1565.3248 - val_mae: 1565.3248\n",
      "Epoch 191/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1438.8374 - mae: 1438.8374 - val_loss: 1561.1896 - val_mae: 1561.1896\n",
      "Epoch 192/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1437.4037 - mae: 1437.4037 - val_loss: 1618.6438 - val_mae: 1618.6438\n",
      "Epoch 193/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1444.3591 - mae: 1444.3591 - val_loss: 1563.9520 - val_mae: 1563.9520\n",
      "Epoch 194/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1439.9590 - mae: 1439.9590 - val_loss: 1540.4303 - val_mae: 1540.4303\n",
      "Epoch 195/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1435.2875 - mae: 1435.2875 - val_loss: 1549.7297 - val_mae: 1549.7297\n",
      "Epoch 196/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1437.6965 - mae: 1437.6965 - val_loss: 1569.8896 - val_mae: 1569.8896\n",
      "Epoch 197/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1436.1422 - mae: 1436.1422 - val_loss: 1551.0262 - val_mae: 1551.0262\n",
      "Epoch 198/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1436.5620 - mae: 1436.5620 - val_loss: 1575.0536 - val_mae: 1575.0536\n",
      "Epoch 199/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1435.3782 - mae: 1435.3782 - val_loss: 1536.9105 - val_mae: 1536.9105\n",
      "Epoch 200/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1434.3801 - mae: 1434.3801 - val_loss: 1551.0232 - val_mae: 1551.0232\n",
      "Epoch 201/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1436.5598 - mae: 1436.5598 - val_loss: 1573.1158 - val_mae: 1573.1158\n",
      "Epoch 202/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1433.7194 - mae: 1433.7194 - val_loss: 1578.8615 - val_mae: 1578.8615\n",
      "Epoch 203/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1435.7800 - mae: 1435.7800 - val_loss: 1542.0649 - val_mae: 1542.0649\n",
      "Epoch 204/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1435.0829 - mae: 1435.0829 - val_loss: 1561.6416 - val_mae: 1561.6416\n",
      "Epoch 205/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1432.9348 - mae: 1432.9348 - val_loss: 1546.2897 - val_mae: 1546.2897\n",
      "Epoch 206/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1432.4556 - mae: 1432.4556 - val_loss: 1597.6082 - val_mae: 1597.6082\n",
      "Epoch 207/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1432.0059 - mae: 1432.0059 - val_loss: 1532.8441 - val_mae: 1532.8441\n",
      "Epoch 208/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1432.9038 - mae: 1432.9038 - val_loss: 1562.4031 - val_mae: 1562.4031\n",
      "Epoch 209/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1434.6377 - mae: 1434.6377 - val_loss: 1594.2163 - val_mae: 1594.2163\n",
      "Epoch 210/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1432.7075 - mae: 1432.7075 - val_loss: 1549.8621 - val_mae: 1549.8621\n",
      "Epoch 211/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1431.9303 - mae: 1431.9303 - val_loss: 1534.9425 - val_mae: 1534.9425\n",
      "Epoch 212/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1429.8595 - mae: 1429.8595 - val_loss: 1545.0470 - val_mae: 1545.0470\n",
      "Epoch 213/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1431.8822 - mae: 1431.8822 - val_loss: 1557.2717 - val_mae: 1557.2717\n",
      "Epoch 214/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1427.8071 - mae: 1427.8071 - val_loss: 1592.2721 - val_mae: 1592.2721\n",
      "Epoch 215/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1436.3877 - mae: 1436.3877 - val_loss: 1593.8207 - val_mae: 1593.8207\n",
      "Epoch 216/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1435.0660 - mae: 1435.0660 - val_loss: 1530.0872 - val_mae: 1530.0872\n",
      "Epoch 217/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1430.7880 - mae: 1430.7880 - val_loss: 1551.5209 - val_mae: 1551.5209\n",
      "Epoch 218/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1427.5111 - mae: 1427.5111 - val_loss: 1605.8181 - val_mae: 1605.8181\n",
      "Epoch 219/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1430.1047 - mae: 1430.1047 - val_loss: 1531.8286 - val_mae: 1531.8286\n",
      "Epoch 220/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1435.5148 - mae: 1435.5148 - val_loss: 1569.2123 - val_mae: 1569.2123\n",
      "Epoch 221/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1431.0901 - mae: 1431.0901 - val_loss: 1521.5299 - val_mae: 1521.5299\n",
      "Epoch 222/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1428.8739 - mae: 1428.8739 - val_loss: 1551.0464 - val_mae: 1551.0464\n",
      "Epoch 223/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1429.9421 - mae: 1429.9421 - val_loss: 1532.3391 - val_mae: 1532.3391\n",
      "Epoch 224/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1428.7449 - mae: 1428.7449 - val_loss: 1603.9080 - val_mae: 1603.9080\n",
      "Epoch 225/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1427.9698 - mae: 1427.9698 - val_loss: 1592.5648 - val_mae: 1592.5648\n",
      "Epoch 226/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1426.2803 - mae: 1426.2803 - val_loss: 1542.0062 - val_mae: 1542.0062\n",
      "Epoch 227/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1430.2106 - mae: 1430.2106 - val_loss: 1564.7415 - val_mae: 1564.7415\n",
      "Epoch 228/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1427.5378 - mae: 1427.5378 - val_loss: 1561.0568 - val_mae: 1561.0568\n",
      "Epoch 229/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1429.2722 - mae: 1429.2722 - val_loss: 1551.4547 - val_mae: 1551.4547\n",
      "Epoch 230/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1428.2931 - mae: 1428.2931 - val_loss: 1572.7722 - val_mae: 1572.7722\n",
      "Epoch 231/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1426.5692 - mae: 1426.5692 - val_loss: 1548.6628 - val_mae: 1548.6628\n",
      "Epoch 232/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1426.6073 - mae: 1426.6073 - val_loss: 1530.5919 - val_mae: 1530.5919\n",
      "Epoch 233/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1427.6445 - mae: 1427.6445 - val_loss: 1537.5256 - val_mae: 1537.5256\n",
      "Epoch 234/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1428.3292 - mae: 1428.3292 - val_loss: 1534.1389 - val_mae: 1534.1389\n",
      "Epoch 235/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1427.5427 - mae: 1427.5427 - val_loss: 1535.4559 - val_mae: 1535.4559\n",
      "Epoch 236/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1426.2504 - mae: 1426.2504 - val_loss: 1548.0110 - val_mae: 1548.0110\n",
      "Epoch 237/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1426.1245 - mae: 1426.1245 - val_loss: 1575.4358 - val_mae: 1575.4358\n",
      "Epoch 238/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1427.7136 - mae: 1427.7136 - val_loss: 1540.9211 - val_mae: 1540.9211\n",
      "Epoch 239/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1425.8514 - mae: 1425.8514 - val_loss: 1569.1179 - val_mae: 1569.1179\n",
      "Epoch 240/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1429.6355 - mae: 1429.6355 - val_loss: 1555.0371 - val_mae: 1555.0371\n",
      "Epoch 241/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1427.3672 - mae: 1427.3672 - val_loss: 1567.4817 - val_mae: 1567.4817\n",
      "Epoch 242/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1426.1034 - mae: 1426.1034 - val_loss: 1563.3986 - val_mae: 1563.3986\n",
      "Epoch 243/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1427.5941 - mae: 1427.5941 - val_loss: 1554.6360 - val_mae: 1554.6360\n",
      "Epoch 244/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1428.5609 - mae: 1428.5609 - val_loss: 1543.4528 - val_mae: 1543.4528\n",
      "Epoch 245/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1423.8790 - mae: 1423.8790 - val_loss: 1538.4536 - val_mae: 1538.4536\n",
      "Epoch 246/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1423.0309 - mae: 1423.0309 - val_loss: 1526.2067 - val_mae: 1526.2067\n",
      "Epoch 247/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1425.5615 - mae: 1425.5615 - val_loss: 1533.8781 - val_mae: 1533.8781\n",
      "Epoch 248/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1426.7526 - mae: 1426.7526 - val_loss: 1559.0155 - val_mae: 1559.0155\n",
      "Epoch 249/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1429.4855 - mae: 1429.4855 - val_loss: 1523.0388 - val_mae: 1523.0388\n",
      "Epoch 250/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1424.1527 - mae: 1424.1527 - val_loss: 1537.5576 - val_mae: 1537.5576\n",
      "Epoch 251/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1424.6202 - mae: 1424.6202 - val_loss: 1577.5995 - val_mae: 1577.5995\n",
      "Epoch 252/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1423.7274 - mae: 1423.7274 - val_loss: 1582.8652 - val_mae: 1582.8652\n",
      "Epoch 253/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1423.6342 - mae: 1423.6342 - val_loss: 1538.6506 - val_mae: 1538.6506\n",
      "Epoch 254/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1423.8253 - mae: 1423.8253 - val_loss: 1543.2466 - val_mae: 1543.2466\n",
      "Epoch 255/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1423.5872 - mae: 1423.5872 - val_loss: 1576.2587 - val_mae: 1576.2587\n",
      "Epoch 256/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1425.2461 - mae: 1425.2461 - val_loss: 1583.3441 - val_mae: 1583.3441\n",
      "Epoch 257/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1422.9149 - mae: 1422.9149 - val_loss: 1524.9364 - val_mae: 1524.9364\n",
      "Epoch 258/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1421.5946 - mae: 1421.5946 - val_loss: 1600.6608 - val_mae: 1600.6608\n",
      "Epoch 259/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1425.0457 - mae: 1425.0457 - val_loss: 1537.6372 - val_mae: 1537.6372\n",
      "Epoch 260/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1425.1119 - mae: 1425.1119 - val_loss: 1531.9158 - val_mae: 1531.9158\n",
      "Epoch 261/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1422.5103 - mae: 1422.5103 - val_loss: 1551.2338 - val_mae: 1551.2338\n",
      "Epoch 262/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1423.8711 - mae: 1423.8711 - val_loss: 1533.3541 - val_mae: 1533.3541\n",
      "Epoch 263/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1421.2543 - mae: 1421.2543 - val_loss: 1519.0039 - val_mae: 1519.0039\n",
      "Epoch 264/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1422.0596 - mae: 1422.0596 - val_loss: 1532.5710 - val_mae: 1532.5710\n",
      "Epoch 265/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1422.1295 - mae: 1422.1295 - val_loss: 1541.8940 - val_mae: 1541.8940\n",
      "Epoch 266/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1421.5684 - mae: 1421.5684 - val_loss: 1547.9209 - val_mae: 1547.9209\n",
      "Epoch 267/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1423.5052 - mae: 1423.5052 - val_loss: 1566.1868 - val_mae: 1566.1868\n",
      "Epoch 268/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1423.2870 - mae: 1423.2870 - val_loss: 1560.2042 - val_mae: 1560.2042\n",
      "Epoch 269/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1420.1151 - mae: 1420.1151 - val_loss: 1604.5382 - val_mae: 1604.5382\n",
      "Epoch 270/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1423.6688 - mae: 1423.6688 - val_loss: 1588.0598 - val_mae: 1588.0598\n",
      "Epoch 271/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1421.7068 - mae: 1421.7068 - val_loss: 1548.2627 - val_mae: 1548.2627\n",
      "Epoch 272/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1420.2212 - mae: 1420.2212 - val_loss: 1535.0782 - val_mae: 1535.0782\n",
      "Epoch 273/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1418.2827 - mae: 1418.2827 - val_loss: 1530.5804 - val_mae: 1530.5804\n",
      "Epoch 274/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1421.4302 - mae: 1421.4302 - val_loss: 1585.0978 - val_mae: 1585.0978\n",
      "Epoch 275/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1419.5089 - mae: 1419.5089 - val_loss: 1545.2164 - val_mae: 1545.2164\n",
      "Epoch 276/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1420.2357 - mae: 1420.2357 - val_loss: 1530.8148 - val_mae: 1530.8148\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 2ms/step - loss: 1419.2411 - mae: 1419.2411 - val_loss: 1530.0415 - val_mae: 1530.0415\n",
      "Epoch 278/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1421.3269 - mae: 1421.3269 - val_loss: 1568.5381 - val_mae: 1568.5381\n",
      "Epoch 279/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1422.4348 - mae: 1422.4348 - val_loss: 1547.8134 - val_mae: 1547.8134\n",
      "Epoch 280/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1420.3545 - mae: 1420.3545 - val_loss: 1523.1865 - val_mae: 1523.1865\n",
      "Epoch 281/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1419.8407 - mae: 1419.8407 - val_loss: 1570.9739 - val_mae: 1570.9739\n",
      "Epoch 282/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1419.0728 - mae: 1419.0728 - val_loss: 1526.8969 - val_mae: 1526.8969\n",
      "Epoch 283/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1419.2012 - mae: 1419.2012 - val_loss: 1525.0138 - val_mae: 1525.0138\n",
      "Epoch 284/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1418.9286 - mae: 1418.9286 - val_loss: 1582.6411 - val_mae: 1582.6411\n",
      "Epoch 285/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1419.5680 - mae: 1419.5680 - val_loss: 1521.2946 - val_mae: 1521.2946\n",
      "Epoch 286/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1418.3770 - mae: 1418.3770 - val_loss: 1571.4763 - val_mae: 1571.4763\n",
      "Epoch 287/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1426.3396 - mae: 1426.3396 - val_loss: 1538.9443 - val_mae: 1538.9443\n",
      "Epoch 288/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1418.4674 - mae: 1418.4674 - val_loss: 1560.2407 - val_mae: 1560.2407\n",
      "Epoch 289/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1420.0179 - mae: 1420.0179 - val_loss: 1538.2798 - val_mae: 1538.2798\n",
      "Epoch 290/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1418.9122 - mae: 1418.9122 - val_loss: 1518.3427 - val_mae: 1518.3427\n",
      "Epoch 291/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1420.4225 - mae: 1420.4225 - val_loss: 1595.4437 - val_mae: 1595.4437\n",
      "Epoch 292/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1418.2537 - mae: 1418.2537 - val_loss: 1520.7816 - val_mae: 1520.7816\n",
      "Epoch 293/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1418.8160 - mae: 1418.8160 - val_loss: 1530.2739 - val_mae: 1530.2739\n",
      "Epoch 294/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1418.4323 - mae: 1418.4323 - val_loss: 1527.9739 - val_mae: 1527.9739\n",
      "Epoch 295/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1419.8396 - mae: 1419.8396 - val_loss: 1524.8937 - val_mae: 1524.8937\n",
      "Epoch 296/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1417.8440 - mae: 1417.8440 - val_loss: 1536.3448 - val_mae: 1536.3448\n",
      "Epoch 297/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1419.9784 - mae: 1419.9784 - val_loss: 1578.4232 - val_mae: 1578.4232\n",
      "Epoch 298/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1419.7393 - mae: 1419.7393 - val_loss: 1561.2324 - val_mae: 1561.2324\n",
      "Epoch 299/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1417.7576 - mae: 1417.7576 - val_loss: 1528.3461 - val_mae: 1528.3461\n",
      "Epoch 300/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1416.1433 - mae: 1416.1433 - val_loss: 1548.7493 - val_mae: 1548.7493\n",
      "Epoch 301/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1417.8636 - mae: 1417.8636 - val_loss: 1536.8894 - val_mae: 1536.8894\n",
      "Epoch 302/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1416.7177 - mae: 1416.7177 - val_loss: 1538.6882 - val_mae: 1538.6882\n",
      "Epoch 303/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1419.5071 - mae: 1419.5071 - val_loss: 1541.9164 - val_mae: 1541.9164\n",
      "Epoch 304/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1417.8950 - mae: 1417.8950 - val_loss: 1527.4115 - val_mae: 1527.4115\n",
      "Epoch 305/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1418.5782 - mae: 1418.5782 - val_loss: 1550.8313 - val_mae: 1550.8313\n",
      "Epoch 306/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1415.7068 - mae: 1415.7068 - val_loss: 1574.1166 - val_mae: 1574.1166\n",
      "Epoch 307/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1418.3026 - mae: 1418.3026 - val_loss: 1554.5065 - val_mae: 1554.5065\n",
      "Epoch 308/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1417.5979 - mae: 1417.5979 - val_loss: 1531.6412 - val_mae: 1531.6412\n",
      "Epoch 309/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1417.4004 - mae: 1417.4004 - val_loss: 1618.2634 - val_mae: 1618.2634\n",
      "Epoch 310/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1418.6819 - mae: 1418.6819 - val_loss: 1533.4514 - val_mae: 1533.4514\n",
      "Epoch 311/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1417.1166 - mae: 1417.1166 - val_loss: 1542.1213 - val_mae: 1542.1213\n",
      "Epoch 312/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1416.9106 - mae: 1416.9106 - val_loss: 1538.1871 - val_mae: 1538.1871\n",
      "Epoch 313/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1419.0350 - mae: 1419.0350 - val_loss: 1525.7266 - val_mae: 1525.7266\n",
      "Epoch 314/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1416.8309 - mae: 1416.8309 - val_loss: 1535.5035 - val_mae: 1535.5035\n",
      "Epoch 315/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1415.3909 - mae: 1415.3909 - val_loss: 1544.8521 - val_mae: 1544.8521\n",
      "Epoch 316/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1417.3385 - mae: 1417.3385 - val_loss: 1549.3922 - val_mae: 1549.3922\n",
      "Epoch 317/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1418.3307 - mae: 1418.3307 - val_loss: 1528.6643 - val_mae: 1528.6643\n",
      "Epoch 318/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1417.8634 - mae: 1417.8634 - val_loss: 1575.4846 - val_mae: 1575.4846\n",
      "Epoch 319/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1419.3685 - mae: 1419.3685 - val_loss: 1540.3776 - val_mae: 1540.3776\n",
      "Epoch 320/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1417.5944 - mae: 1417.5944 - val_loss: 1577.2202 - val_mae: 1577.2202\n",
      "Epoch 321/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1415.3527 - mae: 1415.3527 - val_loss: 1529.9084 - val_mae: 1529.9084\n",
      "Epoch 322/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1417.0316 - mae: 1417.0316 - val_loss: 1530.5596 - val_mae: 1530.5596\n",
      "Epoch 323/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1416.3728 - mae: 1416.3728 - val_loss: 1550.3114 - val_mae: 1550.3114\n",
      "Epoch 324/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1412.2081 - mae: 1412.2081 - val_loss: 1553.9138 - val_mae: 1553.9138\n",
      "Epoch 325/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1417.8079 - mae: 1417.8079 - val_loss: 1562.5002 - val_mae: 1562.5002\n",
      "Epoch 326/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1415.2961 - mae: 1415.2961 - val_loss: 1544.2854 - val_mae: 1544.2854\n",
      "Epoch 327/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1418.9868 - mae: 1418.9868 - val_loss: 1598.1807 - val_mae: 1598.1807\n",
      "Epoch 328/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1415.5632 - mae: 1415.5632 - val_loss: 1520.8649 - val_mae: 1520.8649\n",
      "Epoch 329/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1430.2543 - mae: 1430.2543 - val_loss: 1592.0568 - val_mae: 1592.0568\n",
      "Epoch 330/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1434.8905 - mae: 1434.8905 - val_loss: 1526.6804 - val_mae: 1526.6804\n",
      "Epoch 331/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1432.6697 - mae: 1432.6697 - val_loss: 1520.3320 - val_mae: 1520.3320\n",
      "Epoch 332/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1431.8484 - mae: 1431.8484 - val_loss: 1540.1110 - val_mae: 1540.1110\n",
      "Epoch 333/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1430.7966 - mae: 1430.7966 - val_loss: 1534.8358 - val_mae: 1534.8358\n",
      "Epoch 334/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1428.6682 - mae: 1428.6682 - val_loss: 1530.9611 - val_mae: 1530.9611\n",
      "Epoch 335/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1430.9873 - mae: 1430.9873 - val_loss: 1515.8745 - val_mae: 1515.8745\n",
      "Epoch 336/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1429.3861 - mae: 1429.3861 - val_loss: 1541.3116 - val_mae: 1541.3116\n",
      "Epoch 337/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1427.1311 - mae: 1427.1311 - val_loss: 1591.9869 - val_mae: 1591.9869\n",
      "Epoch 338/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1425.4849 - mae: 1425.4849 - val_loss: 1528.4486 - val_mae: 1528.4486\n",
      "Epoch 339/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1419.3640 - mae: 1419.3640 - val_loss: 1524.6249 - val_mae: 1524.6249\n",
      "Epoch 340/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1415.1074 - mae: 1415.1074 - val_loss: 1543.3348 - val_mae: 1543.3348\n",
      "Epoch 341/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1417.2118 - mae: 1417.2118 - val_loss: 1544.6533 - val_mae: 1544.6533\n",
      "Epoch 342/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1414.7758 - mae: 1414.7758 - val_loss: 1574.7081 - val_mae: 1574.7081\n",
      "Epoch 343/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1416.2379 - mae: 1416.2379 - val_loss: 1574.1241 - val_mae: 1574.1241\n",
      "Epoch 344/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1421.0532 - mae: 1421.0532 - val_loss: 1527.6587 - val_mae: 1527.6587\n",
      "Epoch 345/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1416.6493 - mae: 1416.6493 - val_loss: 1525.7094 - val_mae: 1525.7094\n",
      "Epoch 346/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1415.6335 - mae: 1415.6335 - val_loss: 1513.6105 - val_mae: 1513.6105\n",
      "Epoch 347/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1413.9058 - mae: 1413.9058 - val_loss: 1526.5746 - val_mae: 1526.5746\n",
      "Epoch 348/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1415.9615 - mae: 1415.9615 - val_loss: 1554.6880 - val_mae: 1554.6880\n",
      "Epoch 349/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1413.7755 - mae: 1413.7755 - val_loss: 1527.6331 - val_mae: 1527.6331\n",
      "Epoch 350/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1415.0723 - mae: 1415.0723 - val_loss: 1559.1335 - val_mae: 1559.1335\n",
      "Epoch 351/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1414.4800 - mae: 1414.4800 - val_loss: 1550.2336 - val_mae: 1550.2336\n",
      "Epoch 352/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1415.1985 - mae: 1415.1985 - val_loss: 1568.5436 - val_mae: 1568.5436\n",
      "Epoch 353/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1411.3334 - mae: 1411.3334 - val_loss: 1524.9598 - val_mae: 1524.9598\n",
      "Epoch 354/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1416.2266 - mae: 1416.2266 - val_loss: 1530.0681 - val_mae: 1530.0681\n",
      "Epoch 355/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1413.6565 - mae: 1413.6565 - val_loss: 1543.1140 - val_mae: 1543.1140\n",
      "Epoch 356/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1416.1588 - mae: 1416.1588 - val_loss: 1537.9087 - val_mae: 1537.9087\n",
      "Epoch 357/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1411.1779 - mae: 1411.1779 - val_loss: 1516.8188 - val_mae: 1516.8188\n",
      "Epoch 358/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1414.0776 - mae: 1414.0776 - val_loss: 1563.6936 - val_mae: 1563.6936\n",
      "Epoch 359/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1415.4274 - mae: 1415.4274 - val_loss: 1540.2970 - val_mae: 1540.2970\n",
      "Epoch 360/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1412.9230 - mae: 1412.9230 - val_loss: 1522.4406 - val_mae: 1522.4406\n",
      "Epoch 361/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1411.9374 - mae: 1411.9374 - val_loss: 1531.2310 - val_mae: 1531.2310\n",
      "Epoch 362/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1413.8176 - mae: 1413.8176 - val_loss: 1542.8398 - val_mae: 1542.8398\n",
      "Epoch 363/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1414.7123 - mae: 1414.7123 - val_loss: 1529.3428 - val_mae: 1529.3428\n",
      "Epoch 364/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1415.6725 - mae: 1415.6725 - val_loss: 1525.5272 - val_mae: 1525.5272\n",
      "Epoch 365/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1414.5630 - mae: 1414.5630 - val_loss: 1549.4169 - val_mae: 1549.4169\n",
      "Epoch 366/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1413.8049 - mae: 1413.8049 - val_loss: 1573.2368 - val_mae: 1573.2368\n",
      "Epoch 367/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1417.1454 - mae: 1417.1454 - val_loss: 1579.3663 - val_mae: 1579.3663\n",
      "Epoch 368/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1412.6874 - mae: 1412.6874 - val_loss: 1559.0978 - val_mae: 1559.0978\n",
      "Epoch 369/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1414.1249 - mae: 1414.1249 - val_loss: 1548.1660 - val_mae: 1548.1660\n",
      "Epoch 370/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1413.0292 - mae: 1413.0292 - val_loss: 1523.3619 - val_mae: 1523.3619\n",
      "Epoch 371/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1409.7806 - mae: 1409.7806 - val_loss: 1536.5530 - val_mae: 1536.5530\n",
      "Epoch 372/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1412.2560 - mae: 1412.2560 - val_loss: 1514.9734 - val_mae: 1514.9734\n",
      "Epoch 373/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1411.8391 - mae: 1411.8391 - val_loss: 1543.2209 - val_mae: 1543.2209\n",
      "Epoch 374/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1411.5898 - mae: 1411.5898 - val_loss: 1557.0243 - val_mae: 1557.0243\n",
      "Epoch 375/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1413.1975 - mae: 1413.1975 - val_loss: 1535.1812 - val_mae: 1535.1812\n",
      "Epoch 376/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1413.0559 - mae: 1413.0559 - val_loss: 1542.2522 - val_mae: 1542.2522\n",
      "Epoch 377/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1411.2372 - mae: 1411.2372 - val_loss: 1527.1998 - val_mae: 1527.1998\n",
      "Epoch 378/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1410.5822 - mae: 1410.5822 - val_loss: 1541.8271 - val_mae: 1541.8271\n",
      "Epoch 379/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1411.2860 - mae: 1411.2860 - val_loss: 1540.9634 - val_mae: 1540.9634\n",
      "Epoch 380/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1412.3605 - mae: 1412.3605 - val_loss: 1537.5197 - val_mae: 1537.5197\n",
      "Epoch 381/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1409.7240 - mae: 1409.7240 - val_loss: 1531.0289 - val_mae: 1531.0289\n",
      "Epoch 382/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1412.6105 - mae: 1412.6105 - val_loss: 1541.8730 - val_mae: 1541.8730\n",
      "Epoch 383/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1411.4724 - mae: 1411.4724 - val_loss: 1532.5834 - val_mae: 1532.5834\n",
      "Epoch 384/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1408.5880 - mae: 1408.5880 - val_loss: 1527.1382 - val_mae: 1527.1382\n",
      "Epoch 385/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1411.2494 - mae: 1411.2494 - val_loss: 1524.8258 - val_mae: 1524.8258\n",
      "Epoch 386/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1410.0920 - mae: 1410.0920 - val_loss: 1535.8397 - val_mae: 1535.8397\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 2ms/step - loss: 1413.1927 - mae: 1413.1927 - val_loss: 1532.9243 - val_mae: 1532.9243\n",
      "Epoch 388/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1412.9188 - mae: 1412.9188 - val_loss: 1543.7865 - val_mae: 1543.7865\n",
      "Epoch 389/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1410.9899 - mae: 1410.9899 - val_loss: 1530.6926 - val_mae: 1530.6926\n",
      "Epoch 390/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1410.6324 - mae: 1410.6324 - val_loss: 1546.7623 - val_mae: 1546.7623\n",
      "Epoch 391/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1410.1985 - mae: 1410.1985 - val_loss: 1530.8367 - val_mae: 1530.8367\n",
      "Epoch 392/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1409.3412 - mae: 1409.3412 - val_loss: 1567.8539 - val_mae: 1567.8539\n",
      "Epoch 393/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1411.4535 - mae: 1411.4535 - val_loss: 1533.8829 - val_mae: 1533.8829\n",
      "Epoch 394/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1412.1776 - mae: 1412.1776 - val_loss: 1542.6957 - val_mae: 1542.6957\n",
      "Epoch 395/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1407.6804 - mae: 1407.6804 - val_loss: 1518.7177 - val_mae: 1518.7177\n",
      "Epoch 396/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1408.2316 - mae: 1408.2316 - val_loss: 1530.8578 - val_mae: 1530.8578\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"base_model.h5\", save_best_only=True)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=x_train_scaled.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=keras.losses.mean_absolute_error,\n",
    "             optimizer=keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(x_train_scaled,y_train,\n",
    "                   epochs=1000,\n",
    "                   validation_data=(x_test_scaled,y_test),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7509158955070299\n",
      "0.7569301968602313\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_pred_test = model.predict(x_test_scaled)\n",
    "y_pred_train = model.predict(x_train_scaled)\n",
    "print(r2_score(y_test, y_pred_test))\n",
    "print(r2_score(y_train, y_pred_train ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 4799.1562 - mae: 4799.1562 - val_loss: 11250.6436 - val_mae: 11250.6436\n",
      "Epoch 2/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2300.7959 - mae: 2300.7959 - val_loss: 17640.4707 - val_mae: 17640.4707\n",
      "Epoch 3/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2228.7217 - mae: 2228.7217 - val_loss: 4249.5679 - val_mae: 4249.5679\n",
      "Epoch 4/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2212.3518 - mae: 2212.3518 - val_loss: 5563.2651 - val_mae: 5563.2651\n",
      "Epoch 5/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2151.7642 - mae: 2151.7642 - val_loss: 6350.1890 - val_mae: 6350.1890\n",
      "Epoch 6/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2236.7273 - mae: 2236.7273 - val_loss: 3059.9775 - val_mae: 3059.9775\n",
      "Epoch 7/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2111.7046 - mae: 2111.7046 - val_loss: 9279.2061 - val_mae: 9279.2061\n",
      "Epoch 8/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2143.0425 - mae: 2143.0425 - val_loss: 2542.8950 - val_mae: 2542.8950\n",
      "Epoch 9/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1996.9320 - mae: 1996.9320 - val_loss: 3134.8896 - val_mae: 3134.8896\n",
      "Epoch 10/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2061.8489 - mae: 2061.8489 - val_loss: 3364.2549 - val_mae: 3364.2549\n",
      "Epoch 11/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2035.6938 - mae: 2035.6938 - val_loss: 7692.7153 - val_mae: 7692.7153\n",
      "Epoch 12/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2046.5399 - mae: 2046.5399 - val_loss: 3594.6982 - val_mae: 3594.6982\n",
      "Epoch 13/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1959.7855 - mae: 1959.7855 - val_loss: 6538.9585 - val_mae: 6538.9585\n",
      "Epoch 14/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2091.0112 - mae: 2091.0112 - val_loss: 7808.5698 - val_mae: 7808.5698\n",
      "Epoch 15/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2014.7422 - mae: 2014.7422 - val_loss: 5176.3022 - val_mae: 5176.3022\n",
      "Epoch 16/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1992.6277 - mae: 1992.6277 - val_loss: 4349.9629 - val_mae: 4349.9629\n",
      "Epoch 17/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1944.4686 - mae: 1944.4686 - val_loss: 5243.9351 - val_mae: 5243.9351\n",
      "Epoch 18/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1892.6018 - mae: 1892.6018 - val_loss: 13165.3955 - val_mae: 13165.3955\n",
      "Epoch 19/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1968.1119 - mae: 1968.1119 - val_loss: 4755.6792 - val_mae: 4755.6792\n",
      "Epoch 20/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1926.5925 - mae: 1926.5925 - val_loss: 4525.0835 - val_mae: 4525.0835\n",
      "Epoch 21/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1897.9072 - mae: 1897.9072 - val_loss: 4382.4756 - val_mae: 4382.4756\n",
      "Epoch 22/1000\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 1963.1943 - mae: 1963.1943 - val_loss: 4692.6660 - val_mae: 4692.6660\n",
      "Epoch 23/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1897.2100 - mae: 1897.2100 - val_loss: 3338.1846 - val_mae: 3338.1846\n",
      "Epoch 24/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1864.2910 - mae: 1864.2910 - val_loss: 4999.1748 - val_mae: 4999.1748\n",
      "Epoch 25/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1920.2203 - mae: 1920.2203 - val_loss: 3825.1187 - val_mae: 3825.1187\n",
      "Epoch 26/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1847.0720 - mae: 1847.0720 - val_loss: 2729.8843 - val_mae: 2729.8843\n",
      "Epoch 27/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1837.6145 - mae: 1837.6145 - val_loss: 4234.4844 - val_mae: 4234.4844\n",
      "Epoch 28/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1848.2313 - mae: 1848.2313 - val_loss: 5488.8843 - val_mae: 5488.8843\n",
      "Epoch 29/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1973.0858 - mae: 1973.0858 - val_loss: 2387.4216 - val_mae: 2387.4216\n",
      "Epoch 30/1000\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 1857.7620 - mae: 1857.7620 - val_loss: 3596.2275 - val_mae: 3596.2275\n",
      "Epoch 31/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1800.0619 - mae: 1800.0619 - val_loss: 5934.9766 - val_mae: 5934.9766\n",
      "Epoch 32/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1818.5134 - mae: 1818.5134 - val_loss: 8399.7979 - val_mae: 8399.7979\n",
      "Epoch 33/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1805.3369 - mae: 1805.3369 - val_loss: 3519.4099 - val_mae: 3519.4099\n",
      "Epoch 34/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1726.5962 - mae: 1726.5962 - val_loss: 3654.4961 - val_mae: 3654.4961\n",
      "Epoch 35/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1785.6613 - mae: 1785.6613 - val_loss: 2480.8599 - val_mae: 2480.8599\n",
      "Epoch 36/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1775.8898 - mae: 1775.8898 - val_loss: 6974.9116 - val_mae: 6974.9116\n",
      "Epoch 37/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1710.6647 - mae: 1710.6647 - val_loss: 2994.4355 - val_mae: 2994.4355\n",
      "Epoch 38/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1701.8307 - mae: 1701.8307 - val_loss: 2724.3950 - val_mae: 2724.3950\n",
      "Epoch 39/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1704.4301 - mae: 1704.4301 - val_loss: 7318.1934 - val_mae: 7318.1934\n",
      "Epoch 40/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1701.2510 - mae: 1701.2510 - val_loss: 4134.4995 - val_mae: 4134.4995\n",
      "Epoch 41/1000\n",
      "268/268 [==============================] - 23s 85ms/step - loss: 1850.5188 - mae: 1850.5188 - val_loss: 6506.2295 - val_mae: 6506.2295\n",
      "Epoch 42/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1788.9509 - mae: 1788.9509 - val_loss: 8687.7617 - val_mae: 8687.7617\n",
      "Epoch 43/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1751.6638 - mae: 1751.6638 - val_loss: 1697.0441 - val_mae: 1697.0441\n",
      "Epoch 44/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1737.2502 - mae: 1737.2502 - val_loss: 1905.9370 - val_mae: 1905.9370\n",
      "Epoch 45/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1718.3210 - mae: 1718.3210 - val_loss: 3728.7104 - val_mae: 3728.7104\n",
      "Epoch 46/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1771.2458 - mae: 1771.2458 - val_loss: 3588.9688 - val_mae: 3588.9688\n",
      "Epoch 47/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1699.3533 - mae: 1699.3533 - val_loss: 5087.3145 - val_mae: 5087.3145\n",
      "Epoch 48/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1719.9940 - mae: 1719.9940 - val_loss: 4239.7017 - val_mae: 4239.7017\n",
      "Epoch 49/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1710.2798 - mae: 1710.2798 - val_loss: 2184.9822 - val_mae: 2184.9822\n",
      "Epoch 50/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1660.4653 - mae: 1660.4653 - val_loss: 3712.7776 - val_mae: 3712.7776\n",
      "Epoch 51/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1691.4717 - mae: 1691.4717 - val_loss: 5011.1289 - val_mae: 5011.1289\n",
      "Epoch 52/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1694.1969 - mae: 1694.1969 - val_loss: 4339.2314 - val_mae: 4339.2314\n",
      "Epoch 53/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1689.1647 - mae: 1689.1647 - val_loss: 3845.3765 - val_mae: 3845.3765\n",
      "Epoch 54/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1667.3611 - mae: 1667.3611 - val_loss: 6174.2563 - val_mae: 6174.2563\n",
      "Epoch 55/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1659.8123 - mae: 1659.8123 - val_loss: 3892.5977 - val_mae: 3892.5977\n",
      "Epoch 56/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1745.3119 - mae: 1745.3119 - val_loss: 2295.9307 - val_mae: 2295.9307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1639.3143 - mae: 1639.3143 - val_loss: 3170.5813 - val_mae: 3170.5813\n",
      "Epoch 58/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1776.1847 - mae: 1776.1847 - val_loss: 9223.5303 - val_mae: 9223.5303\n",
      "Epoch 59/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1751.4941 - mae: 1751.4941 - val_loss: 3012.0630 - val_mae: 3012.0630\n",
      "Epoch 60/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1631.0178 - mae: 1631.0178 - val_loss: 3160.8274 - val_mae: 3160.8274\n",
      "Epoch 61/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1644.6932 - mae: 1644.6932 - val_loss: 2091.7441 - val_mae: 2091.7441\n",
      "Epoch 62/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1619.6465 - mae: 1619.6465 - val_loss: 2240.9666 - val_mae: 2240.9666\n",
      "Epoch 63/1000\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 1628.5133 - mae: 1628.5133 - val_loss: 2855.3655 - val_mae: 2855.3655\n",
      "Epoch 64/1000\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 1674.9171 - mae: 1674.9171 - val_loss: 5403.8267 - val_mae: 5403.8267\n",
      "Epoch 65/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1648.1104 - mae: 1648.1104 - val_loss: 2616.2720 - val_mae: 2616.2720\n",
      "Epoch 66/1000\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 1661.7120 - mae: 1661.7120 - val_loss: 3064.0488 - val_mae: 3064.0488\n",
      "Epoch 67/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1591.6389 - mae: 1591.6389 - val_loss: 4141.1460 - val_mae: 4141.1460\n",
      "Epoch 68/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1581.5533 - mae: 1581.5533 - val_loss: 8856.2822 - val_mae: 8856.2822\n",
      "Epoch 69/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1645.7579 - mae: 1645.7579 - val_loss: 3029.7390 - val_mae: 3029.7390\n",
      "Epoch 70/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1588.2117 - mae: 1588.2117 - val_loss: 2332.1265 - val_mae: 2332.1265\n",
      "Epoch 71/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1592.7715 - mae: 1592.7715 - val_loss: 1912.1213 - val_mae: 1912.1213\n",
      "Epoch 72/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1616.1211 - mae: 1616.1211 - val_loss: 3568.2102 - val_mae: 3568.2102\n",
      "Epoch 73/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1686.5209 - mae: 1686.5209 - val_loss: 6138.7842 - val_mae: 6138.7842\n",
      "Epoch 74/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1616.7723 - mae: 1616.7723 - val_loss: 2102.8323 - val_mae: 2102.8323\n",
      "Epoch 75/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1598.1154 - mae: 1598.1154 - val_loss: 6053.4546 - val_mae: 6053.4546\n",
      "Epoch 76/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1617.4126 - mae: 1617.4126 - val_loss: 4904.3955 - val_mae: 4904.3955\n",
      "Epoch 77/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1597.7228 - mae: 1597.7228 - val_loss: 3581.5332 - val_mae: 3581.5332\n",
      "Epoch 78/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1584.3872 - mae: 1584.3872 - val_loss: 3088.8218 - val_mae: 3088.8218\n",
      "Epoch 79/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1586.3572 - mae: 1586.3572 - val_loss: 3932.3440 - val_mae: 3932.3440\n",
      "Epoch 80/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1581.4326 - mae: 1581.4326 - val_loss: 3457.7095 - val_mae: 3457.7095\n",
      "Epoch 81/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1560.3909 - mae: 1560.3909 - val_loss: 2784.3230 - val_mae: 2784.3230\n",
      "Epoch 82/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1558.0554 - mae: 1558.0554 - val_loss: 1454.5480 - val_mae: 1454.5480\n",
      "Epoch 83/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1521.1678 - mae: 1521.1678 - val_loss: 1984.7852 - val_mae: 1984.7852\n",
      "Epoch 84/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1569.1899 - mae: 1569.1899 - val_loss: 4175.2578 - val_mae: 4175.2578\n",
      "Epoch 85/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1587.2090 - mae: 1587.2090 - val_loss: 3701.8181 - val_mae: 3701.8181\n",
      "Epoch 86/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1544.4679 - mae: 1544.4679 - val_loss: 29896.9414 - val_mae: 29896.9414\n",
      "Epoch 87/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 2951.9060 - mae: 2951.9060 - val_loss: 3747.1365 - val_mae: 3747.1365\n",
      "Epoch 88/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1713.3253 - mae: 1713.3253 - val_loss: 3599.6157 - val_mae: 3599.6157\n",
      "Epoch 89/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1684.0715 - mae: 1684.0715 - val_loss: 1716.4368 - val_mae: 1716.4368\n",
      "Epoch 90/1000\n",
      "268/268 [==============================] - 3s 12ms/step - loss: 1647.2327 - mae: 1647.2327 - val_loss: 2891.4485 - val_mae: 2891.4485\n",
      "Epoch 91/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1657.9161 - mae: 1657.9161 - val_loss: 3591.4404 - val_mae: 3591.4404\n",
      "Epoch 92/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1641.1851 - mae: 1641.1851 - val_loss: 3621.7122 - val_mae: 3621.7122\n",
      "Epoch 93/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1625.6765 - mae: 1625.6765 - val_loss: 3090.0339 - val_mae: 3090.0339\n",
      "Epoch 94/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1608.5769 - mae: 1608.5769 - val_loss: 2072.1716 - val_mae: 2072.1716\n",
      "Epoch 95/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1574.8903 - mae: 1574.8903 - val_loss: 6239.6743 - val_mae: 6239.6743\n",
      "Epoch 96/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1565.3907 - mae: 1565.3907 - val_loss: 6178.5508 - val_mae: 6178.5508\n",
      "Epoch 97/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1603.1631 - mae: 1603.1631 - val_loss: 5048.4453 - val_mae: 5048.4453\n",
      "Epoch 98/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1570.3981 - mae: 1570.3981 - val_loss: 1665.1110 - val_mae: 1665.1110\n",
      "Epoch 99/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1565.5974 - mae: 1565.5974 - val_loss: 2468.1763 - val_mae: 2468.1763\n",
      "Epoch 100/1000\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 1539.8745 - mae: 1539.8745 - val_loss: 2214.7041 - val_mae: 2214.7041\n",
      "Epoch 101/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1554.7892 - mae: 1554.7892 - val_loss: 3901.7324 - val_mae: 3901.7324\n",
      "Epoch 102/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1564.6422 - mae: 1564.6422 - val_loss: 2348.2246 - val_mae: 2348.2246\n",
      "Epoch 103/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1553.6731 - mae: 1553.6731 - val_loss: 2158.3286 - val_mae: 2158.3286\n",
      "Epoch 104/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1541.5238 - mae: 1541.5238 - val_loss: 8620.0498 - val_mae: 8620.0498\n",
      "Epoch 105/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1583.2605 - mae: 1583.2605 - val_loss: 2789.6506 - val_mae: 2789.6506\n",
      "Epoch 106/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1562.8175 - mae: 1562.8175 - val_loss: 1549.8470 - val_mae: 1549.8470\n",
      "Epoch 107/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1501.4462 - mae: 1501.4462 - val_loss: 2150.1658 - val_mae: 2150.1658\n",
      "Epoch 108/1000\n",
      "268/268 [==============================] - 4s 13ms/step - loss: 1543.0013 - mae: 1543.0013 - val_loss: 5236.9624 - val_mae: 5236.9624\n",
      "Epoch 109/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1531.1846 - mae: 1531.1846 - val_loss: 3619.5828 - val_mae: 3619.5828\n",
      "Epoch 110/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1610.2054 - mae: 1610.2054 - val_loss: 4025.3701 - val_mae: 4025.3701\n",
      "Epoch 111/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1667.1176 - mae: 1667.1176 - val_loss: 2643.0190 - val_mae: 2643.0190\n",
      "Epoch 112/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1571.9918 - mae: 1571.9918 - val_loss: 2070.5449 - val_mae: 2070.5449\n",
      "Epoch 113/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1546.9668 - mae: 1546.9668 - val_loss: 2711.7471 - val_mae: 2711.7471\n",
      "Epoch 114/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1590.6899 - mae: 1590.6899 - val_loss: 1908.2429 - val_mae: 1908.2429\n",
      "Epoch 115/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1554.3130 - mae: 1554.3130 - val_loss: 2802.1682 - val_mae: 2802.1682\n",
      "Epoch 116/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1583.4470 - mae: 1583.4470 - val_loss: 2092.5991 - val_mae: 2092.5991\n",
      "Epoch 117/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1520.9413 - mae: 1520.9413 - val_loss: 3252.7163 - val_mae: 3252.7163\n",
      "Epoch 118/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1581.3387 - mae: 1581.3387 - val_loss: 2617.2190 - val_mae: 2617.2190\n",
      "Epoch 119/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1527.6769 - mae: 1527.6769 - val_loss: 2807.9504 - val_mae: 2807.9504\n",
      "Epoch 120/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1545.8070 - mae: 1545.8070 - val_loss: 3983.2788 - val_mae: 3983.2788\n",
      "Epoch 121/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1567.6523 - mae: 1567.6523 - val_loss: 2602.8013 - val_mae: 2602.8013\n",
      "Epoch 122/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1495.1370 - mae: 1495.1370 - val_loss: 3081.5808 - val_mae: 3081.5808\n",
      "Epoch 123/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1533.1248 - mae: 1533.1248 - val_loss: 2653.8103 - val_mae: 2653.8103\n",
      "Epoch 124/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1524.1700 - mae: 1524.1700 - val_loss: 2743.2798 - val_mae: 2743.2798\n",
      "Epoch 125/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1544.6277 - mae: 1544.6277 - val_loss: 3491.3843 - val_mae: 3491.3843\n",
      "Epoch 126/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1521.0518 - mae: 1521.0518 - val_loss: 7009.0229 - val_mae: 7009.0229\n",
      "Epoch 127/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1512.1409 - mae: 1512.1409 - val_loss: 8659.6367 - val_mae: 8659.6367\n",
      "Epoch 128/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1513.3900 - mae: 1513.3900 - val_loss: 2274.4573 - val_mae: 2274.4573\n",
      "Epoch 129/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1504.5970 - mae: 1504.5970 - val_loss: 2279.8574 - val_mae: 2279.8574\n",
      "Epoch 130/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1482.9618 - mae: 1482.9618 - val_loss: 1802.3484 - val_mae: 1802.3484\n",
      "Epoch 131/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1479.0010 - mae: 1479.0010 - val_loss: 3398.2769 - val_mae: 3398.2769\n",
      "Epoch 132/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1494.9786 - mae: 1494.9786 - val_loss: 8619.0928 - val_mae: 8619.0928\n"
     ]
    }
   ],
   "source": [
    "# Lets complex the model\n",
    "input_ = keras.layers.Input(shape=x_test_scaled.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model1 = keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "checkpoint1 = keras.callbacks.ModelCheckpoint('model1.h5')\n",
    "# compile the model\n",
    "model1.compile(loss=keras.losses.mean_absolute_error,\n",
    "             optimizer=keras.optimizers.SGD(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "history1 = model1.fit(x_train_scaled,y_train,\n",
    "                     epochs=1000,\n",
    "                     validation_data=(x_test_scaled,y_test),\n",
    "                     callbacks=[early_stopping_cb, checkpoint1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.780109177279375\n",
      "0.7729449044024729\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_pred_test = model1.predict(x_test_scaled)\n",
    "y_pred_train = model1.predict(x_train_scaled)\n",
    "print(r2_score(y_test, y_pred_test))\n",
    "print(r2_score(y_train, y_pred_train ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets perform Randomized search cv\n",
    "\n",
    "def build_model(n_hidden=1, n_nuerons=30, learning_rate=3e-3, input_shape=x_train_scaled.shape[1:]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for i in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_nuerons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "# Lets use wrapper to wrap the function with scikit-learn\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 62523056.0000 - val_loss: 34802360.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 24288564.0000 - val_loss: 16300616.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 13338237.0000 - val_loss: 10783334.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 10020046.0000 - val_loss: 9128408.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8965796.0000 - val_loss: 8593032.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8626700.0000 - val_loss: 8438269.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8495542.0000 - val_loss: 8370288.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8438970.0000 - val_loss: 8336843.5000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8405340.0000 - val_loss: 8333279.5000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8386215.5000 - val_loss: 8315964.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8370936.5000 - val_loss: 8305235.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8358636.5000 - val_loss: 8297986.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8352619.5000 - val_loss: 8299847.5000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8344052.5000 - val_loss: 8286758.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8334792.0000 - val_loss: 8283343.5000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8331365.5000 - val_loss: 8274885.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8328001.0000 - val_loss: 8277254.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8323076.0000 - val_loss: 8285344.5000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8316885.0000 - val_loss: 8263620.5000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8315809.5000 - val_loss: 8262805.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8310688.5000 - val_loss: 8268883.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8308697.5000 - val_loss: 8280842.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8305932.0000 - val_loss: 8267548.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8303908.0000 - val_loss: 8269783.5000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8298264.5000 - val_loss: 8261235.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8297293.5000 - val_loss: 8253042.5000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8295355.5000 - val_loss: 8251753.5000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8295744.0000 - val_loss: 8255771.5000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8293817.5000 - val_loss: 8259887.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8291295.5000 - val_loss: 8253466.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8285549.0000 - val_loss: 8267626.5000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8288920.5000 - val_loss: 8256469.5000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8287307.5000 - val_loss: 8253730.5000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8283176.5000 - val_loss: 8241644.5000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8285336.0000 - val_loss: 8248472.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8280024.5000 - val_loss: 8245620.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8281003.0000 - val_loss: 8252590.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8272450.0000 - val_loss: 8246973.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8281763.5000 - val_loss: 8250631.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8277060.5000 - val_loss: 8243099.5000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8277744.5000 - val_loss: 8238939.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8277458.0000 - val_loss: 8245480.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8273691.5000 - val_loss: 8253676.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8270785.0000 - val_loss: 8248769.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8273835.0000 - val_loss: 8235671.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8272141.0000 - val_loss: 8234546.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8271194.5000 - val_loss: 8224691.5000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8268247.0000 - val_loss: 8230952.5000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8268160.5000 - val_loss: 8217069.5000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8266805.5000 - val_loss: 8233862.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8269347.5000 - val_loss: 8222159.5000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8266697.5000 - val_loss: 8230780.5000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8265278.5000 - val_loss: 8230566.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8263287.0000 - val_loss: 8246052.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8267932.0000 - val_loss: 8229934.5000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8265549.5000 - val_loss: 8221596.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8261909.5000 - val_loss: 8236633.5000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8261203.5000 - val_loss: 8236844.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8264393.5000 - val_loss: 8231115.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8262427.0000 - val_loss: 8230660.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8262007.0000 - val_loss: 8215376.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8263196.5000 - val_loss: 8213194.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8258409.5000 - val_loss: 8211854.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8259282.0000 - val_loss: 8222841.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8260145.0000 - val_loss: 8221937.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8258497.5000 - val_loss: 8221100.5000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8259490.0000 - val_loss: 8231973.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8256715.5000 - val_loss: 8227259.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8258253.0000 - val_loss: 8227679.5000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8256624.5000 - val_loss: 8207308.5000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8254074.5000 - val_loss: 8214051.5000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8259176.0000 - val_loss: 8221389.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8258748.0000 - val_loss: 8229559.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8258467.5000 - val_loss: 8234236.5000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8257980.0000 - val_loss: 8221191.5000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8255439.0000 - val_loss: 8215097.5000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8252346.5000 - val_loss: 8224564.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8258310.0000 - val_loss: 8225912.5000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8258372.5000 - val_loss: 8217157.5000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8250712.5000 - val_loss: 8213074.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8253531.5000 - val_loss: 8220884.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8255180.5000 - val_loss: 8214595.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8256060.0000 - val_loss: 8221274.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8250951.0000 - val_loss: 8211778.5000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8255992.0000 - val_loss: 8203365.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8254233.5000 - val_loss: 8210397.5000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8253174.5000 - val_loss: 8227224.5000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8255267.0000 - val_loss: 8227518.5000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8251794.5000 - val_loss: 8217566.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8255188.5000 - val_loss: 8216827.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8255865.0000 - val_loss: 8210479.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8253600.5000 - val_loss: 8210095.5000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8250213.0000 - val_loss: 8199238.5000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8254525.0000 - val_loss: 8212208.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8254597.0000 - val_loss: 8206499.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8252965.5000 - val_loss: 8213697.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8243655.0000 - val_loss: 8230957.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8254661.0000 - val_loss: 8205259.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8252400.5000 - val_loss: 8212936.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8254506.0000 - val_loss: 8219791.5000\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 6990226.5000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 62189584.0000 - val_loss: 35175000.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 24368930.0000 - val_loss: 16520387.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 13414296.0000 - val_loss: 10872562.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 10038968.0000 - val_loss: 9125713.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8981900.0000 - val_loss: 8596967.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8632725.0000 - val_loss: 8425188.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8507351.0000 - val_loss: 8371378.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8460178.0000 - val_loss: 8333326.5000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8430497.0000 - val_loss: 8324134.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8409894.0000 - val_loss: 8320002.5000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8397754.0000 - val_loss: 8309170.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8388515.0000 - val_loss: 8285201.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8378507.5000 - val_loss: 8267758.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8372450.5000 - val_loss: 8278470.5000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8366633.5000 - val_loss: 8276850.5000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8360986.0000 - val_loss: 8260620.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8359126.5000 - val_loss: 8252517.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8354236.5000 - val_loss: 8247161.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8349450.5000 - val_loss: 8243977.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8345739.0000 - val_loss: 8246709.5000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8342534.5000 - val_loss: 8248184.5000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8342069.0000 - val_loss: 8246482.5000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8338284.0000 - val_loss: 8233986.5000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8335967.5000 - val_loss: 8233013.5000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8334220.0000 - val_loss: 8248268.5000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8330884.0000 - val_loss: 8240609.5000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8330984.0000 - val_loss: 8230604.5000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8324174.0000 - val_loss: 8223702.5000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8325379.5000 - val_loss: 8225397.5000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8323200.0000 - val_loss: 8235181.5000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8320491.5000 - val_loss: 8226590.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8320101.5000 - val_loss: 8226920.5000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8319622.0000 - val_loss: 8225884.5000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8318023.5000 - val_loss: 8213982.5000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8315420.0000 - val_loss: 8223091.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8314058.5000 - val_loss: 8213308.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8313065.5000 - val_loss: 8225122.5000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8312841.0000 - val_loss: 8222887.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8311074.0000 - val_loss: 8222933.5000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8309454.0000 - val_loss: 8222137.5000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8309232.0000 - val_loss: 8221164.5000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8307099.5000 - val_loss: 8218288.5000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8309081.0000 - val_loss: 8214011.5000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8306663.5000 - val_loss: 8210018.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8303327.0000 - val_loss: 8200058.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8304694.0000 - val_loss: 8220325.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8303164.0000 - val_loss: 8203272.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8302464.5000 - val_loss: 8209594.5000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8293821.0000 - val_loss: 8209948.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8301302.0000 - val_loss: 8204127.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8301925.0000 - val_loss: 8204159.5000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8298988.5000 - val_loss: 8206130.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8296348.5000 - val_loss: 8197528.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8297436.0000 - val_loss: 8216994.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8297643.5000 - val_loss: 8203387.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8299470.5000 - val_loss: 8196636.5000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8294411.0000 - val_loss: 8208769.5000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8295725.0000 - val_loss: 8212309.5000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8297092.0000 - val_loss: 8201688.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8291660.0000 - val_loss: 8195107.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8295239.5000 - val_loss: 8204470.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8294925.0000 - val_loss: 8195545.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8293331.0000 - val_loss: 8189873.5000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8295314.5000 - val_loss: 8199439.5000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8291824.0000 - val_loss: 8207949.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8291406.5000 - val_loss: 8206310.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8293026.0000 - val_loss: 8199811.5000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8292720.5000 - val_loss: 8200147.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8290736.5000 - val_loss: 8195144.5000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8292651.5000 - val_loss: 8199877.5000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8289668.5000 - val_loss: 8210553.5000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8290322.5000 - val_loss: 8195972.5000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8290159.5000 - val_loss: 8190142.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8291888.0000 - val_loss: 8194725.5000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8288005.5000 - val_loss: 8188629.5000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8289533.5000 - val_loss: 8203223.5000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8294913.5000 - val_loss: 8186761.5000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8290652.5000 - val_loss: 8196542.5000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8288217.0000 - val_loss: 8196933.5000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8288292.5000 - val_loss: 8197347.5000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8287628.5000 - val_loss: 8193183.5000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8286536.0000 - val_loss: 8197593.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8274083.5000 - val_loss: 8207475.5000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8288060.5000 - val_loss: 8197583.5000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8288581.0000 - val_loss: 8205378.5000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8288029.0000 - val_loss: 8196336.5000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8286618.0000 - val_loss: 8196442.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8287898.5000 - val_loss: 8197410.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8288288.0000 - val_loss: 8202318.5000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8287392.5000 - val_loss: 8197084.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8285375.5000 - val_loss: 8184328.5000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8287827.5000 - val_loss: 8189341.5000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8286334.5000 - val_loss: 8190595.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8287473.0000 - val_loss: 8198777.5000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8288444.0000 - val_loss: 8193804.5000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8285596.0000 - val_loss: 8195558.5000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8286804.0000 - val_loss: 8191827.5000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8287967.0000 - val_loss: 8203253.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8286282.5000 - val_loss: 8199245.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8285331.0000 - val_loss: 8186029.5000\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 6853199.5000\n",
      "Epoch 1/100\n",
      "192/214 [=========================>....] - ETA: 0s - loss: 64140944.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 60841348.0000 - val_loss: 35404608.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 23562186.0000 - val_loss: 16727525.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 12761362.0000 - val_loss: 11039725.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9440530.0000 - val_loss: 9257456.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8391612.0000 - val_loss: 8708211.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8049517.0000 - val_loss: 8490407.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7924998.0000 - val_loss: 8415798.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7875441.5000 - val_loss: 8379655.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7849785.0000 - val_loss: 8357416.5000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7831947.0000 - val_loss: 8338043.5000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7817768.0000 - val_loss: 8346032.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7807090.0000 - val_loss: 8326669.5000\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 1s 2ms/step - loss: 7799280.0000 - val_loss: 8334996.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 7792600.0000 - val_loss: 8330925.5000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7788600.5000 - val_loss: 8317730.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7780884.5000 - val_loss: 8299069.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7776050.5000 - val_loss: 8298801.5000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7770556.5000 - val_loss: 8294500.5000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7769386.5000 - val_loss: 8295868.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7763955.0000 - val_loss: 8281504.5000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7762062.5000 - val_loss: 8283491.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7757185.5000 - val_loss: 8290398.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7753968.5000 - val_loss: 8283943.5000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7752472.0000 - val_loss: 8288976.5000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7749339.5000 - val_loss: 8275599.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7747882.0000 - val_loss: 8277397.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7746237.0000 - val_loss: 8275895.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7744243.5000 - val_loss: 8282569.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7742697.0000 - val_loss: 8270895.5000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7739169.5000 - val_loss: 8276184.5000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7738619.0000 - val_loss: 8263493.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7735181.5000 - val_loss: 8253400.5000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7734365.5000 - val_loss: 8259317.5000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7733857.0000 - val_loss: 8259112.5000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7730753.5000 - val_loss: 8256887.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 7731052.5000 - val_loss: 8263141.5000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7728587.0000 - val_loss: 8272960.5000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7726454.5000 - val_loss: 8255782.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7725833.0000 - val_loss: 8244679.5000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7724207.5000 - val_loss: 8262315.5000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7723404.0000 - val_loss: 8266150.5000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7722820.0000 - val_loss: 8248214.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7722250.5000 - val_loss: 8245781.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7720078.5000 - val_loss: 8249835.5000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7721264.5000 - val_loss: 8253753.5000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 7718733.0000 - val_loss: 8258930.5000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7719305.0000 - val_loss: 8246152.5000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7717598.5000 - val_loss: 8248995.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7717215.0000 - val_loss: 8250430.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7716170.0000 - val_loss: 8251925.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7716356.5000 - val_loss: 8243762.5000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7715650.5000 - val_loss: 8240621.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7713421.0000 - val_loss: 8248731.5000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7713627.0000 - val_loss: 8241875.5000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7711448.5000 - val_loss: 8235193.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7712425.5000 - val_loss: 8239979.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7711605.5000 - val_loss: 8245440.5000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7710578.5000 - val_loss: 8236724.5000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7710459.0000 - val_loss: 8244585.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7707744.5000 - val_loss: 8249781.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7710979.0000 - val_loss: 8244977.5000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7709136.0000 - val_loss: 8257164.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7707365.0000 - val_loss: 8258718.5000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7709127.5000 - val_loss: 8236671.5000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7706212.0000 - val_loss: 8238764.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7707717.5000 - val_loss: 8247476.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7707767.0000 - val_loss: 8246654.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7706998.0000 - val_loss: 8244997.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7706597.5000 - val_loss: 8231196.5000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7704326.5000 - val_loss: 8248832.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7705519.0000 - val_loss: 8236141.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7705192.0000 - val_loss: 8228433.5000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7706004.5000 - val_loss: 8234925.5000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7704190.0000 - val_loss: 8241494.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7705149.0000 - val_loss: 8228016.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7703681.0000 - val_loss: 8244691.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7704773.0000 - val_loss: 8244639.5000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7702593.5000 - val_loss: 8239231.5000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 7703932.5000 - val_loss: 8243372.5000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7702414.0000 - val_loss: 8234694.5000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7702610.5000 - val_loss: 8249087.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7703619.5000 - val_loss: 8237144.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7701758.0000 - val_loss: 8234241.5000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7701757.0000 - val_loss: 8249914.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7702705.0000 - val_loss: 8247161.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7701706.0000 - val_loss: 8241327.5000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7702174.0000 - val_loss: 8248275.5000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7702249.5000 - val_loss: 8235118.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7701637.0000 - val_loss: 8236017.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7700900.5000 - val_loss: 8235465.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7700190.5000 - val_loss: 8249780.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7700542.5000 - val_loss: 8227057.5000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7702043.5000 - val_loss: 8231134.5000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7700627.5000 - val_loss: 8236673.5000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7695658.5000 - val_loss: 8227061.5000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7700272.5000 - val_loss: 8235912.5000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7700298.0000 - val_loss: 8235411.5000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7699625.5000 - val_loss: 8221683.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7701680.0000 - val_loss: 8231065.5000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7699733.5000 - val_loss: 8244679.5000\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 9235804.0000\n",
      "Epoch 1/100\n",
      "198/214 [==========================>...] - ETA: 0s - loss: 63366992.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 61027504.0000 - val_loss: 35317056.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 23631826.0000 - val_loss: 16657042.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 12701117.0000 - val_loss: 10980632.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9324828.0000 - val_loss: 9227855.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8249811.5000 - val_loss: 8670606.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7896195.0000 - val_loss: 8506895.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7769010.5000 - val_loss: 8435179.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7714444.0000 - val_loss: 8403385.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7685375.5000 - val_loss: 8387154.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7666440.0000 - val_loss: 8372466.5000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7653029.5000 - val_loss: 8354166.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7642236.0000 - val_loss: 8357461.5000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7631433.5000 - val_loss: 8333632.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7624464.5000 - val_loss: 8325282.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7619733.0000 - val_loss: 8322644.5000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7614001.5000 - val_loss: 8314140.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7608791.5000 - val_loss: 8317739.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7605254.0000 - val_loss: 8313289.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7599310.5000 - val_loss: 8316034.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7597961.0000 - val_loss: 8312731.5000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 7595988.5000 - val_loss: 8305594.5000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 7591225.5000 - val_loss: 8298309.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7588674.5000 - val_loss: 8295300.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 7585495.0000 - val_loss: 8295190.5000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7583843.0000 - val_loss: 8299790.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7579427.0000 - val_loss: 8279350.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7580622.5000 - val_loss: 8290581.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7577966.5000 - val_loss: 8291308.5000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7573687.5000 - val_loss: 8305843.5000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7574205.0000 - val_loss: 8302150.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7571882.5000 - val_loss: 8279203.5000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7570967.0000 - val_loss: 8281306.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7569595.5000 - val_loss: 8280851.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7565308.0000 - val_loss: 8295940.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7567401.5000 - val_loss: 8275619.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7564929.0000 - val_loss: 8275564.5000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7562126.0000 - val_loss: 8271073.5000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7563342.5000 - val_loss: 8266263.5000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7560484.0000 - val_loss: 8261228.5000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7561070.0000 - val_loss: 8262878.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7560412.5000 - val_loss: 8262518.5000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7557404.5000 - val_loss: 8266683.5000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 7557860.0000 - val_loss: 8264470.5000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 7557356.5000 - val_loss: 8271531.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7555749.0000 - val_loss: 8273357.5000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7554897.0000 - val_loss: 8268276.5000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7554067.0000 - val_loss: 8261008.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7553894.5000 - val_loss: 8265134.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7551573.0000 - val_loss: 8267231.5000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7550910.5000 - val_loss: 8276558.5000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7550336.5000 - val_loss: 8261287.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7549755.0000 - val_loss: 8272434.5000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7548823.5000 - val_loss: 8274544.0000\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 1s 3ms/step - loss: 7548211.5000 - val_loss: 8271094.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7549320.5000 - val_loss: 8264632.5000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7548237.0000 - val_loss: 8260690.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7545550.5000 - val_loss: 8272606.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7546810.5000 - val_loss: 8255610.5000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7545869.0000 - val_loss: 8252863.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7545103.0000 - val_loss: 8259246.5000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7544323.5000 - val_loss: 8262512.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7544587.0000 - val_loss: 8266074.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7542932.5000 - val_loss: 8248250.5000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7544234.5000 - val_loss: 8243773.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7543403.0000 - val_loss: 8248195.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7542509.5000 - val_loss: 8241382.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7541104.0000 - val_loss: 8253929.5000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7543167.0000 - val_loss: 8254231.5000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7540723.0000 - val_loss: 8267139.5000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7541980.0000 - val_loss: 8257277.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7538833.0000 - val_loss: 8254266.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7542095.0000 - val_loss: 8254519.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7540244.5000 - val_loss: 8243245.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7539255.5000 - val_loss: 8261193.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 7541254.5000 - val_loss: 8254197.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7540101.5000 - val_loss: 8261876.5000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7539872.5000 - val_loss: 8250869.5000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7540561.5000 - val_loss: 8247693.5000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7540569.5000 - val_loss: 8247323.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7541047.5000 - val_loss: 8240615.5000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7539266.0000 - val_loss: 8247896.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7538437.5000 - val_loss: 8244629.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7540105.5000 - val_loss: 8244706.5000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7538642.0000 - val_loss: 8236218.5000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7536903.5000 - val_loss: 8252750.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 7538328.0000 - val_loss: 8245459.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 7538193.5000 - val_loss: 8246613.5000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7538438.5000 - val_loss: 8250398.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7539380.0000 - val_loss: 8239704.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7537623.5000 - val_loss: 8251413.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7536621.5000 - val_loss: 8238580.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7536821.5000 - val_loss: 8248694.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7536416.5000 - val_loss: 8249050.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7536801.0000 - val_loss: 8241177.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7537887.0000 - val_loss: 8243036.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7535561.5000 - val_loss: 8245414.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7536631.0000 - val_loss: 8234675.5000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7538067.0000 - val_loss: 8246098.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7538057.5000 - val_loss: 8250170.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7537397.5000 - val_loss: 8248180.5000\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 9930508.0000\n",
      "Epoch 1/100\n",
      "  1/214 [..............................] - ETA: 0s - loss: 121796672.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0040s). Check your callbacks.\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 61709336.0000 - val_loss: 35162512.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 24027524.0000 - val_loss: 16669597.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 13196005.0000 - val_loss: 11037410.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9869540.0000 - val_loss: 9299711.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8826317.0000 - val_loss: 8743490.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8488990.0000 - val_loss: 8557552.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8367042.5000 - val_loss: 8488265.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8317885.0000 - val_loss: 8459844.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8288848.5000 - val_loss: 8436656.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8271087.0000 - val_loss: 8430193.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8252380.0000 - val_loss: 8412908.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8250684.0000 - val_loss: 8405684.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8239132.0000 - val_loss: 8404809.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8227630.5000 - val_loss: 8389029.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8231017.5000 - val_loss: 8382397.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8215200.5000 - val_loss: 8373627.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8213426.5000 - val_loss: 8368402.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8213018.5000 - val_loss: 8363721.5000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8208968.0000 - val_loss: 8368731.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8205347.5000 - val_loss: 8352762.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8199190.0000 - val_loss: 8356445.5000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8197078.5000 - val_loss: 8356528.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8194375.0000 - val_loss: 8358638.5000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8190517.0000 - val_loss: 8354367.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8188245.0000 - val_loss: 8344677.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8189392.0000 - val_loss: 8349638.5000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8185880.5000 - val_loss: 8354401.5000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 8183369.5000 - val_loss: 8352659.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8178310.0000 - val_loss: 8341782.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8180932.0000 - val_loss: 8342475.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8178102.5000 - val_loss: 8339669.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8175543.5000 - val_loss: 8347928.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8169909.0000 - val_loss: 8333382.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8170634.5000 - val_loss: 8361771.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8169843.0000 - val_loss: 8342123.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8169873.5000 - val_loss: 8345019.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8166074.0000 - val_loss: 8345121.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8165003.5000 - val_loss: 8353530.5000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8168594.0000 - val_loss: 8335608.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8163620.5000 - val_loss: 8337516.5000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8162984.5000 - val_loss: 8327404.5000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8162004.0000 - val_loss: 8333185.5000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8163339.5000 - val_loss: 8338249.5000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8167708.5000 - val_loss: 8335847.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8159174.5000 - val_loss: 8346580.5000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8157994.0000 - val_loss: 8351607.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8158461.0000 - val_loss: 8338072.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8153959.0000 - val_loss: 8334965.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8158466.0000 - val_loss: 8327193.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8153140.0000 - val_loss: 8329498.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8150189.0000 - val_loss: 8334993.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8154058.0000 - val_loss: 8334283.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 8160481.5000 - val_loss: 8333284.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8153991.5000 - val_loss: 8329258.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8151640.0000 - val_loss: 8325952.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8152141.5000 - val_loss: 8322342.5000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8151285.0000 - val_loss: 8323134.5000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8147361.0000 - val_loss: 8338938.5000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8136828.0000 - val_loss: 8350739.5000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8145689.5000 - val_loss: 8348435.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8148488.0000 - val_loss: 8348395.5000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8148722.0000 - val_loss: 8342662.5000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8149258.5000 - val_loss: 8328869.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8148024.5000 - val_loss: 8331324.5000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8143280.0000 - val_loss: 8339906.5000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8147763.5000 - val_loss: 8330756.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8147740.5000 - val_loss: 8335834.5000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8145458.5000 - val_loss: 8325773.5000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8143361.0000 - val_loss: 8328788.5000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8145379.5000 - val_loss: 8329410.5000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8145087.5000 - val_loss: 8331743.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8141078.5000 - val_loss: 8332047.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8142866.0000 - val_loss: 8332004.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8144256.0000 - val_loss: 8331387.5000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8139246.5000 - val_loss: 8343066.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8141922.5000 - val_loss: 8345181.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8142116.5000 - val_loss: 8327096.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8142850.5000 - val_loss: 8323865.5000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8144398.0000 - val_loss: 8325568.5000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8144862.0000 - val_loss: 8318356.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8140703.5000 - val_loss: 8316317.5000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8140968.5000 - val_loss: 8321768.5000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8141641.0000 - val_loss: 8343099.5000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8139144.5000 - val_loss: 8347990.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8142779.5000 - val_loss: 8350638.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8141510.5000 - val_loss: 8340576.5000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8142070.5000 - val_loss: 8340047.5000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8141888.0000 - val_loss: 8327126.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8143143.5000 - val_loss: 8333009.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8138564.5000 - val_loss: 8324058.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8141529.0000 - val_loss: 8317880.5000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8141578.5000 - val_loss: 8327163.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8141909.5000 - val_loss: 8329363.5000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8137961.0000 - val_loss: 8351626.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8141124.0000 - val_loss: 8330919.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8140461.0000 - val_loss: 8325563.5000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8140395.0000 - val_loss: 8331564.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8138807.5000 - val_loss: 8335759.5000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8137801.5000 - val_loss: 8332344.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8141297.5000 - val_loss: 8320664.5000\n",
      " 1/54 [..............................] - ETA: 0s - loss: 3627151.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 7527830.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: inf - val_loss: 2012246929800104839915562806018048.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 918031032734485116905822273667072.0000 - val_loss: 312825049418589480042726074351616.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 142717638939382196223690317758464.0000 - val_loss: 48632039230031102832909200916480.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 22186992443350424123171300966400.0000 - val_loss: 7560368201447771786485736407040.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3449204389829792717791811338240.0000 - val_loss: 1175338309126139658259637731328.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 536215382733678063596238536704.0000 - val_loss: 182718748428488886537368371200.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 83360270965707140112689659904.0000 - val_loss: 28405539687674583012419305472.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 12959230258494848549498388480.0000 - val_loss: 4415941566529199675069693952.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2014647134484692660482211840.0000 - val_loss: 686504435140256343974215680.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 313198007361989474693152768.0000 - val_loss: 106724311144605301273001984.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 48689955009941458548424704.0000 - val_loss: 16591439730066121325281280.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7569367787915700999290880.0000 - val_loss: 2579314260724181144436736.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1176738268818639069118464.0000 - val_loss: 400981415558648912936960.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 182936324950180604411904.0000 - val_loss: 62336740875434933092352.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 28439378214715295531008.0000 - val_loss: 9690914358070150692864.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 4421205146287845933056.0000 - val_loss: 1506555828559511814144.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 687323753268077658112.0000 - val_loss: 234210050465123532800.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 106851753848108744704.0000 - val_loss: 36410428708871995392.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 16611207267672391680.0000 - val_loss: 5660380417790836736.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2582388600419123200.0000 - val_loss: 879965406549245952.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 401459457969618944.0000 - val_loss: 136799922467897344.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 62411106081046528.0000 - val_loss: 21267028782350336.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9702459970682880.0000 - val_loss: 3306180730421248.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1508348222504960.0000 - val_loss: 513982662180864.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 234488957239296.0000 - val_loss: 79904662093824.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 36453820137472.0000 - val_loss: 12422287982592.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 5667149053952.0000 - val_loss: 1931295064064.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 881049141248.0000 - val_loss: 300311183360.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 136987803648.0000 - val_loss: 46720348160.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21315184640.0000 - val_loss: 7286804480.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3331877120.0000 - val_loss: 1153217152.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 536534784.0000 - val_loss: 198845840.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 102004456.0000 - val_loss: 49510560.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 34279772.0000 - val_loss: 26061230.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 23735272.0000 - val_loss: 22293844.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 22096400.0000 - val_loss: 21689720.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21860918.0000 - val_loss: 21601428.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21825876.0000 - val_loss: 21572940.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819454.0000 - val_loss: 21568060.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818566.0000 - val_loss: 21564292.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818426.0000 - val_loss: 21564106.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21817172.0000 - val_loss: 21562966.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819154.0000 - val_loss: 21564552.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21816780.0000 - val_loss: 21569040.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819452.0000 - val_loss: 21565946.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818796.0000 - val_loss: 21565624.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818436.0000 - val_loss: 21566460.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818736.0000 - val_loss: 21566654.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818478.0000 - val_loss: 21565306.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819198.0000 - val_loss: 21565240.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818590.0000 - val_loss: 21566064.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818360.0000 - val_loss: 21565286.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818366.0000 - val_loss: 21565130.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818146.0000 - val_loss: 21567680.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818664.0000 - val_loss: 21564736.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818774.0000 - val_loss: 21564400.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818450.0000 - val_loss: 21566768.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818610.0000 - val_loss: 21565924.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21817768.0000 - val_loss: 21564588.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21817802.0000 - val_loss: 21567332.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21817906.0000 - val_loss: 21565576.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818196.0000 - val_loss: 21564252.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818800.0000 - val_loss: 21565486.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818074.0000 - val_loss: 21567070.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818430.0000 - val_loss: 21565198.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21817288.0000 - val_loss: 21563158.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818802.0000 - val_loss: 21564042.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818030.0000 - val_loss: 21565846.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818780.0000 - val_loss: 21565992.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818654.0000 - val_loss: 21565514.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818748.0000 - val_loss: 21565916.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818370.0000 - val_loss: 21565430.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818436.0000 - val_loss: 21565556.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818848.0000 - val_loss: 21566990.0000\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 1s 3ms/step - loss: 21818428.0000 - val_loss: 21566940.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818872.0000 - val_loss: 21565482.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818808.0000 - val_loss: 21565658.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818244.0000 - val_loss: 21564760.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818548.0000 - val_loss: 21564772.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818556.0000 - val_loss: 21566516.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818892.0000 - val_loss: 21565966.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819052.0000 - val_loss: 21565286.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818348.0000 - val_loss: 21564460.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819094.0000 - val_loss: 21564774.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818034.0000 - val_loss: 21566480.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818452.0000 - val_loss: 21565918.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21817866.0000 - val_loss: 21563910.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818888.0000 - val_loss: 21564826.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818406.0000 - val_loss: 21564400.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818496.0000 - val_loss: 21564082.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818276.0000 - val_loss: 21564174.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818610.0000 - val_loss: 21564900.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818010.0000 - val_loss: 21564008.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818354.0000 - val_loss: 21563724.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818416.0000 - val_loss: 21565108.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818690.0000 - val_loss: 21564718.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818152.0000 - val_loss: 21567108.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818870.0000 - val_loss: 21565570.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818206.0000 - val_loss: 21566780.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818966.0000 - val_loss: 21565108.0000\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 18684936.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 33093736.0000 - val_loss: 10759063.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9178082.0000 - val_loss: 8697249.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8572107.0000 - val_loss: 8822048.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8534916.0000 - val_loss: 9016349.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8538918.0000 - val_loss: 9420069.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8604252.0000 - val_loss: 10057147.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8761581.0000 - val_loss: 11088248.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8942837.0000 - val_loss: 12587800.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9222933.0000 - val_loss: 15137605.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9711536.0000 - val_loss: 19243134.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 10557659.0000 - val_loss: 25834856.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 11931991.0000 - val_loss: 36397224.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 14038730.0000 - val_loss: 53376024.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 17419456.0000 - val_loss: 80278544.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 22824728.0000 - val_loss: 123425112.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 31451020.0000 - val_loss: 192263728.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 45285448.0000 - val_loss: 301421888.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 67075840.0000 - val_loss: 475554208.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 102241408.0000 - val_loss: 755836096.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 158487920.0000 - val_loss: 1205547136.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 248200592.0000 - val_loss: 1921365248.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 391197568.0000 - val_loss: 3050753536.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 620308352.0000 - val_loss: 4895439360.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 986293568.0000 - val_loss: 7802707968.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1566301056.0000 - val_loss: 12444402688.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2484181504.0000 - val_loss: 19863216128.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3965174272.0000 - val_loss: 31625132032.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 6339412480.0000 - val_loss: 50357149696.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 10104170496.0000 - val_loss: 80296026112.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 16090481664.0000 - val_loss: 127797428224.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 25655074816.0000 - val_loss: 203952619520.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 40661708800.0000 - val_loss: 326495502336.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 65059131392.0000 - val_loss: 520318746624.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 104119754752.0000 - val_loss: 826980827136.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 166375227392.0000 - val_loss: 1324762398720.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 265848864768.0000 - val_loss: 2108885172224.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 423434878976.0000 - val_loss: 3365586337792.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 676179673088.0000 - val_loss: 5371305394176.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1074028609536.0000 - val_loss: 8578885746688.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1722367868928.0000 - val_loss: 13680627417088.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2747231371264.0000 - val_loss: 21798708051968.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 4374719889408.0000 - val_loss: 34737143939072.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 6978732556288.0000 - val_loss: 55345103765504.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 11151054209024.0000 - val_loss: 89420128583680.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 17863037419520.0000 - val_loss: 142385078075392.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 28532835090432.0000 - val_loss: 226774776545280.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 45551894659072.0000 - val_loss: 364471830708224.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 72928100089856.0000 - val_loss: 580326787121152.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 116057071157248.0000 - val_loss: 925512838938624.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 184825814188032.0000 - val_loss: 1475542725427200.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 295556194762752.0000 - val_loss: 2360964192141312.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 471567578431488.0000 - val_loss: 3771474670256128.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 753109227798528.0000 - val_loss: 6015479118299136.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1198584041046016.0000 - val_loss: 9587209892003840.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1902664606547968.0000 - val_loss: 65962562998501376.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 11086711824056320.0000 - val_loss: 106658503409532928.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 17840785193959424.0000 - val_loss: 169962816659259392.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 28408760531681280.0000 - val_loss: 270931673812566016.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 45280938258595840.0000 - val_loss: 432182527269011456.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 71731524415782912.0000 - val_loss: 691751418423410688.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 115558440151023616.0000 - val_loss: 1101886435453042688.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 183180801850998784.0000 - val_loss: 1761302178976235520.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 293914782547836928.0000 - val_loss: 2802287902317346816.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 468734142066982912.0000 - val_loss: 4472868827129970688.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 748851668593934336.0000 - val_loss: 7159182441972760576.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1196091904526123008.0000 - val_loss: 11407126374431850496.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1905711211534614528.0000 - val_loss: 18195568338925518848.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3033541860795613184.0000 - val_loss: 28999927045847777280.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 4826660332866895872.0000 - val_loss: 46306851395507060736.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7718373714894520320.0000 - val_loss: 73723684007496908800.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 12333106480042475520.0000 - val_loss: 117829726540568461312.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 19664442206355193856.0000 - val_loss: 187751725949727539200.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 31486973969365467136.0000 - val_loss: 302652168795947270144.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 50525787462446350336.0000 - val_loss: 482371091491561930752.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 80502089629852237824.0000 - val_loss: 768760797217446428672.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 128261549817279283200.0000 - val_loss: 1225969890562796421120.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 204702852734685020160.0000 - val_loss: 1960425784256143294464.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 325770306767518957568.0000 - val_loss: 3126921841827326722048.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 522267636165507022848.0000 - val_loss: 5012948300976797777920.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 835626022359992893440.0000 - val_loss: 7998736337681587896320.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 1332347728511054643200.0000 - val_loss: 12754197522412965199872.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2123748824742734331904.0000 - val_loss: 20343252660991727501312.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3381597586005361164288.0000 - val_loss: 32411294129077499199488.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 5378310702046577164288.0000 - val_loss: 51715618147430568034304.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8615459270653703618560.0000 - val_loss: 82651897830151309754368.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 13739214699812278501376.0000 - val_loss: 131686829364182882713600.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21919775991149602275328.0000 - val_loss: 209922056046971201781760.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 34998817028784894509056.0000 - val_loss: 335855978239951758163968.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 55894958601630388322304.0000 - val_loss: 535408784375278544617472.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 89016610003532663226368.0000 - val_loss: 853017509990614754656256.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 141327784165686705651712.0000 - val_loss: 1362521337107679073533952.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 226576151296205182205952.0000 - val_loss: 2169014429162141428744192.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 361679654532091201191936.0000 - val_loss: 3478829094995590037635072.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 578894461513257485074432.0000 - val_loss: 5542072343597278186962944.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 922519293225611424694272.0000 - val_loss: 8826696711058239430590464.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1471221082405021820125184.0000 - val_loss: 14111346470489157735022592.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2342378515233932629245952.0000 - val_loss: 22499053330688780290490368.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3715836609849500329050112.0000 - val_loss: 154815886058597750958718976.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 24744815294454402232877056.0000 - val_loss: 247438814280356706868264960.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 39463179548805083328151552.0000 - val_loss: 394498084263632549596626944.0000\n",
      " 1/54 [..............................] - ETA: 0s - loss: 375850717148372222869504.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 2ms/step - loss: 379588488666307620765696.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 32961488.0000 - val_loss: 10823571.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9214727.0000 - val_loss: 8719770.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8588805.0000 - val_loss: 8849267.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8560161.0000 - val_loss: 9003359.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8571084.0000 - val_loss: 9497743.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8667121.0000 - val_loss: 10124971.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8800762.0000 - val_loss: 11267292.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9005880.0000 - val_loss: 13045366.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9337998.0000 - val_loss: 15870332.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9873049.0000 - val_loss: 20217776.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 10796094.0000 - val_loss: 27685240.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 12226622.0000 - val_loss: 39027872.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 14517181.0000 - val_loss: 57651660.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 18193768.0000 - val_loss: 87278240.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 24042120.0000 - val_loss: 133865512.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 33299828.0000 - val_loss: 208401504.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 47962972.0000 - val_loss: 327619072.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 71556664.0000 - val_loss: 516026784.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 109054576.0000 - val_loss: 818968896.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 168228240.0000 - val_loss: 1303384064.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 264746000.0000 - val_loss: 2067287424.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 417030752.0000 - val_loss: 3289480960.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 660609536.0000 - val_loss: 5250479616.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 1048548288.0000 - val_loss: 8363781632.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1668419456.0000 - val_loss: 13386390528.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2655321088.0000 - val_loss: 21298860032.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 4225176064.0000 - val_loss: 33959888896.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 6768270336.0000 - val_loss: 54815535104.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 10846476288.0000 - val_loss: 87338844160.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 17280972800.0000 - val_loss: 139712692224.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 27528038400.0000 - val_loss: 222608064512.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 43889364992.0000 - val_loss: 354813837312.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 69948686336.0000 - val_loss: 565319761920.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 111801171968.0000 - val_loss: 906050142208.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 178624512000.0000 - val_loss: 1444406099968.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 285018521600.0000 - val_loss: 2307649437696.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 454618841088.0000 - val_loss: 3677582262272.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 723953123328.0000 - val_loss: 5867385126912.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1152217907200.0000 - val_loss: 9351256342528.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1842296389632.0000 - val_loss: 14958554251264.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2931007422464.0000 - val_loss: 23865675743232.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 4705959280640.0000 - val_loss: 38561592115200.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 7549012672512.0000 - val_loss: 61511556923392.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 12036523163648.0000 - val_loss: 97921588527104.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 19264056590336.0000 - val_loss: 156989292281856.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 30822723747840.0000 - val_loss: 250591108399104.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 49135239561216.0000 - val_loss: 399352333860864.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 78265268043776.0000 - val_loss: 636064926531584.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 124867257040896.0000 - val_loss: 1014674883608576.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 198534661931008.0000 - val_loss: 1620071864598528.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 316438728409088.0000 - val_loss: 2584588375293952.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 507630405550080.0000 - val_loss: 4119372926812160.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 809786689978368.0000 - val_loss: 6577266746195968.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1283933362716672.0000 - val_loss: 10530718643912704.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2058488704401408.0000 - val_loss: 16737808601317376.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3291917949337600.0000 - val_loss: 26784801184808960.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 5236632433197056.0000 - val_loss: 42755484603645952.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8332508747792384.0000 - val_loss: 68288768825622528.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 13294398028644352.0000 - val_loss: 109065214103650304.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21284971008229376.0000 - val_loss: 173027808400900096.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 34118268864167936.0000 - val_loss: 280279498333618176.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 54712574771462144.0000 - val_loss: 446633580391563264.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 87429926235406336.0000 - val_loss: 712773187393290240.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 139553314332213248.0000 - val_loss: 1137171825172676608.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 222645229109379072.0000 - val_loss: 1814208342042607616.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 354405273743392768.0000 - val_loss: 2894847814800506880.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 564740989143482368.0000 - val_loss: 4615018638171176960.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 898572441826099200.0000 - val_loss: 7362518975588073472.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1440268285726687232.0000 - val_loss: 11787804787758596096.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2300049407569035264.0000 - val_loss: 18792382150970703872.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3671003793085956096.0000 - val_loss: 29991704126287773696.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 5862059437627277312.0000 - val_loss: 47733265422406909952.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9339838905538576384.0000 - val_loss: 76113833170281955328.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 14904478248829190144.0000 - val_loss: 121714485839454535680.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 23774185773540048896.0000 - val_loss: 193966693435498823680.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 37904528671577735168.0000 - val_loss: 309924039634894979072.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 60466063070843633664.0000 - val_loss: 493427287839268143104.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 96349500254569103360.0000 - val_loss: 786629391688992292864.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 153678318001786454016.0000 - val_loss: 1256715261531413020672.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 245004985257884123136.0000 - val_loss: 2000430415321145278464.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 389999870596891017216.0000 - val_loss: 3187417569721887752192.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 621603638699534319616.0000 - val_loss: 5078704796186080968704.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 992534599971068968960.0000 - val_loss: 8123854779579241594880.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1583280418448790781952.0000 - val_loss: 12949319353968512466944.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2527530167596216221696.0000 - val_loss: 20777417679468752797696.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 4024622948176204136448.0000 - val_loss: 33161524021203199590400.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 6450862093603277111296.0000 - val_loss: 52911103172115693568000.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 10301293970967115071488.0000 - val_loss: 84810788383523904421888.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 16463515297902636302336.0000 - val_loss: 135229793176636742434816.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 26177224625486722760704.0000 - val_loss: 215290779148361060581376.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 41820520715354600636416.0000 - val_loss: 345132744953988638572544.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 66855278942769417027584.0000 - val_loss: 549723529834071194599424.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 106558607933701246418944.0000 - val_loss: 876508934165325603143680.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 169590628030408518795264.0000 - val_loss: 1396006789287480337104896.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 270928699304858905214976.0000 - val_loss: 2232838001929355339497472.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 433114238611967212257280.0000 - val_loss: 3566477646540316365291520.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 690664472806165284126720.0000 - val_loss: 5676986065144866813247488.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1100958323587899851800576.0000 - val_loss: 9089638906927904593018880.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1755161581753279562383360.0000 - val_loss: 14478412466204381068394496.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2812201810581378868183040.0000 - val_loss: 23369594382858290664046592.0000\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 1392021971686085623808.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 32003176.0000 - val_loss: 10872761.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8608437.0000 - val_loss: 8820683.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7976916.5000 - val_loss: 8900942.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7952947.0000 - val_loss: 9127241.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7980881.5000 - val_loss: 9600981.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8064752.5000 - val_loss: 10339184.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8203833.0000 - val_loss: 11589955.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8433316.0000 - val_loss: 13676817.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8842608.0000 - val_loss: 16858608.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 9442321.0000 - val_loss: 21789658.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 10417220.0000 - val_loss: 29968582.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 11993021.0000 - val_loss: 42798528.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 14494902.0000 - val_loss: 63403796.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 18499848.0000 - val_loss: 96527296.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 25017268.0000 - val_loss: 149951472.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 35371032.0000 - val_loss: 234946064.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 51765488.0000 - val_loss: 369504416.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 77999816.0000 - val_loss: 583639296.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 119770912.0000 - val_loss: 925516480.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 186230144.0000 - val_loss: 1469436416.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 292800480.0000 - val_loss: 2355052544.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 464069152.0000 - val_loss: 3749944320.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 734771776.0000 - val_loss: 5976441344.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1165025792.0000 - val_loss: 9514341376.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1853058048.0000 - val_loss: 15154519040.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2960115968.0000 - val_loss: 24493805568.0000\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 1s 3ms/step - loss: 4752958976.0000 - val_loss: 39017177088.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7568680448.0000 - val_loss: 62103085056.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 12064802816.0000 - val_loss: 99414474752.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 19245979648.0000 - val_loss: 158183587840.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 30714710016.0000 - val_loss: 254064427008.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 49053675520.0000 - val_loss: 404687749120.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 78487216128.0000 - val_loss: 650852958208.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 125559824384.0000 - val_loss: 1037222608896.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 199963852800.0000 - val_loss: 1654066118656.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 318889426944.0000 - val_loss: 2650466156544.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 508315860992.0000 - val_loss: 4226859401216.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 810707648512.0000 - val_loss: 6736002416640.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1289762504704.0000 - val_loss: 10747830599680.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2063588524032.0000 - val_loss: 17114214694912.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3294924111872.0000 - val_loss: 27416351211520.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 5247388352512.0000 - val_loss: 43755595890688.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8417150763008.0000 - val_loss: 70026249895936.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 13456688283648.0000 - val_loss: 111906949955584.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21333786230784.0000 - val_loss: 179009958707200.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 34432838795264.0000 - val_loss: 289856034963456.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 55424158007296.0000 - val_loss: 461340154003456.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 88447805030400.0000 - val_loss: 735207200129024.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 141005839925248.0000 - val_loss: 1173404124184576.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 224579444277248.0000 - val_loss: 1870737296064512.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 355924074037248.0000 - val_loss: 2994134981804032.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 572108836962304.0000 - val_loss: 4765399895769088.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 911547685666816.0000 - val_loss: 7599079194361856.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 1450106855358464.0000 - val_loss: 12118132114063360.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2324458580738048.0000 - val_loss: 19540348850143232.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3729505055145984.0000 - val_loss: 31167589824593920.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 5944526258569216.0000 - val_loss: 49696095919407104.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9465700972232704.0000 - val_loss: 79204814755463168.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 15064744893349888.0000 - val_loss: 126294526951161856.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 24107297097646080.0000 - val_loss: 201779006675091456.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 38480325696815104.0000 - val_loss: 322252255212339200.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 61354922083352576.0000 - val_loss: 512932963315351552.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 97972421679644672.0000 - val_loss: 823108148448460800.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 156720539132493824.0000 - val_loss: 1313001326640103424.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 249737384596340736.0000 - val_loss: 2095210666192273408.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 398164565218557952.0000 - val_loss: 3335250600236417024.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 635524730241155072.0000 - val_loss: 5320904553447555072.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1011366598075744256.0000 - val_loss: 8482745402431373312.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 1618943873042612224.0000 - val_loss: 13582046136079745024.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2577470210030174208.0000 - val_loss: 21686701375556157440.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 4135613701396889600.0000 - val_loss: 34658108440383062016.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 6599499137597571072.0000 - val_loss: 55183569406356619264.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 10492206256285024256.0000 - val_loss: 88052515142627229696.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 16776360511234113536.0000 - val_loss: 140185120101812404224.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 26768369241229885440.0000 - val_loss: 223907802434722856960.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 42685174442822205440.0000 - val_loss: 356484750673069473792.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 68170213503321243648.0000 - val_loss: 572005108975210070016.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 108872453909821521920.0000 - val_loss: 911169261772017238016.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 174226431106315452416.0000 - val_loss: 1466300825502725701632.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 279108458251775115264.0000 - val_loss: 2338743071129030623232.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 442494707462823739392.0000 - val_loss: 3738686874559660949504.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 710672243323714928640.0000 - val_loss: 5950958594315478106112.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1132136055320392761344.0000 - val_loss: 9482581217007712075776.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1808416067508483653632.0000 - val_loss: 15223240849023404343296.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2889545831192905908224.0000 - val_loss: 24257186981951349719040.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 4605424326095482650624.0000 - val_loss: 38656215055970424848384.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7358225954427654635520.0000 - val_loss: 62018201273791017910272.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 11729429322902666215424.0000 - val_loss: 99019122790321044324352.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 18753946989191468417024.0000 - val_loss: 157867217768407833247744.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 29906142066554710261760.0000 - val_loss: 251626649604317658480640.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 47711229027955209404416.0000 - val_loss: 401059886278556216459264.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 76181648303102156079104.0000 - val_loss: 642167982636382872928256.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 121632831426454402105344.0000 - val_loss: 1022086314939399108820992.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 193640246357334176038912.0000 - val_loss: 1630166299794635564777472.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 308656254103267024306176.0000 - val_loss: 2597856120822020760928256.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 490195778621819414642688.0000 - val_loss: 4151580986672648929935360.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 791266025397555499630592.0000 - val_loss: 6776209674213897587916800.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1272777350728329801498624.0000 - val_loss: 10818864366513548525830144.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2037344164037388014714880.0000 - val_loss: 17212119633757235822198784.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3243343148297384632516608.0000 - val_loss: 27456970900321641196158976.0000\n",
      " 1/54 [..............................] - ETA: 0s - loss: 65611808064054658859008.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 37658217378545122934784.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 32493714.0000 - val_loss: 11020217.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8533819.0000 - val_loss: 8834726.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 7816959.5000 - val_loss: 8864176.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7785968.5000 - val_loss: 9058163.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7815202.0000 - val_loss: 9446953.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7851301.5000 - val_loss: 10130507.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7990457.0000 - val_loss: 11160339.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8167871.5000 - val_loss: 12845185.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8484378.0000 - val_loss: 15527441.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8983932.0000 - val_loss: 19758326.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9759630.0000 - val_loss: 26459844.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 11062954.0000 - val_loss: 37713888.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 13142051.0000 - val_loss: 55315492.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 16439552.0000 - val_loss: 83431640.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818158.0000 - val_loss: 128414288.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 30253602.0000 - val_loss: 199863648.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 43890028.0000 - val_loss: 318568800.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 65998228.0000 - val_loss: 502826560.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 100738360.0000 - val_loss: 795868544.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 155736208.0000 - val_loss: 1263044736.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 244386000.0000 - val_loss: 2018929408.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 386010176.0000 - val_loss: 3215918080.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 610878400.0000 - val_loss: 5126894592.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 963837888.0000 - val_loss: 8200606720.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1547326848.0000 - val_loss: 13107300352.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2459842816.0000 - val_loss: 20910112768.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3932742144.0000 - val_loss: 33529501696.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 6260366336.0000 - val_loss: 53509685248.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 10097849344.0000 - val_loss: 87715749888.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 16331784192.0000 - val_loss: 139802230784.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 26038882304.0000 - val_loss: 222925062144.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 41578192896.0000 - val_loss: 357527420928.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 66433843200.0000 - val_loss: 569743769600.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 105681051648.0000 - val_loss: 907984175104.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 168555790336.0000 - val_loss: 1447546585088.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 270705311744.0000 - val_loss: 2355276283904.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 436551221248.0000 - val_loss: 3753642295296.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 695405903872.0000 - val_loss: 5977722585088.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1107772309504.0000 - val_loss: 9531320958976.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 1765747589120.0000 - val_loss: 15226123583488.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2811961802752.0000 - val_loss: 24242982748160.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 4496297558016.0000 - val_loss: 38981903319040.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7199923896320.0000 - val_loss: 62151439941632.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 11477606989824.0000 - val_loss: 99220279263232.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 18299278589952.0000 - val_loss: 158178041921536.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 29116803842048.0000 - val_loss: 252290120286208.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 46433633828864.0000 - val_loss: 401710640005120.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 74161846222848.0000 - val_loss: 640288758431744.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 118024216510464.0000 - val_loss: 1020263575584768.0000\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 1s 3ms/step - loss: 187903510577152.0000 - val_loss: 1627530880614400.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 300778774331392.0000 - val_loss: 2599404133416960.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 480383669895168.0000 - val_loss: 4152411962736640.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 766637368147968.0000 - val_loss: 6610002986926080.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1220130415575040.0000 - val_loss: 10533610230644736.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1948481841266688.0000 - val_loss: 16827001113411584.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3096261787910144.0000 - val_loss: 26866757750751232.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 4951972201365504.0000 - val_loss: 42773510581387264.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7855245002539008.0000 - val_loss: 68420997983764480.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 12631869258465280.0000 - val_loss: 109101979023704064.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20152317265313792.0000 - val_loss: 173738384970219520.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 32115446157148160.0000 - val_loss: 276913480924135424.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 51359322004783104.0000 - val_loss: 444249942261760000.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 82167972822515712.0000 - val_loss: 709305052841377792.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 130768783361966080.0000 - val_loss: 1129383090959941632.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 208947324271984640.0000 - val_loss: 1806593124508631040.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 333432261242257408.0000 - val_loss: 2880174557249929216.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 531247356700524544.0000 - val_loss: 4596468227743154176.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 848875959359635456.0000 - val_loss: 7370669655284776960.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1355128977219387392.0000 - val_loss: 11747081076089028608.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2164402932928217088.0000 - val_loss: 18770570039298883584.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3448018711804379136.0000 - val_loss: 29933645514294689792.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 5513507104796704768.0000 - val_loss: 47720330767617753088.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8788691109929811968.0000 - val_loss: 76147302304231456768.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 14026638060817481728.0000 - val_loss: 121992943756258574336.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 22363853203708051456.0000 - val_loss: 194490940579622420480.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 35679539349424177152.0000 - val_loss: 309872001948575596544.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 56968987173864865792.0000 - val_loss: 495510273035671175168.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 90878647054104526848.0000 - val_loss: 789602893342963662848.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 145010797471284068352.0000 - val_loss: 1260752738597350670336.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 231558960804788174848.0000 - val_loss: 2013439766532246732800.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 368879606825639477248.0000 - val_loss: 3206666517479222673408.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 588539300950914891776.0000 - val_loss: 5110567763549727227904.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 938039777842490769408.0000 - val_loss: 8142145023565900021760.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1493779820104103493632.0000 - val_loss: 12974682501169956257792.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2386624920154768670720.0000 - val_loss: 20774188598535928152064.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 3813529382017164115968.0000 - val_loss: 33140312066958284554240.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 6065183954614429417472.0000 - val_loss: 52873700777210381598720.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9694177216000180617216.0000 - val_loss: 84479557638130059182080.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 15447855628638694146048.0000 - val_loss: 134555280053246208507904.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 24733577750534600785920.0000 - val_loss: 217296141990436595040256.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 39509629170958624358400.0000 - val_loss: 347264316672021603811328.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 62992347887589765677056.0000 - val_loss: 554460019605372273688576.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 101276317916359882178560.0000 - val_loss: 882952035993820967469056.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 161509855247814656786432.0000 - val_loss: 1412166137096049904320512.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 257642810188138299785216.0000 - val_loss: 2248510384517416589721600.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 411294406503748216029184.0000 - val_loss: 3596274038135751870251008.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 656111991773850383679488.0000 - val_loss: 5727424075128407154753536.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1041894587252455308787712.0000 - val_loss: 9159416598690472489123840.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 1670704316933304987156480.0000 - val_loss: 14569887564222897521164288.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2669890368199480408276992.0000 - val_loss: 23326724149630989666091008.0000\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 4565346230061559185408.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 33021118.0000 - val_loss: 10881450.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 9051509.0000 - val_loss: 8579818.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8382841.5000 - val_loss: 8447012.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8332206.0000 - val_loss: 8467893.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8323710.0000 - val_loss: 8423159.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8297042.5000 - val_loss: 8412620.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8267417.0000 - val_loss: 8342086.5000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8223673.5000 - val_loss: 8432776.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8247655.0000 - val_loss: 8366568.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8253975.0000 - val_loss: 8341974.5000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8217606.5000 - val_loss: 8350615.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8245390.5000 - val_loss: 8335292.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8229561.0000 - val_loss: 8353714.5000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8216138.5000 - val_loss: 8327804.5000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8237951.0000 - val_loss: 8342663.5000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8237582.0000 - val_loss: 8323021.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8227242.0000 - val_loss: 8318228.5000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8230006.5000 - val_loss: 8350628.5000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8218866.5000 - val_loss: 8314681.5000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8185670.5000 - val_loss: 8392367.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8252670.0000 - val_loss: 8324076.5000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8193596.0000 - val_loss: 8380138.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8200669.0000 - val_loss: 8380504.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8218436.5000 - val_loss: 8368386.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8212952.0000 - val_loss: 8366707.5000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8243459.5000 - val_loss: 8328900.5000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8191383.0000 - val_loss: 8327432.5000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8168832.0000 - val_loss: 8386819.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8213094.0000 - val_loss: 8367391.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8194413.0000 - val_loss: 8327789.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8221677.0000 - val_loss: 8333473.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8219048.0000 - val_loss: 8353868.5000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8215268.0000 - val_loss: 8352287.5000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 8215503.5000 - val_loss: 8345076.5000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8163126.0000 - val_loss: 8370745.5000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8233636.0000 - val_loss: 8305731.5000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8183061.0000 - val_loss: 8412998.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8224793.0000 - val_loss: 8377974.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8208172.0000 - val_loss: 8364272.5000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8209335.0000 - val_loss: 8380374.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8226729.0000 - val_loss: 8384346.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8196043.5000 - val_loss: 8361758.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 8158292.5000 - val_loss: 8361096.5000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8198819.5000 - val_loss: 8313121.5000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8178430.5000 - val_loss: 8383665.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8205103.0000 - val_loss: 8367819.5000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8193681.5000 - val_loss: 8376134.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8200238.0000 - val_loss: 8334281.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8213799.5000 - val_loss: 8327435.5000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8218857.0000 - val_loss: 8348436.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8209618.5000 - val_loss: 8280190.5000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8189158.0000 - val_loss: 8427621.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8199981.5000 - val_loss: 8334725.5000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8194102.0000 - val_loss: 8390046.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8182833.5000 - val_loss: 8315344.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8218694.0000 - val_loss: 8319598.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8209715.0000 - val_loss: 8380062.5000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8172964.5000 - val_loss: 8343288.5000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8170619.5000 - val_loss: 8417344.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8214123.0000 - val_loss: 8370305.5000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8199297.0000 - val_loss: 8350567.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 8191829.0000 - val_loss: 8374382.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8188137.5000 - val_loss: 8333699.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8209055.5000 - val_loss: 8355958.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8219201.5000 - val_loss: 8355895.5000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8203712.0000 - val_loss: 8348498.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8200216.5000 - val_loss: 8302912.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8162445.0000 - val_loss: 8344440.5000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8209949.0000 - val_loss: 8338081.5000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8210849.0000 - val_loss: 8427607.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8205659.5000 - val_loss: 8358972.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8222969.5000 - val_loss: 8345351.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8179063.5000 - val_loss: 8359175.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8217427.5000 - val_loss: 8313565.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8186122.5000 - val_loss: 8383267.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8172416.0000 - val_loss: 8406230.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8189507.0000 - val_loss: 8331091.5000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8196041.0000 - val_loss: 8321536.5000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8194933.5000 - val_loss: 8356062.5000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8203452.5000 - val_loss: 8352346.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8162242.5000 - val_loss: 8370332.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8164049.5000 - val_loss: 8354904.5000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8188391.5000 - val_loss: 8393345.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 8193517.0000 - val_loss: 8358257.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 8187770.5000 - val_loss: 8394667.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 8203503.5000 - val_loss: 8392066.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 8161107.5000 - val_loss: 8361825.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 8167186.5000 - val_loss: 8383520.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 8204089.0000 - val_loss: 8353757.5000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8216977.0000 - val_loss: 8304495.5000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8195414.0000 - val_loss: 8351173.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 6ms/step - loss: 8190205.0000 - val_loss: 8320087.5000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 8214265.5000 - val_loss: 8331349.5000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8212057.0000 - val_loss: 8320928.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8207820.0000 - val_loss: 8358303.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 8184120.0000 - val_loss: 8353951.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8207601.5000 - val_loss: 8357634.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8211174.5000 - val_loss: 8336092.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8203402.0000 - val_loss: 8351173.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 8165157.5000 - val_loss: 8334834.0000\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 7561689.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 172876414976.0000 - val_loss: 113537712.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 51091120.0000 - val_loss: 25924758.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 23288488.0000 - val_loss: 21793810.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21970408.0000 - val_loss: 21583568.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 5ms/step - loss: 21893196.0000 - val_loss: 21564390.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21884086.0000 - val_loss: 21562736.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884204.0000 - val_loss: 21563684.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21884600.0000 - val_loss: 21563116.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21884570.0000 - val_loss: 21563402.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21884798.0000 - val_loss: 21562500.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21884046.0000 - val_loss: 21563212.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883790.0000 - val_loss: 21562192.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21884938.0000 - val_loss: 21562066.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21884428.0000 - val_loss: 21562666.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21884068.0000 - val_loss: 21563438.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21884738.0000 - val_loss: 21562058.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884678.0000 - val_loss: 21562070.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21882040.0000 - val_loss: 21562916.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21883854.0000 - val_loss: 21562056.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883010.0000 - val_loss: 21562188.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21883864.0000 - val_loss: 21562846.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21884424.0000 - val_loss: 21562854.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883144.0000 - val_loss: 21564478.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885150.0000 - val_loss: 21562802.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883432.0000 - val_loss: 21563326.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884702.0000 - val_loss: 21562316.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884024.0000 - val_loss: 21562190.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884472.0000 - val_loss: 21562402.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21883866.0000 - val_loss: 21563114.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883160.0000 - val_loss: 21566310.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885028.0000 - val_loss: 21562208.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21884954.0000 - val_loss: 21563330.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21885488.0000 - val_loss: 21562584.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884648.0000 - val_loss: 21562060.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885254.0000 - val_loss: 21562102.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884558.0000 - val_loss: 21562066.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883590.0000 - val_loss: 21562152.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884204.0000 - val_loss: 21562750.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883832.0000 - val_loss: 21562322.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885094.0000 - val_loss: 21562084.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21882176.0000 - val_loss: 21563134.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885096.0000 - val_loss: 21563024.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885422.0000 - val_loss: 21562070.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21884468.0000 - val_loss: 21562220.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885120.0000 - val_loss: 21562058.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883792.0000 - val_loss: 21562152.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885156.0000 - val_loss: 21562090.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884660.0000 - val_loss: 21562304.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884592.0000 - val_loss: 21562108.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884630.0000 - val_loss: 21562082.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884904.0000 - val_loss: 21562088.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884186.0000 - val_loss: 21562082.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885546.0000 - val_loss: 21562248.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884466.0000 - val_loss: 21562064.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884602.0000 - val_loss: 21562106.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883540.0000 - val_loss: 21562958.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883040.0000 - val_loss: 21562452.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21884670.0000 - val_loss: 21562142.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884498.0000 - val_loss: 21562058.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884102.0000 - val_loss: 21562480.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21882290.0000 - val_loss: 21562682.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884836.0000 - val_loss: 21562078.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885638.0000 - val_loss: 21562058.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884520.0000 - val_loss: 21562214.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884492.0000 - val_loss: 21562150.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884856.0000 - val_loss: 21562060.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21882250.0000 - val_loss: 21564784.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884736.0000 - val_loss: 21562292.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883408.0000 - val_loss: 21562214.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883884.0000 - val_loss: 21562526.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21882176.0000 - val_loss: 21565730.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21885318.0000 - val_loss: 21562378.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883514.0000 - val_loss: 21563998.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884550.0000 - val_loss: 21562518.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884498.0000 - val_loss: 21563274.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21884446.0000 - val_loss: 21564266.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21882166.0000 - val_loss: 21562604.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884846.0000 - val_loss: 21562066.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21882866.0000 - val_loss: 21563036.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21883866.0000 - val_loss: 21562820.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884944.0000 - val_loss: 21562820.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883584.0000 - val_loss: 21563314.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885020.0000 - val_loss: 21562560.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21885274.0000 - val_loss: 21562154.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885192.0000 - val_loss: 21562068.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884650.0000 - val_loss: 21562110.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884254.0000 - val_loss: 21562332.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21882266.0000 - val_loss: 21563300.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884828.0000 - val_loss: 21562120.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885220.0000 - val_loss: 21562114.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884998.0000 - val_loss: 21562218.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883030.0000 - val_loss: 21562638.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884926.0000 - val_loss: 21562218.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884974.0000 - val_loss: 21562060.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885102.0000 - val_loss: 21562062.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884238.0000 - val_loss: 21562124.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21884470.0000 - val_loss: 21562160.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885234.0000 - val_loss: 21562590.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21882352.0000 - val_loss: 21562396.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21885094.0000 - val_loss: 21562512.0000\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 18424928.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 27316512096256.0000 - val_loss: 721486592.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 242837104.0000 - val_loss: 56078336.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 32003140.0000 - val_loss: 23232800.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21743402.0000 - val_loss: 21651806.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21275032.0000 - val_loss: 21576328.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21252756.0000 - val_loss: 21562982.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251012.0000 - val_loss: 21564662.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250860.0000 - val_loss: 21562388.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251232.0000 - val_loss: 21562886.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21247744.0000 - val_loss: 21562288.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21252102.0000 - val_loss: 21562220.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21251048.0000 - val_loss: 21564852.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250016.0000 - val_loss: 21564928.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251518.0000 - val_loss: 21563806.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21249956.0000 - val_loss: 21562066.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250354.0000 - val_loss: 21563326.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250040.0000 - val_loss: 21566500.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251254.0000 - val_loss: 21563604.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21249622.0000 - val_loss: 21565874.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21251646.0000 - val_loss: 21564368.0000\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 1s 3ms/step - loss: 21250594.0000 - val_loss: 21563158.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21251378.0000 - val_loss: 21563718.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251002.0000 - val_loss: 21563118.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251502.0000 - val_loss: 21563514.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251192.0000 - val_loss: 21562808.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250478.0000 - val_loss: 21562050.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250228.0000 - val_loss: 21562590.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250678.0000 - val_loss: 21562192.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21250846.0000 - val_loss: 21562082.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250904.0000 - val_loss: 21563518.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251136.0000 - val_loss: 21562938.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251470.0000 - val_loss: 21564188.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21250412.0000 - val_loss: 21562056.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250450.0000 - val_loss: 21562228.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21252294.0000 - val_loss: 21562058.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21248886.0000 - val_loss: 21565804.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251140.0000 - val_loss: 21563870.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21249538.0000 - val_loss: 21562058.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251252.0000 - val_loss: 21562138.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250772.0000 - val_loss: 21563382.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21246800.0000 - val_loss: 21562558.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21252026.0000 - val_loss: 21562228.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250164.0000 - val_loss: 21562228.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250388.0000 - val_loss: 21562772.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250398.0000 - val_loss: 21562058.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251066.0000 - val_loss: 21562164.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250858.0000 - val_loss: 21562164.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250254.0000 - val_loss: 21562078.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251168.0000 - val_loss: 21562058.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21248106.0000 - val_loss: 21566660.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21247860.0000 - val_loss: 21562314.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21252014.0000 - val_loss: 21562268.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250220.0000 - val_loss: 21563660.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250496.0000 - val_loss: 21563246.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250724.0000 - val_loss: 21562558.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21248402.0000 - val_loss: 21562658.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251404.0000 - val_loss: 21562086.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251188.0000 - val_loss: 21562668.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21249326.0000 - val_loss: 21562090.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251744.0000 - val_loss: 21562652.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250854.0000 - val_loss: 21562918.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250882.0000 - val_loss: 21562924.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251192.0000 - val_loss: 21563144.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250536.0000 - val_loss: 21562238.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251520.0000 - val_loss: 21562682.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21248560.0000 - val_loss: 21566546.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250152.0000 - val_loss: 21566902.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21252804.0000 - val_loss: 21563610.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251164.0000 - val_loss: 21562890.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250692.0000 - val_loss: 21563406.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250084.0000 - val_loss: 21566942.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21247362.0000 - val_loss: 21562172.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251394.0000 - val_loss: 21562088.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250966.0000 - val_loss: 21563688.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21249488.0000 - val_loss: 21564740.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250372.0000 - val_loss: 21562250.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250256.0000 - val_loss: 21564630.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250914.0000 - val_loss: 21563028.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250616.0000 - val_loss: 21564244.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21249274.0000 - val_loss: 21562198.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251042.0000 - val_loss: 21563150.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250982.0000 - val_loss: 21564426.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251622.0000 - val_loss: 21562760.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250726.0000 - val_loss: 21562820.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251086.0000 - val_loss: 21563086.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21249388.0000 - val_loss: 21562112.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251618.0000 - val_loss: 21562064.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250980.0000 - val_loss: 21563438.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250348.0000 - val_loss: 21563082.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21250654.0000 - val_loss: 21562736.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21249880.0000 - val_loss: 21562112.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251096.0000 - val_loss: 21563764.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250872.0000 - val_loss: 21562618.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21249748.0000 - val_loss: 21562360.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21246258.0000 - val_loss: 21568466.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21252430.0000 - val_loss: 21563840.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251048.0000 - val_loss: 21563224.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251132.0000 - val_loss: 21563566.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21251622.0000 - val_loss: 21562944.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21250096.0000 - val_loss: 21565652.0000\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 20958408.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - ETA: 0s - loss: n - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 231652736.0000 - val_loss: 27089776.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 22163590.0000 - val_loss: 21888448.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20608068.0000 - val_loss: 21601396.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20528234.0000 - val_loss: 21571762.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522282.0000 - val_loss: 21570666.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522904.0000 - val_loss: 21566548.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523124.0000 - val_loss: 21566708.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522564.0000 - val_loss: 21569076.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523318.0000 - val_loss: 21569420.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523532.0000 - val_loss: 21568104.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522980.0000 - val_loss: 21568968.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20521992.0000 - val_loss: 21564542.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522250.0000 - val_loss: 21564564.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523688.0000 - val_loss: 21566548.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522698.0000 - val_loss: 21565366.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20524334.0000 - val_loss: 21566688.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20519880.0000 - val_loss: 21577244.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523520.0000 - val_loss: 21570296.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523288.0000 - val_loss: 21569016.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20520992.0000 - val_loss: 21564034.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523982.0000 - val_loss: 21567982.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522482.0000 - val_loss: 21564718.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522760.0000 - val_loss: 21563272.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522322.0000 - val_loss: 21569186.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522764.0000 - val_loss: 21565262.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20521266.0000 - val_loss: 21563002.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523086.0000 - val_loss: 21563210.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523494.0000 - val_loss: 21564856.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20521960.0000 - val_loss: 21564214.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522608.0000 - val_loss: 21563710.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523006.0000 - val_loss: 21565712.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20521288.0000 - val_loss: 21563076.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523188.0000 - val_loss: 21567812.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522218.0000 - val_loss: 21571774.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522992.0000 - val_loss: 21570204.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522582.0000 - val_loss: 21569462.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523102.0000 - val_loss: 21568646.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523048.0000 - val_loss: 21567332.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20521628.0000 - val_loss: 21564240.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20521662.0000 - val_loss: 21573516.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20524102.0000 - val_loss: 21570972.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523398.0000 - val_loss: 21568146.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522830.0000 - val_loss: 21566550.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20520608.0000 - val_loss: 21576982.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523066.0000 - val_loss: 21566326.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523234.0000 - val_loss: 21570412.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523618.0000 - val_loss: 21569528.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522920.0000 - val_loss: 21566882.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523146.0000 - val_loss: 21569064.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522504.0000 - val_loss: 21566000.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522592.0000 - val_loss: 21569356.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20519290.0000 - val_loss: 21577882.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20521116.0000 - val_loss: 21563890.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 20522686.0000 - val_loss: 21563872.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 20522782.0000 - val_loss: 21563560.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522142.0000 - val_loss: 21569674.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523160.0000 - val_loss: 21566844.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522966.0000 - val_loss: 21568824.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523084.0000 - val_loss: 21567798.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523312.0000 - val_loss: 21568036.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522966.0000 - val_loss: 21567396.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522592.0000 - val_loss: 21568136.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522436.0000 - val_loss: 21570182.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523512.0000 - val_loss: 21569982.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522544.0000 - val_loss: 21571032.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522794.0000 - val_loss: 21567612.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522870.0000 - val_loss: 21567396.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523740.0000 - val_loss: 21569560.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522910.0000 - val_loss: 21567578.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522568.0000 - val_loss: 21565592.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522426.0000 - val_loss: 21565940.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20520430.0000 - val_loss: 21572466.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 20522454.0000 - val_loss: 21573986.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523464.0000 - val_loss: 21570410.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523070.0000 - val_loss: 21566654.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522652.0000 - val_loss: 21570866.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523686.0000 - val_loss: 21566468.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 20523462.0000 - val_loss: 21564740.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523348.0000 - val_loss: 21569568.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522352.0000 - val_loss: 21566238.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522326.0000 - val_loss: 21563308.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523928.0000 - val_loss: 21565878.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523264.0000 - val_loss: 21568030.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522330.0000 - val_loss: 21565194.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523052.0000 - val_loss: 21566868.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522228.0000 - val_loss: 21564540.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522460.0000 - val_loss: 21570028.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523392.0000 - val_loss: 21568420.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523132.0000 - val_loss: 21566372.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522362.0000 - val_loss: 21566956.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20522374.0000 - val_loss: 21571062.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20521222.0000 - val_loss: 21574092.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523050.0000 - val_loss: 21568238.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523494.0000 - val_loss: 21570054.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523574.0000 - val_loss: 21570482.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20523676.0000 - val_loss: 21566428.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20520934.0000 - val_loss: 21572872.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 20523724.0000 - val_loss: 21571116.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 20521976.0000 - val_loss: 21564588.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 20522974.0000 - val_loss: 21565760.0000\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 23872684.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 61090796.0000 - val_loss: 26067494.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 23226612.0000 - val_loss: 21888640.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21911548.0000 - val_loss: 21597350.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21825530.0000 - val_loss: 21572676.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818676.0000 - val_loss: 21563646.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820200.0000 - val_loss: 21564180.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820146.0000 - val_loss: 21563898.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820104.0000 - val_loss: 21563434.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819892.0000 - val_loss: 21565632.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819674.0000 - val_loss: 21565832.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819714.0000 - val_loss: 21563634.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819468.0000 - val_loss: 21562768.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818748.0000 - val_loss: 21568550.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819832.0000 - val_loss: 21563826.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820686.0000 - val_loss: 21565248.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819248.0000 - val_loss: 21563006.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820588.0000 - val_loss: 21565656.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819892.0000 - val_loss: 21565772.0000\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 1s 3ms/step - loss: 21819554.0000 - val_loss: 21564358.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818252.0000 - val_loss: 21568832.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819932.0000 - val_loss: 21566256.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819638.0000 - val_loss: 21563630.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819702.0000 - val_loss: 21565876.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21818982.0000 - val_loss: 21563042.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820144.0000 - val_loss: 21563034.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820608.0000 - val_loss: 21564002.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21817818.0000 - val_loss: 21562166.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820966.0000 - val_loss: 21563568.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820274.0000 - val_loss: 21563068.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818798.0000 - val_loss: 21570006.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820760.0000 - val_loss: 21568322.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819268.0000 - val_loss: 21563174.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820330.0000 - val_loss: 21563988.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819340.0000 - val_loss: 21562376.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819230.0000 - val_loss: 21562168.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21820106.0000 - val_loss: 21567146.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819190.0000 - val_loss: 21563460.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820516.0000 - val_loss: 21565840.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: 21819368.0000 - val_loss: 21563306.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818792.0000 - val_loss: 21568554.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819358.0000 - val_loss: 21564036.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819618.0000 - val_loss: 21565918.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819064.0000 - val_loss: 21570256.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820592.0000 - val_loss: 21566804.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21821028.0000 - val_loss: 21565662.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819908.0000 - val_loss: 21567228.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819294.0000 - val_loss: 21569802.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819788.0000 - val_loss: 21565666.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819956.0000 - val_loss: 21565106.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819586.0000 - val_loss: 21567810.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820346.0000 - val_loss: 21568800.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21821002.0000 - val_loss: 21567194.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819754.0000 - val_loss: 21564390.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819788.0000 - val_loss: 21566534.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819242.0000 - val_loss: 21563864.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21817282.0000 - val_loss: 21569892.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819462.0000 - val_loss: 21564546.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819608.0000 - val_loss: 21566094.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818670.0000 - val_loss: 21565444.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819294.0000 - val_loss: 21565092.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21821226.0000 - val_loss: 21564044.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820448.0000 - val_loss: 21564218.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820130.0000 - val_loss: 21566794.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819224.0000 - val_loss: 21570446.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820168.0000 - val_loss: 21564016.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819868.0000 - val_loss: 21568310.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819842.0000 - val_loss: 21565520.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820792.0000 - val_loss: 21565076.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819922.0000 - val_loss: 21568294.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820502.0000 - val_loss: 21564234.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820222.0000 - val_loss: 21564400.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819080.0000 - val_loss: 21562920.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819946.0000 - val_loss: 21565676.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819158.0000 - val_loss: 21567794.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820144.0000 - val_loss: 21564204.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819384.0000 - val_loss: 21563152.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820216.0000 - val_loss: 21566668.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820436.0000 - val_loss: 21566882.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819438.0000 - val_loss: 21570648.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820458.0000 - val_loss: 21568822.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819740.0000 - val_loss: 21568490.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820504.0000 - val_loss: 21565418.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820324.0000 - val_loss: 21564244.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819692.0000 - val_loss: 21562816.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820138.0000 - val_loss: 21565360.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818644.0000 - val_loss: 21562902.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21821038.0000 - val_loss: 21564160.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21818234.0000 - val_loss: 21570244.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819964.0000 - val_loss: 21570660.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820440.0000 - val_loss: 21566784.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819032.0000 - val_loss: 21562898.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820334.0000 - val_loss: 21563752.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819476.0000 - val_loss: 21565150.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820652.0000 - val_loss: 21565416.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819754.0000 - val_loss: 21563686.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820094.0000 - val_loss: 21562942.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820224.0000 - val_loss: 21563458.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820424.0000 - val_loss: 21563438.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21820418.0000 - val_loss: 21565406.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21819770.0000 - val_loss: 21565712.0000\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 18685670.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: inf - val_loss: 1097308040983385966349580763136.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 129791909932629661093698994176.0000 - val_loss: 194145561908855379834437632.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 22963945868991399196622848.0000 - val_loss: 34349967667870931353600.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 4062986017177029574656.0000 - val_loss: 6077496096706265088.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 718859602728321024.0000 - val_loss: 1075279220965376.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 127187504070656.0000 - val_loss: 190263033856.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 22532874240.0000 - val_loss: 54670432.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 24587104.0000 - val_loss: 21566536.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20494996.0000 - val_loss: 21566306.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20491576.0000 - val_loss: 21576462.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20491396.0000 - val_loss: 21563674.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20486520.0000 - val_loss: 21562146.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20492104.0000 - val_loss: 21574530.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483394.0000 - val_loss: 21563368.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20493438.0000 - val_loss: 21570548.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490774.0000 - val_loss: 21565680.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20482770.0000 - val_loss: 21562280.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20491320.0000 - val_loss: 21564224.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490962.0000 - val_loss: 21564082.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20488656.0000 - val_loss: 21585896.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490326.0000 - val_loss: 21563464.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20489154.0000 - val_loss: 21566514.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20487936.0000 - val_loss: 21593466.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20491772.0000 - val_loss: 21564108.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20484736.0000 - val_loss: 21585836.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490720.0000 - val_loss: 21562216.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20492494.0000 - val_loss: 21583956.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20486218.0000 - val_loss: 21563308.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483278.0000 - val_loss: 21574612.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20488522.0000 - val_loss: 21562088.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20491938.0000 - val_loss: 21585176.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483564.0000 - val_loss: 21567890.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20492772.0000 - val_loss: 21568426.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20489538.0000 - val_loss: 21579388.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20491492.0000 - val_loss: 21565802.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20489100.0000 - val_loss: 21564630.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490200.0000 - val_loss: 21575382.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20485906.0000 - val_loss: 21562616.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20486858.0000 - val_loss: 21562348.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20491844.0000 - val_loss: 21568408.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490758.0000 - val_loss: 21570236.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20491928.0000 - val_loss: 21564338.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20493504.0000 - val_loss: 21573010.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20492736.0000 - val_loss: 21568408.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20488672.0000 - val_loss: 21562450.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490196.0000 - val_loss: 21570008.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20484616.0000 - val_loss: 21580052.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490392.0000 - val_loss: 21563572.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20487846.0000 - val_loss: 21565582.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20489196.0000 - val_loss: 21563022.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20491832.0000 - val_loss: 21563472.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 20486372.0000 - val_loss: 21562468.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20488184.0000 - val_loss: 21587750.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 20491142.0000 - val_loss: 21563856.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20489796.0000 - val_loss: 21571916.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490176.0000 - val_loss: 21570122.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20481796.0000 - val_loss: 21562212.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20482176.0000 - val_loss: 21565144.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20489566.0000 - val_loss: 21586278.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20488710.0000 - val_loss: 21567502.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20489786.0000 - val_loss: 21584922.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20492734.0000 - val_loss: 21573894.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20488388.0000 - val_loss: 21572042.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20488224.0000 - val_loss: 21576408.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20482924.0000 - val_loss: 21563870.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20494850.0000 - val_loss: 21564732.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20489244.0000 - val_loss: 21563270.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20492086.0000 - val_loss: 21572658.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490860.0000 - val_loss: 21563220.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20492888.0000 - val_loss: 21564490.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20488254.0000 - val_loss: 21563478.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483952.0000 - val_loss: 21562068.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20488578.0000 - val_loss: 21584302.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20492220.0000 - val_loss: 21565650.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490054.0000 - val_loss: 21568030.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490098.0000 - val_loss: 21575474.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490318.0000 - val_loss: 21573886.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490406.0000 - val_loss: 21575956.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20492024.0000 - val_loss: 21568424.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20489108.0000 - val_loss: 21563758.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20491740.0000 - val_loss: 21564012.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 20487988.0000 - val_loss: 21567052.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20488350.0000 - val_loss: 21562058.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20487180.0000 - val_loss: 21579816.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20488438.0000 - val_loss: 21562094.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20491288.0000 - val_loss: 21562400.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20490392.0000 - val_loss: 21562194.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20491106.0000 - val_loss: 21581616.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20492684.0000 - val_loss: 21593214.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20493546.0000 - val_loss: 21565322.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20492336.0000 - val_loss: 21563458.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20484606.0000 - val_loss: 21562086.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20489812.0000 - val_loss: 21585662.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20487770.0000 - val_loss: 21562402.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20492546.0000 - val_loss: 21566666.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20486988.0000 - val_loss: 21562068.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20491486.0000 - val_loss: 21563646.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20489072.0000 - val_loss: 21586278.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20492072.0000 - val_loss: 21577288.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20488684.0000 - val_loss: 21563856.0000\n",
      "54/54 [==============================] - 0s 956us/step - loss: 24021102.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - ETA: 0s - loss: n - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 921us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: inf - val_loss: inf\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: inf - val_loss: 27426150574274557244138830673477632.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 3244024658312427402478773552021504.0000 - val_loss: 4852478030900034389595633221632.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 573962353620279163547000242176.0000 - val_loss: 858545042264656683592581120.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 101550460600531614783504384.0000 - val_loss: 151901281327631627714560.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 17967201911287048044544.0000 - val_loss: 26875703566333378560.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 3178918188708528128.0000 - val_loss: 4755085531807744.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 562442107092992.0000 - val_loss: 841364602880.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 99546308608.0000 - val_loss: 168348464.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 39220752.0000 - val_loss: 21562146.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827848.0000 - val_loss: 21568198.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21825108.0000 - val_loss: 21569860.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827250.0000 - val_loss: 21563706.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21822060.0000 - val_loss: 21568148.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21826022.0000 - val_loss: 21570382.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21826852.0000 - val_loss: 21571236.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21815936.0000 - val_loss: 21569056.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21829568.0000 - val_loss: 21580088.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21828076.0000 - val_loss: 21580270.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21821750.0000 - val_loss: 21563676.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21825702.0000 - val_loss: 21570004.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21823992.0000 - val_loss: 21563024.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21825916.0000 - val_loss: 21569794.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818962.0000 - val_loss: 21567274.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21828174.0000 - val_loss: 21564390.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21828174.0000 - val_loss: 21572628.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827260.0000 - val_loss: 21562512.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21824804.0000 - val_loss: 21563296.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21822630.0000 - val_loss: 21563220.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21826936.0000 - val_loss: 21567606.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21823538.0000 - val_loss: 21562600.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21823486.0000 - val_loss: 21562090.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21824190.0000 - val_loss: 21583130.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21828744.0000 - val_loss: 21564580.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21825286.0000 - val_loss: 21564202.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827444.0000 - val_loss: 21567594.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 21824952.0000 - val_loss: 21563388.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21824782.0000 - val_loss: 21573622.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827584.0000 - val_loss: 21572042.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818380.0000 - val_loss: 21571372.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827304.0000 - val_loss: 21570012.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21826946.0000 - val_loss: 21568054.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21824924.0000 - val_loss: 21564078.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21828306.0000 - val_loss: 21565006.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21821094.0000 - val_loss: 21563878.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21825562.0000 - val_loss: 21569552.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819822.0000 - val_loss: 21594826.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21828090.0000 - val_loss: 21566680.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21829396.0000 - val_loss: 21570770.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21825734.0000 - val_loss: 21563476.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21824790.0000 - val_loss: 21562580.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21823500.0000 - val_loss: 21562062.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827182.0000 - val_loss: 21563588.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827610.0000 - val_loss: 21563496.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21825972.0000 - val_loss: 21566790.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21829772.0000 - val_loss: 21562570.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21826898.0000 - val_loss: 21562196.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21825636.0000 - val_loss: 21562512.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21825618.0000 - val_loss: 21569086.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21823612.0000 - val_loss: 21572372.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21820322.0000 - val_loss: 21601292.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827260.0000 - val_loss: 21579074.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21826664.0000 - val_loss: 21571126.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21828862.0000 - val_loss: 21564396.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818626.0000 - val_loss: 21598692.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21828708.0000 - val_loss: 21570744.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21813302.0000 - val_loss: 21564914.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827814.0000 - val_loss: 21564282.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21828764.0000 - val_loss: 21562078.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827402.0000 - val_loss: 21565888.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21823552.0000 - val_loss: 21562070.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21821726.0000 - val_loss: 21564536.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827510.0000 - val_loss: 21564996.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21822464.0000 - val_loss: 21582894.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827102.0000 - val_loss: 21563308.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21821652.0000 - val_loss: 21584928.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21821846.0000 - val_loss: 21586796.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21823778.0000 - val_loss: 21566656.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21826304.0000 - val_loss: 21566436.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21822512.0000 - val_loss: 21562078.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21826338.0000 - val_loss: 21566372.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21824428.0000 - val_loss: 21562280.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827782.0000 - val_loss: 21573414.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21822368.0000 - val_loss: 21598066.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827456.0000 - val_loss: 21568340.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21826620.0000 - val_loss: 21567892.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21821144.0000 - val_loss: 21577090.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21825322.0000 - val_loss: 21580834.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21827362.0000 - val_loss: 21564634.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21826220.0000 - val_loss: 21566622.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21825290.0000 - val_loss: 21567762.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21822402.0000 - val_loss: 21563858.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21825128.0000 - val_loss: 21563240.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21825866.0000 - val_loss: 21568220.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21825902.0000 - val_loss: 21562472.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21828430.0000 - val_loss: 21564124.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21823996.0000 - val_loss: 21566676.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 21827652.0000 - val_loss: 21568608.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21824554.0000 - val_loss: 21563122.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21826888.0000 - val_loss: 21574160.0000\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 18695334.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 923us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 928us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 909us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 878us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - ETA: 0s - loss: n - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 41075275894261694418793791488.0000 - val_loss: 7143203612335082993352704.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 3081699518126238562516992.0000 - val_loss: 944271535310622844518400.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 407375770424777619013632.0000 - val_loss: 124825054899928647598080.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 53851670947092766916608.0000 - val_loss: 16500816361816332435456.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 7118738037042973769728.0000 - val_loss: 2181272880570672611328.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 941038612244366098432.0000 - val_loss: 288345692931232890880.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 124397390968251219968.0000 - val_loss: 38116945521971036160.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 16444324492320178176.0000 - val_loss: 5038747879527677952.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 2173804169662562304.0000 - val_loss: 666080708132864000.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 287358841388007424.0000 - val_loss: 88050411570724864.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 37986494652088320.0000 - val_loss: 11639539613302784.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 5021500205694976.0000 - val_loss: 1538649753649152.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 663801221349376.0000 - val_loss: 203397085003776.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 87749596020736.0000 - val_loss: 26887694843904.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 11599872000000.0000 - val_loss: 3554301181952.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 1533404512256.0000 - val_loss: 469852422144.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 202722574336.0000 - val_loss: 62127026176.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 26817906688.0000 - val_loss: 8229605888.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 3563548672.0000 - val_loss: 1106111232.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 490116448.0000 - val_loss: 164843808.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 83861344.0000 - val_loss: 40551764.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 30150410.0000 - val_loss: 24089552.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 22985874.0000 - val_loss: 21895296.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 22025066.0000 - val_loss: 21598818.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21896854.0000 - val_loss: 21563876.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21884300.0000 - val_loss: 21562140.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883476.0000 - val_loss: 21562100.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883258.0000 - val_loss: 21562100.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883906.0000 - val_loss: 21562088.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882958.0000 - val_loss: 21562098.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883382.0000 - val_loss: 21562088.0000\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 0s 2ms/step - loss: 21883200.0000 - val_loss: 21562504.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883306.0000 - val_loss: 21562354.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883468.0000 - val_loss: 21562848.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883962.0000 - val_loss: 21562414.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883934.0000 - val_loss: 21562156.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883470.0000 - val_loss: 21562288.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883076.0000 - val_loss: 21562100.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883396.0000 - val_loss: 21562074.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883562.0000 - val_loss: 21562076.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883598.0000 - val_loss: 21562132.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883548.0000 - val_loss: 21562062.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883318.0000 - val_loss: 21562066.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883806.0000 - val_loss: 21562196.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883256.0000 - val_loss: 21562094.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883504.0000 - val_loss: 21562350.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883082.0000 - val_loss: 21562966.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883836.0000 - val_loss: 21562504.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883334.0000 - val_loss: 21562150.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882966.0000 - val_loss: 21562192.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883732.0000 - val_loss: 21562100.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882536.0000 - val_loss: 21562080.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883002.0000 - val_loss: 21562186.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883706.0000 - val_loss: 21562056.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882750.0000 - val_loss: 21562136.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883658.0000 - val_loss: 21562104.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882854.0000 - val_loss: 21562320.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883370.0000 - val_loss: 21562552.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883196.0000 - val_loss: 21562644.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883292.0000 - val_loss: 21562420.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882608.0000 - val_loss: 21563210.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883558.0000 - val_loss: 21562906.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882564.0000 - val_loss: 21562168.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882906.0000 - val_loss: 21562068.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883362.0000 - val_loss: 21562212.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883972.0000 - val_loss: 21562116.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882584.0000 - val_loss: 21562144.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883722.0000 - val_loss: 21562108.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883880.0000 - val_loss: 21562126.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883026.0000 - val_loss: 21562074.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883610.0000 - val_loss: 21562068.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882212.0000 - val_loss: 21562402.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882676.0000 - val_loss: 21562856.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883620.0000 - val_loss: 21562246.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883232.0000 - val_loss: 21562386.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883616.0000 - val_loss: 21562268.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21879452.0000 - val_loss: 21563038.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21884356.0000 - val_loss: 21562242.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883548.0000 - val_loss: 21562062.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21884158.0000 - val_loss: 21562058.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883056.0000 - val_loss: 21562194.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883490.0000 - val_loss: 21562334.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 21883076.0000 - val_loss: 21562070.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21882986.0000 - val_loss: 21562192.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 21883404.0000 - val_loss: 21562100.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 21882872.0000 - val_loss: 21562120.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882266.0000 - val_loss: 21562992.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882546.0000 - val_loss: 21562062.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883292.0000 - val_loss: 21562144.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883650.0000 - val_loss: 21562174.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883066.0000 - val_loss: 21562702.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883816.0000 - val_loss: 21562446.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882284.0000 - val_loss: 21562064.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883076.0000 - val_loss: 21562374.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882528.0000 - val_loss: 21562064.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21882582.0000 - val_loss: 21562584.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21880716.0000 - val_loss: 21562214.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883368.0000 - val_loss: 21562062.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883118.0000 - val_loss: 21562166.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21883502.0000 - val_loss: 21562078.0000\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 18438170.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 3756911372001939570657893285888.0000 - val_loss: 111073619898700281369591808.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 47919116303647339087659008.0000 - val_loss: 14683023751469967414919168.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 6334518528269986870329344.0000 - val_loss: 1940975923038132027523072.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 837372004885129651552256.0000 - val_loss: 256581509914350678179840.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 110693696017962524213248.0000 - val_loss: 33917950866416161783808.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 14632805427076250206208.0000 - val_loss: 4483675421144032215040.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 1934334742764925747200.0000 - val_loss: 592704743578139623424.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 255702899144609759232.0000 - val_loss: 78350565276620161024.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 33801830774903668736.0000 - val_loss: 10357304975649931264.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 4468326194839814144.0000 - val_loss: 1369151598764228608.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 590675788383125504.0000 - val_loss: 180990523148861440.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 78082462491607040.0000 - val_loss: 23925452477300736.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 10321852236824576.0000 - val_loss: 3162748955394048.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 1364464536387584.0000 - val_loss: 418090638639104.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 180371178127360.0000 - val_loss: 55268557717504.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 23843596926976.0000 - val_loss: 7306083827712.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 3151920627712.0000 - val_loss: 965863997440.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 416676610048.0000 - val_loss: 127715196928.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 55105314816.0000 - val_loss: 16912405504.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 7302984704.0000 - val_loss: 2253636352.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 983267648.0000 - val_loss: 317990464.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 148559216.0000 - val_loss: 60841568.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 38087176.0000 - val_loss: 26865678.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 23463662.0000 - val_loss: 22280244.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21535692.0000 - val_loss: 21669604.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21285918.0000 - val_loss: 21579894.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21254618.0000 - val_loss: 21568178.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21250624.0000 - val_loss: 21564306.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249338.0000 - val_loss: 21563948.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249888.0000 - val_loss: 21563170.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21250140.0000 - val_loss: 21563088.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249576.0000 - val_loss: 21563954.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249990.0000 - val_loss: 21563828.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21250034.0000 - val_loss: 21563088.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249708.0000 - val_loss: 21563480.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249254.0000 - val_loss: 21564236.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249780.0000 - val_loss: 21563024.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249528.0000 - val_loss: 21563480.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249640.0000 - val_loss: 21562442.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249428.0000 - val_loss: 21563426.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249270.0000 - val_loss: 21562860.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249684.0000 - val_loss: 21562716.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249804.0000 - val_loss: 21562954.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249512.0000 - val_loss: 21563254.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249066.0000 - val_loss: 21564406.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21248900.0000 - val_loss: 21562532.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249226.0000 - val_loss: 21563996.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249470.0000 - val_loss: 21563046.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249138.0000 - val_loss: 21564642.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249726.0000 - val_loss: 21564018.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249780.0000 - val_loss: 21563564.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249834.0000 - val_loss: 21563022.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249198.0000 - val_loss: 21562880.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249432.0000 - val_loss: 21562450.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249760.0000 - val_loss: 21563320.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21248560.0000 - val_loss: 21562092.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249394.0000 - val_loss: 21562658.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249658.0000 - val_loss: 21562652.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249314.0000 - val_loss: 21562516.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249168.0000 - val_loss: 21563710.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249814.0000 - val_loss: 21563062.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249228.0000 - val_loss: 21562518.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249010.0000 - val_loss: 21563734.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249190.0000 - val_loss: 21562348.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249682.0000 - val_loss: 21563538.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21248538.0000 - val_loss: 21564698.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21248584.0000 - val_loss: 21565654.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249652.0000 - val_loss: 21563240.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249536.0000 - val_loss: 21562994.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21248086.0000 - val_loss: 21564784.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249722.0000 - val_loss: 21563002.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249284.0000 - val_loss: 21563822.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249496.0000 - val_loss: 21563774.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249254.0000 - val_loss: 21562988.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249912.0000 - val_loss: 21562746.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249630.0000 - val_loss: 21562880.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249564.0000 - val_loss: 21563224.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249572.0000 - val_loss: 21564206.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249826.0000 - val_loss: 21563636.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249282.0000 - val_loss: 21563372.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249564.0000 - val_loss: 21564976.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249782.0000 - val_loss: 21564000.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249590.0000 - val_loss: 21562658.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249248.0000 - val_loss: 21562408.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21250366.0000 - val_loss: 21562898.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21250336.0000 - val_loss: 21562896.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249948.0000 - val_loss: 21562670.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249482.0000 - val_loss: 21563014.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249638.0000 - val_loss: 21562904.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249806.0000 - val_loss: 21562990.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249328.0000 - val_loss: 21562200.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21248214.0000 - val_loss: 21564034.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249630.0000 - val_loss: 21563464.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21247920.0000 - val_loss: 21562220.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21248214.0000 - val_loss: 21562092.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249990.0000 - val_loss: 21562116.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249144.0000 - val_loss: 21563336.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21250024.0000 - val_loss: 21563464.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249532.0000 - val_loss: 21563042.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21249084.0000 - val_loss: 21563712.0000\n",
      "54/54 [==============================] - 0s 850us/step - loss: 20960226.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 9798672562742939260041560064.0000 - val_loss: 403336437875793492705280.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 174006443493842309087232.0000 - val_loss: 53317737686070603022336.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 23002213909788287303680.0000 - val_loss: 7048168882681891782656.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 3040701834336202129408.0000 - val_loss: 931709546353756471296.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 401955977629513285632.0000 - val_loss: 123164433813235302400.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 53135245214507597824.0000 - val_loss: 16281294405711691776.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 7024037069756301312.0000 - val_loss: 2152254154075013120.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 928520321068171264.0000 - val_loss: 284510350357823488.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 122742666306781184.0000 - val_loss: 37609911919575040.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 16225566105534464.0000 - val_loss: 4971726366572544.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 2144886803398656.0000 - val_loss: 657224821112832.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 283536863002624.0000 - val_loss: 86880628506624.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 37481202319360.0000 - val_loss: 11485146251264.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 4954739179520.0000 - val_loss: 1518406467584.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 655001583616.0000 - val_loss: 200773435392.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 86605553664.0000 - val_loss: 26575194112.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 11464592384.0000 - val_loss: 3535382016.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 1532909056.0000 - val_loss: 488007264.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 220505728.0000 - val_loss: 83920048.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 46949420.0000 - val_loss: 30078650.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 23982524.0000 - val_loss: 22784534.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20945994.0000 - val_loss: 21759886.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20545628.0000 - val_loss: 21605200.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20492526.0000 - val_loss: 21578264.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20485568.0000 - val_loss: 21569744.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483914.0000 - val_loss: 21568902.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20484016.0000 - val_loss: 21569144.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483862.0000 - val_loss: 21568052.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483754.0000 - val_loss: 21567494.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20482682.0000 - val_loss: 21569744.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483936.0000 - val_loss: 21567286.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483792.0000 - val_loss: 21566034.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483898.0000 - val_loss: 21565288.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483886.0000 - val_loss: 21565774.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483682.0000 - val_loss: 21566656.0000\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 0s 2ms/step - loss: 20483102.0000 - val_loss: 21569974.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20484024.0000 - val_loss: 21569030.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483784.0000 - val_loss: 21567946.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483444.0000 - val_loss: 21567958.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483270.0000 - val_loss: 21565512.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483708.0000 - val_loss: 21567608.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20484218.0000 - val_loss: 21566512.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20482956.0000 - val_loss: 21568818.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483940.0000 - val_loss: 21566456.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483334.0000 - val_loss: 21569626.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20484256.0000 - val_loss: 21567266.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483856.0000 - val_loss: 21567536.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20482946.0000 - val_loss: 21570062.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483666.0000 - val_loss: 21568738.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483974.0000 - val_loss: 21567534.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20482816.0000 - val_loss: 21564730.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483874.0000 - val_loss: 21565434.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483934.0000 - val_loss: 21566582.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483734.0000 - val_loss: 21566996.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483666.0000 - val_loss: 21565630.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483780.0000 - val_loss: 21567154.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483596.0000 - val_loss: 21567354.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20484256.0000 - val_loss: 21566308.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483504.0000 - val_loss: 21567606.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483698.0000 - val_loss: 21569652.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483720.0000 - val_loss: 21569072.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483538.0000 - val_loss: 21569706.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20484226.0000 - val_loss: 21570250.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483786.0000 - val_loss: 21566940.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483592.0000 - val_loss: 21569448.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483368.0000 - val_loss: 21565498.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483512.0000 - val_loss: 21565922.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483436.0000 - val_loss: 21568942.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483986.0000 - val_loss: 21567304.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483890.0000 - val_loss: 21567926.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483666.0000 - val_loss: 21565686.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483338.0000 - val_loss: 21565092.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483406.0000 - val_loss: 21565694.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20484008.0000 - val_loss: 21565682.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483564.0000 - val_loss: 21565034.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20484168.0000 - val_loss: 21564814.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483696.0000 - val_loss: 21565020.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483700.0000 - val_loss: 21565390.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483604.0000 - val_loss: 21567314.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20482824.0000 - val_loss: 21563810.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483360.0000 - val_loss: 21565514.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483940.0000 - val_loss: 21566832.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483732.0000 - val_loss: 21566270.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483560.0000 - val_loss: 21565662.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20482268.0000 - val_loss: 21569262.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483842.0000 - val_loss: 21570562.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483880.0000 - val_loss: 21570184.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483428.0000 - val_loss: 21565868.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483918.0000 - val_loss: 21567334.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483670.0000 - val_loss: 21568546.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483528.0000 - val_loss: 21567744.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483696.0000 - val_loss: 21567030.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483388.0000 - val_loss: 21565622.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483502.0000 - val_loss: 21565694.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483346.0000 - val_loss: 21569698.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483902.0000 - val_loss: 21566954.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20484194.0000 - val_loss: 21567826.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483688.0000 - val_loss: 21566428.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20483482.0000 - val_loss: 21566200.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 20484184.0000 - val_loss: 21566830.0000\n",
      "54/54 [==============================] - 0s 942us/step - loss: 24026834.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 53136242909317948185247744.0000 - val_loss: 9886470786989739212800.0000\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 4265193699796290895872.0000 - val_loss: 1306909427490829107200.0000\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 563823757302138142720.0000 - val_loss: 172762884372722352128.0000\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 74532920167493533696.0000 - val_loss: 22837826278163218432.0000\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 9852637934593769472.0000 - val_loss: 3018970582948511744.0000\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 1302435569652989952.0000 - val_loss: 399082279470628864.0000\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 172170979605217280.0000 - val_loss: 52755426894151680.0000\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 22759609374605312.0000 - val_loss: 6973850604535808.0000\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 3008635596701696.0000 - val_loss: 921887550996480.0000\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 397716957954048.0000 - val_loss: 121866761011200.0000\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 52574992465920.0000 - val_loss: 16110279720960.0000\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 6950038274048.0000 - val_loss: 2129769922560.0000\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 918769696768.0000 - val_loss: 281602785280.0000\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 121470525440.0000 - val_loss: 37254602752.0000\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 16075004928.0000 - val_loss: 4948612096.0000\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 2144459648.0000 - val_loss: 675240384.0000\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 302626208.0000 - val_loss: 108789456.0000\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 59010680.0000 - val_loss: 33336672.0000\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 26736396.0000 - val_loss: 23228020.0000\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 22476318.0000 - val_loss: 21814498.0000\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21903706.0000 - val_loss: 21610980.0000\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21831124.0000 - val_loss: 21576912.0000\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21820742.0000 - val_loss: 21570972.0000\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819100.0000 - val_loss: 21565720.0000\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818604.0000 - val_loss: 21563744.0000\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819010.0000 - val_loss: 21563196.0000\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818670.0000 - val_loss: 21563266.0000\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818562.0000 - val_loss: 21565124.0000\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819068.0000 - val_loss: 21565310.0000\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: 21818348.0000 - val_loss: 21566522.0000\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818716.0000 - val_loss: 21566236.0000\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819248.0000 - val_loss: 21565886.0000\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21817952.0000 - val_loss: 21565278.0000\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818386.0000 - val_loss: 21563766.0000\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818848.0000 - val_loss: 21565162.0000\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818406.0000 - val_loss: 21565354.0000\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818668.0000 - val_loss: 21565854.0000\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818864.0000 - val_loss: 21565890.0000\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818984.0000 - val_loss: 21566236.0000\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818904.0000 - val_loss: 21567018.0000\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819270.0000 - val_loss: 21566342.0000\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818912.0000 - val_loss: 21566250.0000\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818488.0000 - val_loss: 21566028.0000\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21817884.0000 - val_loss: 21564394.0000\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819006.0000 - val_loss: 21564762.0000\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818786.0000 - val_loss: 21565200.0000\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819194.0000 - val_loss: 21564224.0000\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818872.0000 - val_loss: 21565992.0000\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818864.0000 - val_loss: 21565992.0000\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818880.0000 - val_loss: 21565570.0000\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818508.0000 - val_loss: 21564484.0000\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819296.0000 - val_loss: 21565912.0000\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818208.0000 - val_loss: 21564206.0000\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818816.0000 - val_loss: 21563868.0000\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818254.0000 - val_loss: 21565610.0000\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818316.0000 - val_loss: 21564396.0000\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818812.0000 - val_loss: 21566174.0000\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818708.0000 - val_loss: 21567748.0000\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818760.0000 - val_loss: 21566436.0000\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818364.0000 - val_loss: 21567210.0000\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21817886.0000 - val_loss: 21565230.0000\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818638.0000 - val_loss: 21565006.0000\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819064.0000 - val_loss: 21565596.0000\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21817824.0000 - val_loss: 21569048.0000\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818356.0000 - val_loss: 21565108.0000\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819034.0000 - val_loss: 21564394.0000\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818660.0000 - val_loss: 21564666.0000\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21817498.0000 - val_loss: 21563250.0000\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819552.0000 - val_loss: 21565460.0000\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819368.0000 - val_loss: 21564928.0000\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818864.0000 - val_loss: 21565310.0000\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819456.0000 - val_loss: 21565194.0000\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818802.0000 - val_loss: 21565750.0000\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818952.0000 - val_loss: 21565394.0000\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818828.0000 - val_loss: 21567154.0000\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818320.0000 - val_loss: 21563774.0000\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818666.0000 - val_loss: 21564820.0000\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819050.0000 - val_loss: 21566154.0000\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21817958.0000 - val_loss: 21564142.0000\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819542.0000 - val_loss: 21564970.0000\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818426.0000 - val_loss: 21565378.0000\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818496.0000 - val_loss: 21565908.0000\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819312.0000 - val_loss: 21566028.0000\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818414.0000 - val_loss: 21564140.0000\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818936.0000 - val_loss: 21564726.0000\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818532.0000 - val_loss: 21566850.0000\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818834.0000 - val_loss: 21567732.0000\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819042.0000 - val_loss: 21565116.0000\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818760.0000 - val_loss: 21566176.0000\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818584.0000 - val_loss: 21567630.0000\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819300.0000 - val_loss: 21567180.0000\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818852.0000 - val_loss: 21566210.0000\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21817908.0000 - val_loss: 21567892.0000\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818810.0000 - val_loss: 21565868.0000\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818368.0000 - val_loss: 21564230.0000\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819230.0000 - val_loss: 21564314.0000\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818700.0000 - val_loss: 21564244.0000\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818972.0000 - val_loss: 21564374.0000\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21819450.0000 - val_loss: 21564800.0000\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: 21818144.0000 - val_loss: 21566194.0000\n",
      "54/54 [==============================] - 0s 930us/step - loss: 18686250.0000\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 997us/step - loss: nan\n",
      "Epoch 1/100\n",
      "186/214 [=========================>....] - ETA: 0s - loss: nan  WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 991us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - ETA: 0s - loss: n - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 995us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 896us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - ETA: 0s - loss: n - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 960us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 923us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 886us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - ETA: 0s - loss: n - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 887us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 930us/step - loss: nan\n",
      "Epoch 1/100\n",
      "188/214 [=========================>....] - ETA: 0s - loss: nan   WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "214/214 [==============================] - 1s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 981us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 944us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - ETA: 0s - loss: n - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 940us/step - loss: nan\n",
      "Epoch 1/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "54/54 [==============================] - 0s 946us/step - loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [-8.10751360e+06             nan -8.46408148e+22             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002794A2380A0>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-a28818c29e27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m rnd_search_cv.fit(x_train_scaled, y_train,\n\u001b[0m\u001b[0;32m     12\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                  validation_data=(x_test_scaled,y_test))\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m             \u001b[1;31m# we clone again after setting params in case some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 876\u001b[1;33m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[0;32m    877\u001b[0m                 **self.best_params_))\n\u001b[0;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\gpuenv\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[0;32m     86\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                                (estimator, name))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002794A2380A0>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_nuerons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=5)\n",
    "rnd_search_cv.fit(x_train_scaled, y_train,\n",
    "                 epochs=100,\n",
    "                 validation_data=(x_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0013782568364911828, 'n_hidden': 0, 'n_nuerons': 79}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8107513.6"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 9032.1924 - mae: 9032.1924 - val_loss: 8932.4297 - val_mae: 8932.4297\n",
      "Epoch 2/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 8306.5215 - mae: 8306.5215 - val_loss: 7416.6787 - val_mae: 7416.6787\n",
      "Epoch 3/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 5939.6489 - mae: 5939.6489 - val_loss: 4423.9946 - val_mae: 4423.9946\n",
      "Epoch 4/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 3216.9910 - mae: 3216.9910 - val_loss: 2465.8599 - val_mae: 2465.8599\n",
      "Epoch 5/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2293.3569 - mae: 2293.3569 - val_loss: 2216.0251 - val_mae: 2216.0251\n",
      "Epoch 6/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2133.9988 - mae: 2133.9988 - val_loss: 2125.9165 - val_mae: 2125.9165\n",
      "Epoch 7/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2055.1765 - mae: 2055.1765 - val_loss: 2072.1187 - val_mae: 2072.1187\n",
      "Epoch 8/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 2005.0731 - mae: 2005.0731 - val_loss: 2037.6820 - val_mae: 2037.6820\n",
      "Epoch 9/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1968.2261 - mae: 1968.2261 - val_loss: 2013.5339 - val_mae: 2013.5339\n",
      "Epoch 10/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1939.2848 - mae: 1939.2848 - val_loss: 1986.0789 - val_mae: 1986.0789\n",
      "Epoch 11/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1915.7959 - mae: 1915.7959 - val_loss: 1961.6211 - val_mae: 1961.6211\n",
      "Epoch 12/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1895.7417 - mae: 1895.7417 - val_loss: 1938.2836 - val_mae: 1938.2836\n",
      "Epoch 13/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1879.8307 - mae: 1879.8307 - val_loss: 1927.0011 - val_mae: 1927.0011\n",
      "Epoch 14/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1866.0178 - mae: 1866.0178 - val_loss: 1912.5618 - val_mae: 1912.5618\n",
      "Epoch 15/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1852.9683 - mae: 1852.9683 - val_loss: 1898.7664 - val_mae: 1898.7664\n",
      "Epoch 16/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1841.6537 - mae: 1841.6537 - val_loss: 1888.4100 - val_mae: 1888.4100\n",
      "Epoch 17/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1831.1874 - mae: 1831.1874 - val_loss: 1876.3231 - val_mae: 1876.3231\n",
      "Epoch 18/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1822.4265 - mae: 1822.4265 - val_loss: 1869.2019 - val_mae: 1869.2019\n",
      "Epoch 19/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1813.7092 - mae: 1813.7092 - val_loss: 1858.7291 - val_mae: 1858.7291\n",
      "Epoch 20/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1806.0570 - mae: 1806.0570 - val_loss: 1855.0038 - val_mae: 1855.0038\n",
      "Epoch 21/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1798.8700 - mae: 1798.8700 - val_loss: 1846.3054 - val_mae: 1846.3054\n",
      "Epoch 22/1000\n",
      "268/268 [==============================] - 8s 29ms/step - loss: 1790.8551 - mae: 1790.8551 - val_loss: 1838.3673 - val_mae: 1838.3673\n",
      "Epoch 23/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1784.9216 - mae: 1784.9216 - val_loss: 1832.2542 - val_mae: 1832.2542\n",
      "Epoch 24/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1777.9235 - mae: 1777.9235 - val_loss: 1825.2853 - val_mae: 1825.2853\n",
      "Epoch 25/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1771.5325 - mae: 1771.5325 - val_loss: 1817.6442 - val_mae: 1817.6442\n",
      "Epoch 26/1000\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 1765.8521 - mae: 1765.8521 - val_loss: 1816.1344 - val_mae: 1816.1344\n",
      "Epoch 27/1000\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 1760.5466 - mae: 1760.5466 - val_loss: 1807.6210 - val_mae: 1807.6210\n",
      "Epoch 28/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1754.6985 - mae: 1754.6985 - val_loss: 1801.4664 - val_mae: 1801.4664\n",
      "Epoch 29/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1749.6461 - mae: 1749.6461 - val_loss: 1797.7599 - val_mae: 1797.7599\n",
      "Epoch 30/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1745.2526 - mae: 1745.2526 - val_loss: 1794.0625 - val_mae: 1794.0625\n",
      "Epoch 31/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1740.5126 - mae: 1740.5126 - val_loss: 1788.4366 - val_mae: 1788.4366\n",
      "Epoch 32/1000\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1737.1106 - mae: 1737.1106 - val_loss: 1784.3695 - val_mae: 1784.3695\n",
      "Epoch 33/1000\n",
      "268/268 [==============================] - 3s 12ms/step - loss: 1734.2216 - mae: 1734.2216 - val_loss: 1779.3070 - val_mae: 1779.3070\n",
      "Epoch 34/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1730.4941 - mae: 1730.4941 - val_loss: 1778.5792 - val_mae: 1778.5792\n",
      "Epoch 35/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1726.7025 - mae: 1726.7025 - val_loss: 1775.1077 - val_mae: 1775.1077\n",
      "Epoch 36/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1724.1422 - mae: 1724.1422 - val_loss: 1773.1764 - val_mae: 1773.1764\n",
      "Epoch 37/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1720.5049 - mae: 1720.5049 - val_loss: 1775.2015 - val_mae: 1775.2015\n",
      "Epoch 38/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1716.6558 - mae: 1716.6558 - val_loss: 1764.4252 - val_mae: 1764.4252\n",
      "Epoch 39/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1714.5073 - mae: 1714.5073 - val_loss: 1761.5887 - val_mae: 1761.5887\n",
      "Epoch 40/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1710.4475 - mae: 1710.4475 - val_loss: 1760.3248 - val_mae: 1760.3248\n",
      "Epoch 41/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1707.3802 - mae: 1707.3802 - val_loss: 1755.8613 - val_mae: 1755.8613\n",
      "Epoch 42/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1704.9747 - mae: 1704.9747 - val_loss: 1755.2209 - val_mae: 1755.2209\n",
      "Epoch 43/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1700.5731 - mae: 1700.5731 - val_loss: 1754.3236 - val_mae: 1754.3236\n",
      "Epoch 44/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1697.7754 - mae: 1697.7754 - val_loss: 1748.4390 - val_mae: 1748.4390\n",
      "Epoch 45/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1693.3291 - mae: 1693.3291 - val_loss: 1744.3820 - val_mae: 1744.3820\n",
      "Epoch 46/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1690.7040 - mae: 1690.7040 - val_loss: 1744.8815 - val_mae: 1744.8815\n",
      "Epoch 47/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1688.3516 - mae: 1688.3516 - val_loss: 1740.9469 - val_mae: 1740.9469\n",
      "Epoch 48/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1685.2469 - mae: 1685.2469 - val_loss: 1739.1600 - val_mae: 1739.1600\n",
      "Epoch 49/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1682.5101 - mae: 1682.5101 - val_loss: 1735.5493 - val_mae: 1735.5493\n",
      "Epoch 50/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1679.5128 - mae: 1679.5128 - val_loss: 1731.8685 - val_mae: 1731.8685\n",
      "Epoch 51/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1676.1310 - mae: 1676.1310 - val_loss: 1732.7739 - val_mae: 1732.7739\n",
      "Epoch 52/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1673.0846 - mae: 1673.0846 - val_loss: 1733.8088 - val_mae: 1733.8088\n",
      "Epoch 53/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1671.0367 - mae: 1671.0367 - val_loss: 1726.0850 - val_mae: 1726.0850\n",
      "Epoch 54/1000\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 1668.2875 - mae: 1668.2875 - val_loss: 1725.5409 - val_mae: 1725.5409\n",
      "Epoch 55/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1666.9309 - mae: 1666.9309 - val_loss: 1722.4357 - val_mae: 1722.4357\n",
      "Epoch 56/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1663.9590 - mae: 1663.9590 - val_loss: 1721.5082 - val_mae: 1721.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1662.5415 - mae: 1662.5415 - val_loss: 1719.1923 - val_mae: 1719.1923\n",
      "Epoch 58/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1659.4038 - mae: 1659.4038 - val_loss: 1721.2903 - val_mae: 1721.2903\n",
      "Epoch 59/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1656.7361 - mae: 1656.7361 - val_loss: 1721.6589 - val_mae: 1721.6589\n",
      "Epoch 60/1000\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 1656.3243 - mae: 1656.3243 - val_loss: 1716.8005 - val_mae: 1716.8005\n",
      "Epoch 61/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1653.3484 - mae: 1653.3484 - val_loss: 1711.5839 - val_mae: 1711.5839\n",
      "Epoch 62/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1651.3530 - mae: 1651.3530 - val_loss: 1709.2083 - val_mae: 1709.2083\n",
      "Epoch 63/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1649.4594 - mae: 1649.4594 - val_loss: 1711.3033 - val_mae: 1711.3033\n",
      "Epoch 64/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1647.2811 - mae: 1647.2811 - val_loss: 1707.9565 - val_mae: 1707.9565\n",
      "Epoch 65/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1644.7848 - mae: 1644.7848 - val_loss: 1713.9998 - val_mae: 1713.9998\n",
      "Epoch 66/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1643.9988 - mae: 1643.9988 - val_loss: 1706.7050 - val_mae: 1706.7050\n",
      "Epoch 67/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1642.2290 - mae: 1642.2290 - val_loss: 1706.1781 - val_mae: 1706.1781\n",
      "Epoch 68/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1639.7218 - mae: 1639.7218 - val_loss: 1703.0925 - val_mae: 1703.0925\n",
      "Epoch 69/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1638.0085 - mae: 1638.0085 - val_loss: 1703.8820 - val_mae: 1703.8820\n",
      "Epoch 70/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1635.7701 - mae: 1635.7701 - val_loss: 1701.5924 - val_mae: 1701.5924\n",
      "Epoch 71/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1633.8640 - mae: 1633.8640 - val_loss: 1698.5664 - val_mae: 1698.5664\n",
      "Epoch 72/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1632.0688 - mae: 1632.0688 - val_loss: 1701.8683 - val_mae: 1701.8683\n",
      "Epoch 73/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1630.0980 - mae: 1630.0980 - val_loss: 1696.1987 - val_mae: 1696.1987\n",
      "Epoch 74/1000\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 1629.0157 - mae: 1629.0157 - val_loss: 1692.7587 - val_mae: 1692.7587\n",
      "Epoch 75/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1627.6787 - mae: 1627.6787 - val_loss: 1693.7982 - val_mae: 1693.7982\n",
      "Epoch 76/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1624.4126 - mae: 1624.4126 - val_loss: 1689.9720 - val_mae: 1689.9720\n",
      "Epoch 77/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1624.3685 - mae: 1624.3685 - val_loss: 1694.3870 - val_mae: 1694.3870\n",
      "Epoch 78/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1621.4471 - mae: 1621.4471 - val_loss: 1689.3972 - val_mae: 1689.3972\n",
      "Epoch 79/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1619.5896 - mae: 1619.5896 - val_loss: 1694.3702 - val_mae: 1694.3702\n",
      "Epoch 80/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1618.3496 - mae: 1618.3496 - val_loss: 1686.3904 - val_mae: 1686.3904\n",
      "Epoch 81/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1617.3129 - mae: 1617.3129 - val_loss: 1686.2402 - val_mae: 1686.2402\n",
      "Epoch 82/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1615.1987 - mae: 1615.1987 - val_loss: 1681.9255 - val_mae: 1681.9255\n",
      "Epoch 83/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1614.0544 - mae: 1614.0544 - val_loss: 1682.6777 - val_mae: 1682.6777\n",
      "Epoch 84/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1612.1852 - mae: 1612.1852 - val_loss: 1684.5813 - val_mae: 1684.5813\n",
      "Epoch 85/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1610.7792 - mae: 1610.7792 - val_loss: 1682.4977 - val_mae: 1682.4977\n",
      "Epoch 86/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1608.8739 - mae: 1608.8739 - val_loss: 1680.1479 - val_mae: 1680.1479\n",
      "Epoch 87/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1607.5797 - mae: 1607.5797 - val_loss: 1677.6514 - val_mae: 1677.6514\n",
      "Epoch 88/1000\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 1605.4380 - mae: 1605.4380 - val_loss: 1676.6813 - val_mae: 1676.6813\n",
      "Epoch 89/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1603.9252 - mae: 1603.9252 - val_loss: 1681.1409 - val_mae: 1681.1409\n",
      "Epoch 90/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1602.8738 - mae: 1602.8738 - val_loss: 1675.7101 - val_mae: 1675.7101\n",
      "Epoch 91/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1601.0885 - mae: 1601.0885 - val_loss: 1671.5500 - val_mae: 1671.5500\n",
      "Epoch 92/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1599.6520 - mae: 1599.6520 - val_loss: 1674.8916 - val_mae: 1674.8916\n",
      "Epoch 93/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1597.7860 - mae: 1597.7860 - val_loss: 1670.6919 - val_mae: 1670.6919\n",
      "Epoch 94/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1595.9082 - mae: 1595.9082 - val_loss: 1670.0645 - val_mae: 1670.0645\n",
      "Epoch 95/1000\n",
      "268/268 [==============================] - 3s 12ms/step - loss: 1594.1689 - mae: 1594.1689 - val_loss: 1666.8735 - val_mae: 1666.8735\n",
      "Epoch 96/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1592.7814 - mae: 1592.7814 - val_loss: 1667.3090 - val_mae: 1667.3090\n",
      "Epoch 97/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1590.8884 - mae: 1590.8884 - val_loss: 1670.9191 - val_mae: 1670.9191\n",
      "Epoch 98/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1589.5934 - mae: 1589.5934 - val_loss: 1666.0674 - val_mae: 1666.0674\n",
      "Epoch 99/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1587.4536 - mae: 1587.4536 - val_loss: 1663.0929 - val_mae: 1663.0929\n",
      "Epoch 100/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1586.1567 - mae: 1586.1567 - val_loss: 1662.0326 - val_mae: 1662.0326\n",
      "Epoch 101/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1584.3640 - mae: 1584.3640 - val_loss: 1660.7119 - val_mae: 1660.7119\n",
      "Epoch 102/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1582.7683 - mae: 1582.7683 - val_loss: 1659.2373 - val_mae: 1659.2373\n",
      "Epoch 103/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1581.5410 - mae: 1581.5410 - val_loss: 1660.1737 - val_mae: 1660.1737\n",
      "Epoch 104/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1579.1332 - mae: 1579.1332 - val_loss: 1656.7147 - val_mae: 1656.7147\n",
      "Epoch 105/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1578.0870 - mae: 1578.0870 - val_loss: 1659.7496 - val_mae: 1659.7496\n",
      "Epoch 106/1000\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 1576.4679 - mae: 1576.4679 - val_loss: 1655.6487 - val_mae: 1655.6487\n",
      "Epoch 107/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1574.9722 - mae: 1574.9722 - val_loss: 1659.2124 - val_mae: 1659.2124\n",
      "Epoch 108/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1573.6799 - mae: 1573.6799 - val_loss: 1655.9109 - val_mae: 1655.9109\n",
      "Epoch 109/1000\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1572.1404 - mae: 1572.1404 - val_loss: 1650.0491 - val_mae: 1650.0491\n",
      "Epoch 110/1000\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 1570.6163 - mae: 1570.6163 - val_loss: 1647.8773 - val_mae: 1647.8773\n",
      "Epoch 111/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1568.5743 - mae: 1568.5743 - val_loss: 1649.5942 - val_mae: 1649.5942\n",
      "Epoch 112/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1567.3818 - mae: 1567.3818 - val_loss: 1649.8993 - val_mae: 1649.8993\n",
      "Epoch 113/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1566.2065 - mae: 1566.2065 - val_loss: 1644.3759 - val_mae: 1644.3759\n",
      "Epoch 114/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1564.5076 - mae: 1564.5076 - val_loss: 1641.6675 - val_mae: 1641.6675\n",
      "Epoch 115/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1563.2075 - mae: 1563.2075 - val_loss: 1646.6420 - val_mae: 1646.6420\n",
      "Epoch 116/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1562.0071 - mae: 1562.0071 - val_loss: 1646.6503 - val_mae: 1646.6503\n",
      "Epoch 117/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1560.0040 - mae: 1560.0040 - val_loss: 1644.9567 - val_mae: 1644.9567\n",
      "Epoch 118/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1558.8138 - mae: 1558.8138 - val_loss: 1641.7784 - val_mae: 1641.7784\n",
      "Epoch 119/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1557.8917 - mae: 1557.8917 - val_loss: 1637.6816 - val_mae: 1637.6816\n",
      "Epoch 120/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1555.8059 - mae: 1555.8059 - val_loss: 1635.2692 - val_mae: 1635.2692\n",
      "Epoch 121/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1555.3729 - mae: 1555.3729 - val_loss: 1637.0815 - val_mae: 1637.0815\n",
      "Epoch 122/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1553.8019 - mae: 1553.8019 - val_loss: 1636.1495 - val_mae: 1636.1495\n",
      "Epoch 123/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1551.6055 - mae: 1551.6055 - val_loss: 1638.1598 - val_mae: 1638.1598\n",
      "Epoch 124/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1551.0524 - mae: 1551.0524 - val_loss: 1632.1748 - val_mae: 1632.1748\n",
      "Epoch 125/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1549.8207 - mae: 1549.8207 - val_loss: 1631.3234 - val_mae: 1631.3234\n",
      "Epoch 126/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1548.8274 - mae: 1548.8274 - val_loss: 1629.3207 - val_mae: 1629.3207\n",
      "Epoch 127/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1546.7362 - mae: 1546.7362 - val_loss: 1627.8236 - val_mae: 1627.8236\n",
      "Epoch 128/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1546.3402 - mae: 1546.3402 - val_loss: 1629.5684 - val_mae: 1629.5684\n",
      "Epoch 129/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1544.7172 - mae: 1544.7172 - val_loss: 1627.8906 - val_mae: 1627.8906\n",
      "Epoch 130/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1543.1593 - mae: 1543.1593 - val_loss: 1625.8722 - val_mae: 1625.8722\n",
      "Epoch 131/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1541.6455 - mae: 1541.6455 - val_loss: 1626.2729 - val_mae: 1626.2729\n",
      "Epoch 132/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1541.2267 - mae: 1541.2267 - val_loss: 1627.0127 - val_mae: 1627.0127\n",
      "Epoch 133/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1539.5527 - mae: 1539.5527 - val_loss: 1628.6334 - val_mae: 1628.6334\n",
      "Epoch 134/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1538.6036 - mae: 1538.6036 - val_loss: 1623.6938 - val_mae: 1623.6938\n",
      "Epoch 135/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1537.3118 - mae: 1537.3118 - val_loss: 1628.7874 - val_mae: 1628.7874\n",
      "Epoch 136/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1537.5289 - mae: 1537.5289 - val_loss: 1624.4504 - val_mae: 1624.4504\n",
      "Epoch 137/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1535.1787 - mae: 1535.1787 - val_loss: 1623.6729 - val_mae: 1623.6729\n",
      "Epoch 138/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1534.6426 - mae: 1534.6426 - val_loss: 1626.2800 - val_mae: 1626.2800\n",
      "Epoch 139/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1533.6189 - mae: 1533.6189 - val_loss: 1619.9746 - val_mae: 1619.9746\n",
      "Epoch 140/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1533.5785 - mae: 1533.5785 - val_loss: 1620.8339 - val_mae: 1620.8339\n",
      "Epoch 141/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1531.1471 - mae: 1531.1471 - val_loss: 1617.8301 - val_mae: 1617.8301\n",
      "Epoch 142/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1531.5302 - mae: 1531.5302 - val_loss: 1621.4749 - val_mae: 1621.4749\n",
      "Epoch 143/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1529.2948 - mae: 1529.2948 - val_loss: 1614.1892 - val_mae: 1614.1892\n",
      "Epoch 144/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1528.5526 - mae: 1528.5526 - val_loss: 1617.4259 - val_mae: 1617.4259\n",
      "Epoch 145/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1527.8279 - mae: 1527.8279 - val_loss: 1619.2803 - val_mae: 1619.2803\n",
      "Epoch 146/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1526.5006 - mae: 1526.5006 - val_loss: 1617.9675 - val_mae: 1617.9675\n",
      "Epoch 147/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1525.6011 - mae: 1525.6011 - val_loss: 1614.3096 - val_mae: 1614.3096\n",
      "Epoch 148/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1524.5924 - mae: 1524.5924 - val_loss: 1615.4481 - val_mae: 1615.4481\n",
      "Epoch 149/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1524.0935 - mae: 1524.0935 - val_loss: 1616.6404 - val_mae: 1616.6404\n",
      "Epoch 150/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1522.3696 - mae: 1522.3696 - val_loss: 1612.1669 - val_mae: 1612.1669\n",
      "Epoch 151/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1522.2329 - mae: 1522.2329 - val_loss: 1611.9143 - val_mae: 1611.9143\n",
      "Epoch 152/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1520.7429 - mae: 1520.7429 - val_loss: 1612.7347 - val_mae: 1612.7347\n",
      "Epoch 153/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1520.2299 - mae: 1520.2299 - val_loss: 1610.1968 - val_mae: 1610.1968\n",
      "Epoch 154/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1518.3417 - mae: 1518.3417 - val_loss: 1616.2649 - val_mae: 1616.2649\n",
      "Epoch 155/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1518.7020 - mae: 1518.7020 - val_loss: 1611.5295 - val_mae: 1611.5295\n",
      "Epoch 156/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1517.6112 - mae: 1517.6112 - val_loss: 1613.1885 - val_mae: 1613.1885\n",
      "Epoch 157/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1516.2612 - mae: 1516.2612 - val_loss: 1608.0295 - val_mae: 1608.0295\n",
      "Epoch 158/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1515.4083 - mae: 1515.4083 - val_loss: 1605.7662 - val_mae: 1605.7662\n",
      "Epoch 159/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1513.8701 - mae: 1513.8701 - val_loss: 1603.2019 - val_mae: 1603.2019\n",
      "Epoch 160/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1513.7142 - mae: 1513.7142 - val_loss: 1610.1317 - val_mae: 1610.1317\n",
      "Epoch 161/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1512.8691 - mae: 1512.8691 - val_loss: 1604.6503 - val_mae: 1604.6503\n",
      "Epoch 162/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1511.1959 - mae: 1511.1959 - val_loss: 1603.4161 - val_mae: 1603.4161\n",
      "Epoch 163/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1511.6406 - mae: 1511.6406 - val_loss: 1604.7457 - val_mae: 1604.7457\n",
      "Epoch 164/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1509.4137 - mae: 1509.4137 - val_loss: 1603.1676 - val_mae: 1603.1676\n",
      "Epoch 165/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1509.2479 - mae: 1509.2479 - val_loss: 1605.7083 - val_mae: 1605.7083\n",
      "Epoch 166/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1508.1262 - mae: 1508.1262 - val_loss: 1600.2314 - val_mae: 1600.2314\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 2ms/step - loss: 1506.6161 - mae: 1506.6161 - val_loss: 1600.9099 - val_mae: 1600.9099\n",
      "Epoch 168/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1505.2449 - mae: 1505.2449 - val_loss: 1605.1730 - val_mae: 1605.1730\n",
      "Epoch 169/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1504.6956 - mae: 1504.6956 - val_loss: 1598.7914 - val_mae: 1598.7914\n",
      "Epoch 170/1000\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 1503.4857 - mae: 1503.4857 - val_loss: 1598.2031 - val_mae: 1598.2031\n",
      "Epoch 171/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1502.2345 - mae: 1502.2345 - val_loss: 1600.2708 - val_mae: 1600.2708\n",
      "Epoch 172/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1501.7748 - mae: 1501.7748 - val_loss: 1595.9406 - val_mae: 1595.9406\n",
      "Epoch 173/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1499.7306 - mae: 1499.7306 - val_loss: 1594.0157 - val_mae: 1594.0157\n",
      "Epoch 174/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1499.4858 - mae: 1499.4858 - val_loss: 1596.0402 - val_mae: 1596.0402\n",
      "Epoch 175/1000\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 1498.3442 - mae: 1498.3442 - val_loss: 1590.5005 - val_mae: 1590.5005\n",
      "Epoch 176/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1497.4908 - mae: 1497.4908 - val_loss: 1594.9241 - val_mae: 1594.9241\n",
      "Epoch 177/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1495.7399 - mae: 1495.7399 - val_loss: 1591.4379 - val_mae: 1591.4379\n",
      "Epoch 178/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1495.4607 - mae: 1495.4607 - val_loss: 1591.6968 - val_mae: 1591.6968\n",
      "Epoch 179/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1494.2733 - mae: 1494.2733 - val_loss: 1592.0486 - val_mae: 1592.0486\n",
      "Epoch 180/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1493.0625 - mae: 1493.0625 - val_loss: 1589.1610 - val_mae: 1589.1610\n",
      "Epoch 181/1000\n",
      "268/268 [==============================] - 3s 13ms/step - loss: 1492.0802 - mae: 1492.0802 - val_loss: 1587.9281 - val_mae: 1587.9281\n",
      "Epoch 182/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1491.7308 - mae: 1491.7308 - val_loss: 1586.8486 - val_mae: 1586.8486\n",
      "Epoch 183/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1490.1377 - mae: 1490.1377 - val_loss: 1582.4972 - val_mae: 1582.4972\n",
      "Epoch 184/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1488.9812 - mae: 1488.9812 - val_loss: 1584.0249 - val_mae: 1584.0249\n",
      "Epoch 185/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1488.5566 - mae: 1488.5566 - val_loss: 1582.9573 - val_mae: 1582.9573\n",
      "Epoch 186/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1486.9728 - mae: 1486.9728 - val_loss: 1588.4447 - val_mae: 1588.4447\n",
      "Epoch 187/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1486.7147 - mae: 1486.7147 - val_loss: 1581.4484 - val_mae: 1581.4484\n",
      "Epoch 188/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1484.6937 - mae: 1484.6937 - val_loss: 1583.2443 - val_mae: 1583.2443\n",
      "Epoch 189/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1483.7192 - mae: 1483.7192 - val_loss: 1581.0302 - val_mae: 1581.0302\n",
      "Epoch 190/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1482.8690 - mae: 1482.8690 - val_loss: 1578.2776 - val_mae: 1578.2776\n",
      "Epoch 191/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1481.7330 - mae: 1481.7330 - val_loss: 1575.6305 - val_mae: 1575.6305\n",
      "Epoch 192/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1480.8743 - mae: 1480.8743 - val_loss: 1573.6840 - val_mae: 1573.6840\n",
      "Epoch 193/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1480.6093 - mae: 1480.6093 - val_loss: 1575.2555 - val_mae: 1575.2555\n",
      "Epoch 194/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1478.7253 - mae: 1478.7253 - val_loss: 1578.3051 - val_mae: 1578.3051\n",
      "Epoch 195/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1477.7819 - mae: 1477.7819 - val_loss: 1573.0074 - val_mae: 1573.0074\n",
      "Epoch 196/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1476.3796 - mae: 1476.3796 - val_loss: 1576.7809 - val_mae: 1576.7809\n",
      "Epoch 197/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1475.9360 - mae: 1475.9360 - val_loss: 1572.6273 - val_mae: 1572.6273\n",
      "Epoch 198/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1474.2148 - mae: 1474.2148 - val_loss: 1568.6815 - val_mae: 1568.6815\n",
      "Epoch 199/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1473.4868 - mae: 1473.4868 - val_loss: 1570.9087 - val_mae: 1570.9087\n",
      "Epoch 200/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1472.6927 - mae: 1472.6927 - val_loss: 1567.7865 - val_mae: 1567.7865\n",
      "Epoch 201/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1471.4983 - mae: 1471.4983 - val_loss: 1565.3805 - val_mae: 1565.3805\n",
      "Epoch 202/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1470.4174 - mae: 1470.4174 - val_loss: 1565.7760 - val_mae: 1565.7760\n",
      "Epoch 203/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1469.3077 - mae: 1469.3077 - val_loss: 1568.0145 - val_mae: 1568.0145\n",
      "Epoch 204/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1468.6312 - mae: 1468.6312 - val_loss: 1564.1876 - val_mae: 1564.1876\n",
      "Epoch 205/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1467.4675 - mae: 1467.4675 - val_loss: 1561.3083 - val_mae: 1561.3083\n",
      "Epoch 206/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1465.5364 - mae: 1465.5364 - val_loss: 1561.5232 - val_mae: 1561.5232\n",
      "Epoch 207/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1465.9080 - mae: 1465.9080 - val_loss: 1561.3053 - val_mae: 1561.3053\n",
      "Epoch 208/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1464.9697 - mae: 1464.9697 - val_loss: 1563.5459 - val_mae: 1563.5459\n",
      "Epoch 209/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1463.3440 - mae: 1463.3440 - val_loss: 1557.2302 - val_mae: 1557.2302\n",
      "Epoch 210/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1462.9158 - mae: 1462.9158 - val_loss: 1560.3018 - val_mae: 1560.3018\n",
      "Epoch 211/1000\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 1461.5009 - mae: 1461.5009 - val_loss: 1556.5551 - val_mae: 1556.5551\n",
      "Epoch 212/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1460.0934 - mae: 1460.0934 - val_loss: 1559.5620 - val_mae: 1559.5620\n",
      "Epoch 213/1000\n",
      "268/268 [==============================] - 7s 27ms/step - loss: 1459.6605 - mae: 1459.6605 - val_loss: 1554.2427 - val_mae: 1554.2427\n",
      "Epoch 214/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1458.6306 - mae: 1458.6306 - val_loss: 1551.3933 - val_mae: 1551.3933\n",
      "Epoch 215/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1457.8190 - mae: 1457.8190 - val_loss: 1554.1945 - val_mae: 1554.1945\n",
      "Epoch 216/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1457.0715 - mae: 1457.0715 - val_loss: 1553.2410 - val_mae: 1553.2410\n",
      "Epoch 217/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1455.3861 - mae: 1455.3861 - val_loss: 1555.5520 - val_mae: 1555.5520\n",
      "Epoch 218/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1454.6959 - mae: 1454.6959 - val_loss: 1552.8849 - val_mae: 1552.8849\n",
      "Epoch 219/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1454.0214 - mae: 1454.0214 - val_loss: 1546.4446 - val_mae: 1546.4446\n",
      "Epoch 220/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1452.8794 - mae: 1452.8794 - val_loss: 1548.1207 - val_mae: 1548.1207\n",
      "Epoch 221/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1451.7755 - mae: 1451.7755 - val_loss: 1547.7626 - val_mae: 1547.7626\n",
      "Epoch 222/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1450.9119 - mae: 1450.9119 - val_loss: 1544.1772 - val_mae: 1544.1772\n",
      "Epoch 223/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1449.7861 - mae: 1449.7861 - val_loss: 1546.6639 - val_mae: 1546.6639\n",
      "Epoch 224/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1448.9329 - mae: 1448.9329 - val_loss: 1542.5789 - val_mae: 1542.5789\n",
      "Epoch 225/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1447.9763 - mae: 1447.9763 - val_loss: 1542.5869 - val_mae: 1542.5869\n",
      "Epoch 226/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1447.9259 - mae: 1447.9259 - val_loss: 1540.4327 - val_mae: 1540.4327\n",
      "Epoch 227/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1446.7998 - mae: 1446.7998 - val_loss: 1544.3546 - val_mae: 1544.3546\n",
      "Epoch 228/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1445.0692 - mae: 1445.0692 - val_loss: 1536.7994 - val_mae: 1536.7994\n",
      "Epoch 229/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1445.1733 - mae: 1445.1733 - val_loss: 1539.9396 - val_mae: 1539.9396\n",
      "Epoch 230/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1443.4193 - mae: 1443.4193 - val_loss: 1545.0221 - val_mae: 1545.0221\n",
      "Epoch 231/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1443.4222 - mae: 1443.4222 - val_loss: 1534.8005 - val_mae: 1534.8005\n",
      "Epoch 232/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1442.5583 - mae: 1442.5583 - val_loss: 1535.4635 - val_mae: 1535.4635\n",
      "Epoch 233/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1440.9877 - mae: 1440.9877 - val_loss: 1536.8413 - val_mae: 1536.8413\n",
      "Epoch 234/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1440.8381 - mae: 1440.8381 - val_loss: 1532.5785 - val_mae: 1532.5785\n",
      "Epoch 235/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1439.4929 - mae: 1439.4929 - val_loss: 1532.9989 - val_mae: 1532.9989\n",
      "Epoch 236/1000\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 1438.3584 - mae: 1438.3584 - val_loss: 1532.2578 - val_mae: 1532.2578\n",
      "Epoch 237/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1438.4576 - mae: 1438.4576 - val_loss: 1532.8149 - val_mae: 1532.8149\n",
      "Epoch 238/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1437.2141 - mae: 1437.2141 - val_loss: 1532.2360 - val_mae: 1532.2360\n",
      "Epoch 239/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1436.1473 - mae: 1436.1473 - val_loss: 1533.9382 - val_mae: 1533.9382\n",
      "Epoch 240/1000\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1435.6625 - mae: 1435.6625 - val_loss: 1529.4417 - val_mae: 1529.4417\n",
      "Epoch 241/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1434.6271 - mae: 1434.6271 - val_loss: 1528.0771 - val_mae: 1528.0771\n",
      "Epoch 242/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1434.2919 - mae: 1434.2919 - val_loss: 1527.8143 - val_mae: 1527.8143\n",
      "Epoch 243/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1433.4581 - mae: 1433.4581 - val_loss: 1527.5320 - val_mae: 1527.5320\n",
      "Epoch 244/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1432.8821 - mae: 1432.8821 - val_loss: 1530.2114 - val_mae: 1530.2114\n",
      "Epoch 245/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1432.4583 - mae: 1432.4583 - val_loss: 1526.2910 - val_mae: 1526.2910\n",
      "Epoch 246/1000\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 1431.3245 - mae: 1431.3245 - val_loss: 1526.1371 - val_mae: 1526.1371\n",
      "Epoch 247/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1430.7992 - mae: 1430.7992 - val_loss: 1526.2113 - val_mae: 1526.2113\n",
      "Epoch 248/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1429.7218 - mae: 1429.7218 - val_loss: 1524.6329 - val_mae: 1524.6329\n",
      "Epoch 249/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1429.3474 - mae: 1429.3474 - val_loss: 1523.2596 - val_mae: 1523.2596\n",
      "Epoch 250/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1428.0236 - mae: 1428.0236 - val_loss: 1522.1602 - val_mae: 1522.1602\n",
      "Epoch 251/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1428.4458 - mae: 1428.4458 - val_loss: 1523.5829 - val_mae: 1523.5829\n",
      "Epoch 252/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1427.3804 - mae: 1427.3804 - val_loss: 1520.7203 - val_mae: 1520.7203\n",
      "Epoch 253/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1426.4292 - mae: 1426.4292 - val_loss: 1520.0006 - val_mae: 1520.0006\n",
      "Epoch 254/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1426.9644 - mae: 1426.9644 - val_loss: 1520.7539 - val_mae: 1520.7539\n",
      "Epoch 255/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1425.2594 - mae: 1425.2594 - val_loss: 1522.1877 - val_mae: 1522.1877\n",
      "Epoch 256/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1425.5402 - mae: 1425.5402 - val_loss: 1519.0226 - val_mae: 1519.0226\n",
      "Epoch 257/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1424.4205 - mae: 1424.4205 - val_loss: 1519.0099 - val_mae: 1519.0099\n",
      "Epoch 258/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1423.5930 - mae: 1423.5930 - val_loss: 1517.6252 - val_mae: 1517.6252\n",
      "Epoch 259/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1421.9178 - mae: 1421.9178 - val_loss: 1516.4929 - val_mae: 1516.4929\n",
      "Epoch 260/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1422.3601 - mae: 1422.3601 - val_loss: 1514.7024 - val_mae: 1514.7024\n",
      "Epoch 261/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1421.6277 - mae: 1421.6277 - val_loss: 1516.3154 - val_mae: 1516.3154\n",
      "Epoch 262/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1421.4180 - mae: 1421.4180 - val_loss: 1515.0906 - val_mae: 1515.0906\n",
      "Epoch 263/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1420.0131 - mae: 1420.0131 - val_loss: 1514.8245 - val_mae: 1514.8245\n",
      "Epoch 264/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1419.9259 - mae: 1419.9259 - val_loss: 1513.1710 - val_mae: 1513.1710\n",
      "Epoch 265/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1418.8002 - mae: 1418.8002 - val_loss: 1514.3882 - val_mae: 1514.3882\n",
      "Epoch 266/1000\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1417.8955 - mae: 1417.8955 - val_loss: 1511.3623 - val_mae: 1511.3623\n",
      "Epoch 267/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1417.4720 - mae: 1417.4720 - val_loss: 1515.0786 - val_mae: 1515.0786\n",
      "Epoch 268/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1417.6364 - mae: 1417.6364 - val_loss: 1513.4766 - val_mae: 1513.4766\n",
      "Epoch 269/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1416.6560 - mae: 1416.6560 - val_loss: 1513.1323 - val_mae: 1513.1323\n",
      "Epoch 270/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1415.8954 - mae: 1415.8954 - val_loss: 1513.8616 - val_mae: 1513.8616\n",
      "Epoch 271/1000\n",
      "268/268 [==============================] - 9s 34ms/step - loss: 1415.8668 - mae: 1415.8668 - val_loss: 1511.2191 - val_mae: 1511.2191\n",
      "Epoch 272/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1415.8149 - mae: 1415.8149 - val_loss: 1510.0007 - val_mae: 1510.0007\n",
      "Epoch 273/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1414.8505 - mae: 1414.8505 - val_loss: 1507.8997 - val_mae: 1507.8997\n",
      "Epoch 274/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1414.4281 - mae: 1414.4281 - val_loss: 1508.7288 - val_mae: 1508.7288\n",
      "Epoch 275/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1413.3528 - mae: 1413.3528 - val_loss: 1510.7153 - val_mae: 1510.7153\n",
      "Epoch 276/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1413.6617 - mae: 1413.6617 - val_loss: 1509.2457 - val_mae: 1509.2457\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - ETA: 0s - loss: 1409.4716 - mae: 1409.471 - 0s 2ms/step - loss: 1413.2142 - mae: 1413.2142 - val_loss: 1507.1671 - val_mae: 1507.1671\n",
      "Epoch 278/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1412.0236 - mae: 1412.0236 - val_loss: 1508.0874 - val_mae: 1508.0874\n",
      "Epoch 279/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1411.3914 - mae: 1411.3914 - val_loss: 1508.1777 - val_mae: 1508.1777\n",
      "Epoch 280/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1411.6226 - mae: 1411.6226 - val_loss: 1507.5436 - val_mae: 1507.5436\n",
      "Epoch 281/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1410.6750 - mae: 1410.6750 - val_loss: 1505.9658 - val_mae: 1505.9658\n",
      "Epoch 282/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1409.4893 - mae: 1409.4893 - val_loss: 1511.0035 - val_mae: 1511.0035\n",
      "Epoch 283/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1409.8125 - mae: 1409.8125 - val_loss: 1511.0245 - val_mae: 1511.0245\n",
      "Epoch 284/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1408.8190 - mae: 1408.8190 - val_loss: 1506.4111 - val_mae: 1506.4111\n",
      "Epoch 285/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1408.9174 - mae: 1408.9174 - val_loss: 1504.1112 - val_mae: 1504.1112\n",
      "Epoch 286/1000\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 1407.5846 - mae: 1407.5846 - val_loss: 1503.4648 - val_mae: 1503.4648\n",
      "Epoch 287/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1407.2600 - mae: 1407.2600 - val_loss: 1503.2191 - val_mae: 1503.2191\n",
      "Epoch 288/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1406.9799 - mae: 1406.9799 - val_loss: 1503.3519 - val_mae: 1503.3519\n",
      "Epoch 289/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1406.3933 - mae: 1406.3933 - val_loss: 1500.4282 - val_mae: 1500.4282\n",
      "Epoch 290/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1405.8365 - mae: 1405.8365 - val_loss: 1501.6813 - val_mae: 1501.6813\n",
      "Epoch 291/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1405.1353 - mae: 1405.1353 - val_loss: 1502.2982 - val_mae: 1502.2982\n",
      "Epoch 292/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1404.8459 - mae: 1404.8459 - val_loss: 1498.9559 - val_mae: 1498.9559\n",
      "Epoch 293/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1404.3218 - mae: 1404.3218 - val_loss: 1501.6547 - val_mae: 1501.6547\n",
      "Epoch 294/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1404.3510 - mae: 1404.3510 - val_loss: 1499.8169 - val_mae: 1499.8169\n",
      "Epoch 295/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1403.4368 - mae: 1403.4368 - val_loss: 1499.4543 - val_mae: 1499.4543\n",
      "Epoch 296/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1403.0775 - mae: 1403.0775 - val_loss: 1501.7533 - val_mae: 1501.7533\n",
      "Epoch 297/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1402.1162 - mae: 1402.1162 - val_loss: 1499.6475 - val_mae: 1499.6475\n",
      "Epoch 298/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1402.2660 - mae: 1402.2660 - val_loss: 1497.9464 - val_mae: 1497.9464\n",
      "Epoch 299/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1401.7241 - mae: 1401.7241 - val_loss: 1498.6915 - val_mae: 1498.6915\n",
      "Epoch 300/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1401.1997 - mae: 1401.1997 - val_loss: 1496.4086 - val_mae: 1496.4086\n",
      "Epoch 301/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1400.3202 - mae: 1400.3202 - val_loss: 1500.0355 - val_mae: 1500.0355\n",
      "Epoch 302/1000\n",
      "268/268 [==============================] - 3s 9ms/step - loss: 1399.3666 - mae: 1399.3666 - val_loss: 1495.5336 - val_mae: 1495.5336\n",
      "Epoch 303/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1399.0490 - mae: 1399.0490 - val_loss: 1495.9229 - val_mae: 1495.9229\n",
      "Epoch 304/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1399.6414 - mae: 1399.6414 - val_loss: 1494.2719 - val_mae: 1494.2719\n",
      "Epoch 305/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1398.5289 - mae: 1398.5289 - val_loss: 1495.2996 - val_mae: 1495.2996\n",
      "Epoch 306/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1398.3284 - mae: 1398.3284 - val_loss: 1494.3129 - val_mae: 1494.3129\n",
      "Epoch 307/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1397.7118 - mae: 1397.7118 - val_loss: 1493.7999 - val_mae: 1493.7999\n",
      "Epoch 308/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1397.0332 - mae: 1397.0332 - val_loss: 1492.4769 - val_mae: 1492.4769\n",
      "Epoch 309/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1396.4720 - mae: 1396.4720 - val_loss: 1493.8557 - val_mae: 1493.8557\n",
      "Epoch 310/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1395.7780 - mae: 1395.7780 - val_loss: 1494.3191 - val_mae: 1494.3191\n",
      "Epoch 311/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1395.4093 - mae: 1395.4093 - val_loss: 1497.3602 - val_mae: 1497.3602\n",
      "Epoch 312/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1394.6201 - mae: 1394.6201 - val_loss: 1494.0358 - val_mae: 1494.0358\n",
      "Epoch 313/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1395.1860 - mae: 1395.1860 - val_loss: 1495.4597 - val_mae: 1495.4597\n",
      "Epoch 314/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1394.2684 - mae: 1394.2684 - val_loss: 1497.4954 - val_mae: 1497.4954\n",
      "Epoch 315/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1393.7699 - mae: 1393.7699 - val_loss: 1491.7302 - val_mae: 1491.7302\n",
      "Epoch 316/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1392.6051 - mae: 1392.6051 - val_loss: 1492.3157 - val_mae: 1492.3157\n",
      "Epoch 317/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1392.6814 - mae: 1392.6814 - val_loss: 1491.8417 - val_mae: 1491.8417\n",
      "Epoch 318/1000\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1391.9067 - mae: 1391.9067 - val_loss: 1491.4038 - val_mae: 1491.4038\n",
      "Epoch 319/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1392.1289 - mae: 1392.1289 - val_loss: 1493.4257 - val_mae: 1493.4257\n",
      "Epoch 320/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1391.7808 - mae: 1391.7808 - val_loss: 1494.0186 - val_mae: 1494.0186\n",
      "Epoch 321/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1390.6173 - mae: 1390.6173 - val_loss: 1488.5895 - val_mae: 1488.5895\n",
      "Epoch 322/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1390.5493 - mae: 1390.5493 - val_loss: 1489.3864 - val_mae: 1489.3864\n",
      "Epoch 323/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1390.5806 - mae: 1390.5806 - val_loss: 1487.9584 - val_mae: 1487.9584\n",
      "Epoch 324/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1389.6000 - mae: 1389.6000 - val_loss: 1491.8823 - val_mae: 1491.8823\n",
      "Epoch 325/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1389.7859 - mae: 1389.7859 - val_loss: 1489.0737 - val_mae: 1489.0737\n",
      "Epoch 326/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1389.1808 - mae: 1389.1808 - val_loss: 1487.3698 - val_mae: 1487.3698\n",
      "Epoch 327/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1388.4464 - mae: 1388.4464 - val_loss: 1486.7892 - val_mae: 1486.7892\n",
      "Epoch 328/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1387.6315 - mae: 1387.6315 - val_loss: 1486.0693 - val_mae: 1486.0693\n",
      "Epoch 329/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1387.7930 - mae: 1387.7930 - val_loss: 1485.6989 - val_mae: 1485.6989\n",
      "Epoch 330/1000\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 1386.7979 - mae: 1386.7979 - val_loss: 1482.3373 - val_mae: 1482.3373\n",
      "Epoch 331/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1388.2308 - mae: 1388.2308 - val_loss: 1484.7064 - val_mae: 1484.7064\n",
      "Epoch 332/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1386.7365 - mae: 1386.7365 - val_loss: 1482.3639 - val_mae: 1482.3639\n",
      "Epoch 333/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1386.7064 - mae: 1386.7064 - val_loss: 1483.8912 - val_mae: 1483.8912\n",
      "Epoch 334/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1386.4796 - mae: 1386.4796 - val_loss: 1481.1912 - val_mae: 1481.1912\n",
      "Epoch 335/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1385.2051 - mae: 1385.2051 - val_loss: 1485.0061 - val_mae: 1485.0061\n",
      "Epoch 336/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1384.8241 - mae: 1384.8241 - val_loss: 1480.8549 - val_mae: 1480.8549\n",
      "Epoch 337/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1384.5648 - mae: 1384.5648 - val_loss: 1493.8787 - val_mae: 1493.8787\n",
      "Epoch 338/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1384.6869 - mae: 1384.6869 - val_loss: 1482.8525 - val_mae: 1482.8525\n",
      "Epoch 339/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1383.4945 - mae: 1383.4945 - val_loss: 1484.1902 - val_mae: 1484.1902\n",
      "Epoch 340/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1383.6185 - mae: 1383.6185 - val_loss: 1482.1318 - val_mae: 1482.1318\n",
      "Epoch 341/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1383.1876 - mae: 1383.1876 - val_loss: 1482.6497 - val_mae: 1482.6497\n",
      "Epoch 342/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1382.9022 - mae: 1382.9022 - val_loss: 1480.1511 - val_mae: 1480.1511\n",
      "Epoch 343/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1382.8540 - mae: 1382.8540 - val_loss: 1480.8380 - val_mae: 1480.8380\n",
      "Epoch 344/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1382.2856 - mae: 1382.2856 - val_loss: 1480.3367 - val_mae: 1480.3367\n",
      "Epoch 345/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1381.7621 - mae: 1381.7621 - val_loss: 1482.5253 - val_mae: 1482.5253\n",
      "Epoch 346/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1381.3076 - mae: 1381.3076 - val_loss: 1479.2177 - val_mae: 1479.2177\n",
      "Epoch 347/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1381.0046 - mae: 1381.0046 - val_loss: 1479.4845 - val_mae: 1479.4845\n",
      "Epoch 348/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1380.4572 - mae: 1380.4572 - val_loss: 1481.3383 - val_mae: 1481.3383\n",
      "Epoch 349/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1379.5725 - mae: 1379.5725 - val_loss: 1480.0958 - val_mae: 1480.0958\n",
      "Epoch 350/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1380.4833 - mae: 1380.4833 - val_loss: 1480.9709 - val_mae: 1480.9709\n",
      "Epoch 351/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1379.3560 - mae: 1379.3560 - val_loss: 1480.3455 - val_mae: 1480.3455\n",
      "Epoch 352/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1379.7655 - mae: 1379.7655 - val_loss: 1483.4678 - val_mae: 1483.4678\n",
      "Epoch 353/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1378.5679 - mae: 1378.5679 - val_loss: 1480.2744 - val_mae: 1480.2744\n",
      "Epoch 354/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1378.5885 - mae: 1378.5885 - val_loss: 1480.2444 - val_mae: 1480.2444\n",
      "Epoch 355/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1378.3723 - mae: 1378.3723 - val_loss: 1482.7562 - val_mae: 1482.7562\n",
      "Epoch 356/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1377.8564 - mae: 1377.8564 - val_loss: 1477.0027 - val_mae: 1477.0027\n",
      "Epoch 357/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1378.2441 - mae: 1378.2441 - val_loss: 1477.3861 - val_mae: 1477.3861\n",
      "Epoch 358/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1376.8668 - mae: 1376.8668 - val_loss: 1481.1016 - val_mae: 1481.1016\n",
      "Epoch 359/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1376.9802 - mae: 1376.9802 - val_loss: 1477.4268 - val_mae: 1477.4268\n",
      "Epoch 360/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1377.1581 - mae: 1377.1581 - val_loss: 1477.1731 - val_mae: 1477.1731\n",
      "Epoch 361/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1377.0880 - mae: 1377.0880 - val_loss: 1476.1733 - val_mae: 1476.1733\n",
      "Epoch 362/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1375.9893 - mae: 1375.9893 - val_loss: 1475.6426 - val_mae: 1475.6426\n",
      "Epoch 363/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1375.4102 - mae: 1375.4102 - val_loss: 1475.3358 - val_mae: 1475.3358\n",
      "Epoch 364/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1375.2594 - mae: 1375.2594 - val_loss: 1475.5447 - val_mae: 1475.5447\n",
      "Epoch 365/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1374.4520 - mae: 1374.4520 - val_loss: 1478.0404 - val_mae: 1478.0404\n",
      "Epoch 366/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1374.8550 - mae: 1374.8550 - val_loss: 1475.7928 - val_mae: 1475.7928\n",
      "Epoch 367/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1373.5958 - mae: 1373.5958 - val_loss: 1473.9794 - val_mae: 1473.9794\n",
      "Epoch 368/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1373.9020 - mae: 1373.9020 - val_loss: 1473.5131 - val_mae: 1473.5131\n",
      "Epoch 369/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1373.5696 - mae: 1373.5696 - val_loss: 1471.7496 - val_mae: 1471.7496\n",
      "Epoch 370/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1373.0236 - mae: 1373.0236 - val_loss: 1483.7317 - val_mae: 1483.7317\n",
      "Epoch 371/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1373.3508 - mae: 1373.3508 - val_loss: 1482.1810 - val_mae: 1482.1810\n",
      "Epoch 372/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1372.6697 - mae: 1372.6697 - val_loss: 1476.0074 - val_mae: 1476.0074\n",
      "Epoch 373/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1372.3524 - mae: 1372.3524 - val_loss: 1473.9178 - val_mae: 1473.9178\n",
      "Epoch 374/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1372.0518 - mae: 1372.0518 - val_loss: 1473.7014 - val_mae: 1473.7014\n",
      "Epoch 375/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1371.9535 - mae: 1371.9535 - val_loss: 1473.5032 - val_mae: 1473.5032\n",
      "Epoch 376/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1371.1938 - mae: 1371.1938 - val_loss: 1472.8949 - val_mae: 1472.8949\n",
      "Epoch 377/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1370.2224 - mae: 1370.2224 - val_loss: 1473.1765 - val_mae: 1473.1765\n",
      "Epoch 378/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1370.5500 - mae: 1370.5500 - val_loss: 1472.1017 - val_mae: 1472.1017\n",
      "Epoch 379/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1370.0021 - mae: 1370.0021 - val_loss: 1472.0171 - val_mae: 1472.0171\n",
      "Epoch 380/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1369.3669 - mae: 1369.3669 - val_loss: 1473.3757 - val_mae: 1473.3757\n",
      "Epoch 381/1000\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 1370.1470 - mae: 1370.1470 - val_loss: 1470.2451 - val_mae: 1470.2451\n",
      "Epoch 382/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1369.6313 - mae: 1369.6313 - val_loss: 1472.0316 - val_mae: 1472.0316\n",
      "Epoch 383/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1368.9764 - mae: 1368.9764 - val_loss: 1471.4175 - val_mae: 1471.4175\n",
      "Epoch 384/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1368.4984 - mae: 1368.4984 - val_loss: 1472.5850 - val_mae: 1472.5850\n",
      "Epoch 385/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1368.9929 - mae: 1368.9929 - val_loss: 1472.4011 - val_mae: 1472.4011\n",
      "Epoch 386/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1368.3687 - mae: 1368.3687 - val_loss: 1469.9238 - val_mae: 1469.9238\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 2ms/step - loss: 1368.1370 - mae: 1368.1370 - val_loss: 1475.4536 - val_mae: 1475.4536\n",
      "Epoch 388/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1367.2178 - mae: 1367.2178 - val_loss: 1468.1299 - val_mae: 1468.1299\n",
      "Epoch 389/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1367.8514 - mae: 1367.8514 - val_loss: 1468.6074 - val_mae: 1468.6074\n",
      "Epoch 390/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1367.1731 - mae: 1367.1731 - val_loss: 1469.2323 - val_mae: 1469.2323\n",
      "Epoch 391/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1366.8691 - mae: 1366.8691 - val_loss: 1468.1925 - val_mae: 1468.1925\n",
      "Epoch 392/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1366.4330 - mae: 1366.4330 - val_loss: 1470.7457 - val_mae: 1470.7457\n",
      "Epoch 393/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1365.8402 - mae: 1365.8402 - val_loss: 1473.1036 - val_mae: 1473.1036\n",
      "Epoch 394/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1365.6089 - mae: 1365.6089 - val_loss: 1475.7069 - val_mae: 1475.7069\n",
      "Epoch 395/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1365.4385 - mae: 1365.4385 - val_loss: 1469.2506 - val_mae: 1469.2506\n",
      "Epoch 396/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1364.5367 - mae: 1364.5367 - val_loss: 1470.6450 - val_mae: 1470.6450\n",
      "Epoch 397/1000\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 1365.0806 - mae: 1365.0806 - val_loss: 1467.3727 - val_mae: 1467.3727\n",
      "Epoch 398/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1364.2362 - mae: 1364.2362 - val_loss: 1469.5280 - val_mae: 1469.5280\n",
      "Epoch 399/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1364.6621 - mae: 1364.6621 - val_loss: 1466.1587 - val_mae: 1466.1587\n",
      "Epoch 400/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1363.6584 - mae: 1363.6584 - val_loss: 1466.1722 - val_mae: 1466.1722\n",
      "Epoch 401/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1362.8827 - mae: 1362.8827 - val_loss: 1467.6924 - val_mae: 1467.6924\n",
      "Epoch 402/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1363.2037 - mae: 1363.2037 - val_loss: 1468.8167 - val_mae: 1468.8167\n",
      "Epoch 403/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1362.5801 - mae: 1362.5801 - val_loss: 1467.3434 - val_mae: 1467.3434\n",
      "Epoch 404/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1363.7577 - mae: 1363.7577 - val_loss: 1466.9592 - val_mae: 1466.9592\n",
      "Epoch 405/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1362.0422 - mae: 1362.0422 - val_loss: 1468.7924 - val_mae: 1468.7924\n",
      "Epoch 406/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1361.8394 - mae: 1361.8394 - val_loss: 1464.7689 - val_mae: 1464.7689\n",
      "Epoch 407/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1362.6233 - mae: 1362.6233 - val_loss: 1464.1444 - val_mae: 1464.1444\n",
      "Epoch 408/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1361.0980 - mae: 1361.0980 - val_loss: 1469.1766 - val_mae: 1469.1766\n",
      "Epoch 409/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1361.2755 - mae: 1361.2755 - val_loss: 1465.8326 - val_mae: 1465.8326\n",
      "Epoch 410/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1360.9670 - mae: 1360.9670 - val_loss: 1464.4919 - val_mae: 1464.4919\n",
      "Epoch 411/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1360.2930 - mae: 1360.2930 - val_loss: 1464.5673 - val_mae: 1464.5673\n",
      "Epoch 412/1000\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 1360.7109 - mae: 1360.7109 - val_loss: 1463.6958 - val_mae: 1463.6958\n",
      "Epoch 413/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1360.2584 - mae: 1360.2584 - val_loss: 1464.2676 - val_mae: 1464.2676\n",
      "Epoch 414/1000\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 1359.8395 - mae: 1359.8395 - val_loss: 1462.9475 - val_mae: 1462.9475\n",
      "Epoch 415/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1359.2994 - mae: 1359.2994 - val_loss: 1464.0264 - val_mae: 1464.0264\n",
      "Epoch 416/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1359.8148 - mae: 1359.8148 - val_loss: 1463.0826 - val_mae: 1463.0826\n",
      "Epoch 417/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1358.3574 - mae: 1358.3574 - val_loss: 1469.3066 - val_mae: 1469.3066\n",
      "Epoch 418/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1358.8986 - mae: 1358.8986 - val_loss: 1465.0001 - val_mae: 1465.0001\n",
      "Epoch 419/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1357.9452 - mae: 1357.9452 - val_loss: 1462.3806 - val_mae: 1462.3806\n",
      "Epoch 420/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1357.8374 - mae: 1357.8374 - val_loss: 1465.0364 - val_mae: 1465.0364\n",
      "Epoch 421/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1357.9319 - mae: 1357.9319 - val_loss: 1463.0312 - val_mae: 1463.0312\n",
      "Epoch 422/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1357.2693 - mae: 1357.2693 - val_loss: 1466.5801 - val_mae: 1466.5801\n",
      "Epoch 423/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1357.3336 - mae: 1357.3336 - val_loss: 1462.1172 - val_mae: 1462.1172\n",
      "Epoch 424/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1357.5551 - mae: 1357.5551 - val_loss: 1462.1915 - val_mae: 1462.1915\n",
      "Epoch 425/1000\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1356.6138 - mae: 1356.6138 - val_loss: 1458.6045 - val_mae: 1458.6045\n",
      "Epoch 426/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1356.8047 - mae: 1356.8047 - val_loss: 1460.7269 - val_mae: 1460.7269\n",
      "Epoch 427/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1356.1392 - mae: 1356.1392 - val_loss: 1460.3547 - val_mae: 1460.3547\n",
      "Epoch 428/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1355.6971 - mae: 1355.6971 - val_loss: 1461.2916 - val_mae: 1461.2916\n",
      "Epoch 429/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1355.2650 - mae: 1355.2650 - val_loss: 1461.0593 - val_mae: 1461.0593\n",
      "Epoch 430/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1355.2620 - mae: 1355.2620 - val_loss: 1462.9584 - val_mae: 1462.9584\n",
      "Epoch 431/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1354.5773 - mae: 1354.5773 - val_loss: 1459.4943 - val_mae: 1459.4943\n",
      "Epoch 432/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1354.7787 - mae: 1354.7787 - val_loss: 1462.0349 - val_mae: 1462.0349\n",
      "Epoch 433/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1354.2372 - mae: 1354.2372 - val_loss: 1461.5862 - val_mae: 1461.5862\n",
      "Epoch 434/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1354.0253 - mae: 1354.0253 - val_loss: 1461.3311 - val_mae: 1461.3311\n",
      "Epoch 435/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1353.5026 - mae: 1353.5026 - val_loss: 1459.4296 - val_mae: 1459.4296\n",
      "Epoch 436/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1354.6564 - mae: 1354.6564 - val_loss: 1463.0446 - val_mae: 1463.0446\n",
      "Epoch 437/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1352.0270 - mae: 1352.0270 - val_loss: 1467.0142 - val_mae: 1467.0142\n",
      "Epoch 438/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1353.2863 - mae: 1353.2863 - val_loss: 1458.6377 - val_mae: 1458.6377\n",
      "Epoch 439/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1352.6332 - mae: 1352.6332 - val_loss: 1459.8866 - val_mae: 1459.8866\n",
      "Epoch 440/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1352.6111 - mae: 1352.6111 - val_loss: 1457.4872 - val_mae: 1457.4872\n",
      "Epoch 441/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1352.1376 - mae: 1352.1376 - val_loss: 1457.2357 - val_mae: 1457.2357\n",
      "Epoch 442/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1352.3971 - mae: 1352.3971 - val_loss: 1458.1289 - val_mae: 1458.1289\n",
      "Epoch 443/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1351.4559 - mae: 1351.4559 - val_loss: 1458.0007 - val_mae: 1458.0007\n",
      "Epoch 444/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1351.6030 - mae: 1351.6030 - val_loss: 1458.0813 - val_mae: 1458.0813\n",
      "Epoch 445/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1351.3303 - mae: 1351.3303 - val_loss: 1460.8350 - val_mae: 1460.8350\n",
      "Epoch 446/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1350.7257 - mae: 1350.7257 - val_loss: 1458.7853 - val_mae: 1458.7853\n",
      "Epoch 447/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1350.6975 - mae: 1350.6975 - val_loss: 1459.1580 - val_mae: 1459.1580\n",
      "Epoch 448/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1350.9208 - mae: 1350.9208 - val_loss: 1455.5211 - val_mae: 1455.5211\n",
      "Epoch 449/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1349.9705 - mae: 1349.9705 - val_loss: 1459.4885 - val_mae: 1459.4885\n",
      "Epoch 450/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1349.6658 - mae: 1349.6658 - val_loss: 1457.2621 - val_mae: 1457.2621\n",
      "Epoch 451/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1349.6075 - mae: 1349.6075 - val_loss: 1461.6366 - val_mae: 1461.6366\n",
      "Epoch 452/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1350.4711 - mae: 1350.4711 - val_loss: 1460.7705 - val_mae: 1460.7705\n",
      "Epoch 453/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1349.8047 - mae: 1349.8047 - val_loss: 1456.2731 - val_mae: 1456.2731\n",
      "Epoch 454/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1349.2330 - mae: 1349.2330 - val_loss: 1455.4539 - val_mae: 1455.4539\n",
      "Epoch 455/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1349.0286 - mae: 1349.0286 - val_loss: 1456.1815 - val_mae: 1456.1815\n",
      "Epoch 456/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1348.9789 - mae: 1348.9789 - val_loss: 1456.8689 - val_mae: 1456.8689\n",
      "Epoch 457/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1348.9711 - mae: 1348.9711 - val_loss: 1454.8455 - val_mae: 1454.8455\n",
      "Epoch 458/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1347.7672 - mae: 1347.7672 - val_loss: 1455.0112 - val_mae: 1455.0112\n",
      "Epoch 459/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1348.6495 - mae: 1348.6495 - val_loss: 1455.9939 - val_mae: 1455.9939\n",
      "Epoch 460/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1347.9128 - mae: 1347.9128 - val_loss: 1455.0414 - val_mae: 1455.0414\n",
      "Epoch 461/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1346.9191 - mae: 1346.9191 - val_loss: 1455.5624 - val_mae: 1455.5624\n",
      "Epoch 462/1000\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 1347.1897 - mae: 1347.1897 - val_loss: 1453.5616 - val_mae: 1453.5616\n",
      "Epoch 463/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1347.0283 - mae: 1347.0283 - val_loss: 1455.1920 - val_mae: 1455.1920\n",
      "Epoch 464/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1346.7303 - mae: 1346.7303 - val_loss: 1453.0653 - val_mae: 1453.0653\n",
      "Epoch 465/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1346.3413 - mae: 1346.3413 - val_loss: 1452.6921 - val_mae: 1452.6921\n",
      "Epoch 466/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1345.8822 - mae: 1345.8822 - val_loss: 1452.9005 - val_mae: 1452.9005\n",
      "Epoch 467/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1345.5406 - mae: 1345.5406 - val_loss: 1453.6146 - val_mae: 1453.6146\n",
      "Epoch 468/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1345.1414 - mae: 1345.1414 - val_loss: 1451.7593 - val_mae: 1451.7593\n",
      "Epoch 469/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1345.0936 - mae: 1345.0936 - val_loss: 1451.7474 - val_mae: 1451.7474\n",
      "Epoch 470/1000\n",
      "268/268 [==============================] - 3s 12ms/step - loss: 1344.8911 - mae: 1344.8911 - val_loss: 1451.5540 - val_mae: 1451.5540\n",
      "Epoch 471/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1344.4905 - mae: 1344.4905 - val_loss: 1452.4404 - val_mae: 1452.4404\n",
      "Epoch 472/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1344.4312 - mae: 1344.4312 - val_loss: 1450.7391 - val_mae: 1450.7391\n",
      "Epoch 473/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1344.3224 - mae: 1344.3224 - val_loss: 1452.8160 - val_mae: 1452.8160\n",
      "Epoch 474/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1344.1400 - mae: 1344.1400 - val_loss: 1455.1434 - val_mae: 1455.1434\n",
      "Epoch 475/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1342.8049 - mae: 1342.8049 - val_loss: 1450.3092 - val_mae: 1450.3092\n",
      "Epoch 476/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1343.5234 - mae: 1343.5234 - val_loss: 1448.2682 - val_mae: 1448.2682\n",
      "Epoch 477/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1343.1565 - mae: 1343.1565 - val_loss: 1448.3845 - val_mae: 1448.3845\n",
      "Epoch 478/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1343.0300 - mae: 1343.0300 - val_loss: 1449.2411 - val_mae: 1449.2411\n",
      "Epoch 479/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1342.4086 - mae: 1342.4086 - val_loss: 1449.3715 - val_mae: 1449.3715\n",
      "Epoch 480/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1342.1570 - mae: 1342.1570 - val_loss: 1450.1462 - val_mae: 1450.1462\n",
      "Epoch 481/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1341.2893 - mae: 1341.2893 - val_loss: 1450.0979 - val_mae: 1450.0979\n",
      "Epoch 482/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1341.3544 - mae: 1341.3544 - val_loss: 1449.6289 - val_mae: 1449.6289\n",
      "Epoch 483/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1340.7987 - mae: 1340.7987 - val_loss: 1450.5333 - val_mae: 1450.5333\n",
      "Epoch 484/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1340.1907 - mae: 1340.1907 - val_loss: 1447.5656 - val_mae: 1447.5656\n",
      "Epoch 485/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1339.7732 - mae: 1339.7732 - val_loss: 1449.8964 - val_mae: 1449.8964\n",
      "Epoch 486/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1341.0575 - mae: 1341.0575 - val_loss: 1452.4324 - val_mae: 1452.4324\n",
      "Epoch 487/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1340.3307 - mae: 1340.3307 - val_loss: 1447.5691 - val_mae: 1447.5691\n",
      "Epoch 488/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1340.1409 - mae: 1340.1409 - val_loss: 1446.9857 - val_mae: 1446.9857\n",
      "Epoch 489/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1339.1196 - mae: 1339.1196 - val_loss: 1444.0078 - val_mae: 1444.0078\n",
      "Epoch 490/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1339.4824 - mae: 1339.4824 - val_loss: 1444.8289 - val_mae: 1444.8289\n",
      "Epoch 491/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1338.7214 - mae: 1338.7214 - val_loss: 1447.7804 - val_mae: 1447.7804\n",
      "Epoch 492/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1338.5980 - mae: 1338.5980 - val_loss: 1448.4574 - val_mae: 1448.4574\n",
      "Epoch 493/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1338.3159 - mae: 1338.3159 - val_loss: 1445.9471 - val_mae: 1445.9471\n",
      "Epoch 494/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1337.7823 - mae: 1337.7823 - val_loss: 1445.3529 - val_mae: 1445.3529\n",
      "Epoch 495/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1337.7272 - mae: 1337.7272 - val_loss: 1445.0553 - val_mae: 1445.0553\n",
      "Epoch 496/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1336.8280 - mae: 1336.8280 - val_loss: 1444.0758 - val_mae: 1444.0758\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 2ms/step - loss: 1337.4325 - mae: 1337.4325 - val_loss: 1444.0907 - val_mae: 1444.0907\n",
      "Epoch 498/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1337.2909 - mae: 1337.2909 - val_loss: 1446.1807 - val_mae: 1446.1807\n",
      "Epoch 499/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1337.5000 - mae: 1337.5000 - val_loss: 1443.4122 - val_mae: 1443.4122\n",
      "Epoch 500/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1336.5687 - mae: 1336.5687 - val_loss: 1445.1926 - val_mae: 1445.1926\n",
      "Epoch 501/1000\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 1336.7704 - mae: 1336.7704 - val_loss: 1442.3678 - val_mae: 1442.3678\n",
      "Epoch 502/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1335.3702 - mae: 1335.3702 - val_loss: 1440.4915 - val_mae: 1440.4915\n",
      "Epoch 503/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1336.1610 - mae: 1336.1610 - val_loss: 1441.4374 - val_mae: 1441.4374\n",
      "Epoch 504/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1335.1078 - mae: 1335.1078 - val_loss: 1442.3495 - val_mae: 1442.3495\n",
      "Epoch 505/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1334.7319 - mae: 1334.7319 - val_loss: 1443.6621 - val_mae: 1443.6621\n",
      "Epoch 506/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1334.7162 - mae: 1334.7162 - val_loss: 1441.5710 - val_mae: 1441.5710\n",
      "Epoch 507/1000\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 1333.9076 - mae: 1333.9076 - val_loss: 1440.4766 - val_mae: 1440.4766\n",
      "Epoch 508/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1334.6276 - mae: 1334.6276 - val_loss: 1443.3005 - val_mae: 1443.3005\n",
      "Epoch 509/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1334.8768 - mae: 1334.8768 - val_loss: 1441.7821 - val_mae: 1441.7821\n",
      "Epoch 510/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1334.8290 - mae: 1334.8290 - val_loss: 1444.1028 - val_mae: 1444.1028\n",
      "Epoch 511/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1333.8147 - mae: 1333.8147 - val_loss: 1441.7551 - val_mae: 1441.7551\n",
      "Epoch 512/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1334.0981 - mae: 1334.0981 - val_loss: 1440.0681 - val_mae: 1440.0681\n",
      "Epoch 513/1000\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 1332.7487 - mae: 1332.7487 - val_loss: 1438.0903 - val_mae: 1438.0903\n",
      "Epoch 514/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1332.8604 - mae: 1332.8604 - val_loss: 1440.9176 - val_mae: 1440.9176\n",
      "Epoch 515/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1332.3615 - mae: 1332.3615 - val_loss: 1438.6891 - val_mae: 1438.6891\n",
      "Epoch 516/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1332.1655 - mae: 1332.1655 - val_loss: 1437.1990 - val_mae: 1437.1990\n",
      "Epoch 517/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1332.1591 - mae: 1332.1591 - val_loss: 1437.1173 - val_mae: 1437.1173\n",
      "Epoch 518/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1331.5989 - mae: 1331.5989 - val_loss: 1437.5282 - val_mae: 1437.5282\n",
      "Epoch 519/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1331.3083 - mae: 1331.3083 - val_loss: 1439.2284 - val_mae: 1439.2284\n",
      "Epoch 520/1000\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 1331.0421 - mae: 1331.0421 - val_loss: 1437.1079 - val_mae: 1437.1079\n",
      "Epoch 521/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1331.4995 - mae: 1331.4995 - val_loss: 1438.2064 - val_mae: 1438.2064\n",
      "Epoch 522/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1331.0852 - mae: 1331.0852 - val_loss: 1437.8087 - val_mae: 1437.8087\n",
      "Epoch 523/1000\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 1329.8807 - mae: 1329.8807 - val_loss: 1436.1996 - val_mae: 1436.1996\n",
      "Epoch 524/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1330.2698 - mae: 1330.2698 - val_loss: 1434.7814 - val_mae: 1434.7814\n",
      "Epoch 525/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1329.4045 - mae: 1329.4045 - val_loss: 1436.4559 - val_mae: 1436.4559\n",
      "Epoch 526/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1329.2887 - mae: 1329.2887 - val_loss: 1437.0876 - val_mae: 1437.0876\n",
      "Epoch 527/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1329.5339 - mae: 1329.5339 - val_loss: 1437.5233 - val_mae: 1437.5233\n",
      "Epoch 528/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1329.5101 - mae: 1329.5101 - val_loss: 1436.1290 - val_mae: 1436.1290\n",
      "Epoch 529/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1328.9648 - mae: 1328.9648 - val_loss: 1437.6542 - val_mae: 1437.6542\n",
      "Epoch 530/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1328.3428 - mae: 1328.3428 - val_loss: 1436.4286 - val_mae: 1436.4286\n",
      "Epoch 531/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1328.0994 - mae: 1328.0994 - val_loss: 1435.1237 - val_mae: 1435.1237\n",
      "Epoch 532/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1328.4265 - mae: 1328.4265 - val_loss: 1435.1075 - val_mae: 1435.1075\n",
      "Epoch 533/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1327.3193 - mae: 1327.3193 - val_loss: 1434.1481 - val_mae: 1434.1481\n",
      "Epoch 534/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1327.2246 - mae: 1327.2246 - val_loss: 1433.4255 - val_mae: 1433.4255\n",
      "Epoch 535/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1326.2755 - mae: 1326.2755 - val_loss: 1433.4602 - val_mae: 1433.4602\n",
      "Epoch 536/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1326.7939 - mae: 1326.7939 - val_loss: 1433.2887 - val_mae: 1433.2887\n",
      "Epoch 537/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1326.1538 - mae: 1326.1538 - val_loss: 1431.9324 - val_mae: 1431.9324\n",
      "Epoch 538/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1326.6881 - mae: 1326.6881 - val_loss: 1437.8026 - val_mae: 1437.8026\n",
      "Epoch 539/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1326.2582 - mae: 1326.2582 - val_loss: 1434.3243 - val_mae: 1434.3243\n",
      "Epoch 540/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1325.4303 - mae: 1325.4303 - val_loss: 1432.8004 - val_mae: 1432.8004\n",
      "Epoch 541/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1325.3064 - mae: 1325.3064 - val_loss: 1432.3560 - val_mae: 1432.3560\n",
      "Epoch 542/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1324.6797 - mae: 1324.6797 - val_loss: 1435.2064 - val_mae: 1435.2064\n",
      "Epoch 543/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1325.2175 - mae: 1325.2175 - val_loss: 1430.9331 - val_mae: 1430.9331\n",
      "Epoch 544/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1324.5502 - mae: 1324.5502 - val_loss: 1436.3998 - val_mae: 1436.3998\n",
      "Epoch 545/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1324.2847 - mae: 1324.2847 - val_loss: 1432.3909 - val_mae: 1432.3909\n",
      "Epoch 546/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1324.0774 - mae: 1324.0774 - val_loss: 1429.0212 - val_mae: 1429.0212\n",
      "Epoch 547/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1323.5571 - mae: 1323.5571 - val_loss: 1432.6162 - val_mae: 1432.6162\n",
      "Epoch 548/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1323.8522 - mae: 1323.8522 - val_loss: 1430.8728 - val_mae: 1430.8728\n",
      "Epoch 549/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1322.9410 - mae: 1322.9410 - val_loss: 1432.2487 - val_mae: 1432.2487\n",
      "Epoch 550/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1323.1909 - mae: 1323.1909 - val_loss: 1429.6392 - val_mae: 1429.6392\n",
      "Epoch 551/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1322.2434 - mae: 1322.2434 - val_loss: 1434.8206 - val_mae: 1434.8206\n",
      "Epoch 552/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1322.3492 - mae: 1322.3492 - val_loss: 1428.5494 - val_mae: 1428.5494\n",
      "Epoch 553/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1322.7513 - mae: 1322.7513 - val_loss: 1432.9740 - val_mae: 1432.9740\n",
      "Epoch 554/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1321.3954 - mae: 1321.3954 - val_loss: 1430.7573 - val_mae: 1430.7573\n",
      "Epoch 555/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1322.1499 - mae: 1322.1499 - val_loss: 1429.4583 - val_mae: 1429.4583\n",
      "Epoch 556/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1321.8108 - mae: 1321.8108 - val_loss: 1433.4515 - val_mae: 1433.4515\n",
      "Epoch 557/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1321.7821 - mae: 1321.7821 - val_loss: 1428.4951 - val_mae: 1428.4951\n",
      "Epoch 558/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1321.0487 - mae: 1321.0487 - val_loss: 1426.7141 - val_mae: 1426.7141\n",
      "Epoch 559/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1320.3746 - mae: 1320.3746 - val_loss: 1429.8971 - val_mae: 1429.8971\n",
      "Epoch 560/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1320.2788 - mae: 1320.2788 - val_loss: 1432.3584 - val_mae: 1432.3584\n",
      "Epoch 561/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1320.2496 - mae: 1320.2496 - val_loss: 1433.4501 - val_mae: 1433.4501\n",
      "Epoch 562/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1319.6935 - mae: 1319.6935 - val_loss: 1428.8234 - val_mae: 1428.8234\n",
      "Epoch 563/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1320.0292 - mae: 1320.0292 - val_loss: 1427.2950 - val_mae: 1427.2950\n",
      "Epoch 564/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1319.7498 - mae: 1319.7498 - val_loss: 1427.0764 - val_mae: 1427.0764\n",
      "Epoch 565/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1319.5072 - mae: 1319.5072 - val_loss: 1426.1423 - val_mae: 1426.1423\n",
      "Epoch 566/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1318.6306 - mae: 1318.6306 - val_loss: 1424.0924 - val_mae: 1424.0924\n",
      "Epoch 567/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1318.3357 - mae: 1318.3357 - val_loss: 1424.3357 - val_mae: 1424.3357\n",
      "Epoch 568/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1319.2003 - mae: 1319.2003 - val_loss: 1423.8724 - val_mae: 1423.8724\n",
      "Epoch 569/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1318.7999 - mae: 1318.7999 - val_loss: 1425.4791 - val_mae: 1425.4791\n",
      "Epoch 570/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1317.4320 - mae: 1317.4320 - val_loss: 1424.9186 - val_mae: 1424.9186\n",
      "Epoch 571/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1317.7875 - mae: 1317.7875 - val_loss: 1425.2815 - val_mae: 1425.2815\n",
      "Epoch 572/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1317.3722 - mae: 1317.3722 - val_loss: 1423.9751 - val_mae: 1423.9751\n",
      "Epoch 573/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1317.0743 - mae: 1317.0743 - val_loss: 1427.1938 - val_mae: 1427.1938\n",
      "Epoch 574/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1316.6703 - mae: 1316.6703 - val_loss: 1425.9689 - val_mae: 1425.9689\n",
      "Epoch 575/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1316.7501 - mae: 1316.7501 - val_loss: 1423.5704 - val_mae: 1423.5704\n",
      "Epoch 576/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1316.1128 - mae: 1316.1128 - val_loss: 1428.4941 - val_mae: 1428.4941\n",
      "Epoch 577/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1316.1682 - mae: 1316.1682 - val_loss: 1421.8413 - val_mae: 1421.8413\n",
      "Epoch 578/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1315.9896 - mae: 1315.9896 - val_loss: 1422.2056 - val_mae: 1422.2056\n",
      "Epoch 579/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1315.3544 - mae: 1315.3544 - val_loss: 1423.1023 - val_mae: 1423.1023\n",
      "Epoch 580/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1315.4093 - mae: 1315.4093 - val_loss: 1432.6570 - val_mae: 1432.6570\n",
      "Epoch 581/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1316.3391 - mae: 1316.3391 - val_loss: 1424.9139 - val_mae: 1424.9139\n",
      "Epoch 582/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1315.3359 - mae: 1315.3359 - val_loss: 1425.9341 - val_mae: 1425.9341\n",
      "Epoch 583/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1314.4224 - mae: 1314.4224 - val_loss: 1426.0692 - val_mae: 1426.0692\n",
      "Epoch 584/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1314.9640 - mae: 1314.9640 - val_loss: 1421.7141 - val_mae: 1421.7141\n",
      "Epoch 585/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1314.0120 - mae: 1314.0120 - val_loss: 1425.9829 - val_mae: 1425.9829\n",
      "Epoch 586/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1314.0393 - mae: 1314.0393 - val_loss: 1420.9337 - val_mae: 1420.9337\n",
      "Epoch 587/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1313.3613 - mae: 1313.3613 - val_loss: 1421.8293 - val_mae: 1421.8293\n",
      "Epoch 588/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1312.7323 - mae: 1312.7323 - val_loss: 1426.9929 - val_mae: 1426.9929\n",
      "Epoch 589/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1313.6187 - mae: 1313.6187 - val_loss: 1422.7944 - val_mae: 1422.7944\n",
      "Epoch 590/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1312.8690 - mae: 1312.8690 - val_loss: 1423.3560 - val_mae: 1423.3560\n",
      "Epoch 591/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1312.2286 - mae: 1312.2286 - val_loss: 1421.8101 - val_mae: 1421.8101\n",
      "Epoch 592/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1312.2986 - mae: 1312.2986 - val_loss: 1420.9207 - val_mae: 1420.9207\n",
      "Epoch 593/1000\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 1312.0199 - mae: 1312.0199 - val_loss: 1419.0524 - val_mae: 1419.0524\n",
      "Epoch 594/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1312.0026 - mae: 1312.0026 - val_loss: 1418.6547 - val_mae: 1418.6547\n",
      "Epoch 595/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1310.6556 - mae: 1310.6556 - val_loss: 1418.8447 - val_mae: 1418.8447\n",
      "Epoch 596/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1310.2509 - mae: 1310.2509 - val_loss: 1418.6715 - val_mae: 1418.6715\n",
      "Epoch 597/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1310.2665 - mae: 1310.2665 - val_loss: 1419.4812 - val_mae: 1419.4812\n",
      "Epoch 598/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1310.3262 - mae: 1310.3262 - val_loss: 1421.2330 - val_mae: 1421.2330\n",
      "Epoch 599/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1310.2706 - mae: 1310.2706 - val_loss: 1418.6910 - val_mae: 1418.6910\n",
      "Epoch 600/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1309.3936 - mae: 1309.3936 - val_loss: 1418.3849 - val_mae: 1418.3849\n",
      "Epoch 601/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1309.0394 - mae: 1309.0394 - val_loss: 1420.7942 - val_mae: 1420.7942\n",
      "Epoch 602/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1308.7483 - mae: 1308.7483 - val_loss: 1421.4031 - val_mae: 1421.4031\n",
      "Epoch 603/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1308.2225 - mae: 1308.2225 - val_loss: 1422.2333 - val_mae: 1422.2333\n",
      "Epoch 604/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1309.1177 - mae: 1309.1177 - val_loss: 1419.2118 - val_mae: 1419.2118\n",
      "Epoch 605/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1308.2756 - mae: 1308.2756 - val_loss: 1416.2366 - val_mae: 1416.2366\n",
      "Epoch 606/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1307.4617 - mae: 1307.4617 - val_loss: 1417.4689 - val_mae: 1417.4689\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 2ms/step - loss: 1308.3077 - mae: 1308.3077 - val_loss: 1421.3391 - val_mae: 1421.3391\n",
      "Epoch 608/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1308.3060 - mae: 1308.3060 - val_loss: 1416.6489 - val_mae: 1416.6489\n",
      "Epoch 609/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1307.0850 - mae: 1307.0850 - val_loss: 1414.5861 - val_mae: 1414.5861\n",
      "Epoch 610/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1306.8595 - mae: 1306.8595 - val_loss: 1417.0266 - val_mae: 1417.0266\n",
      "Epoch 611/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1305.8074 - mae: 1305.8074 - val_loss: 1416.3938 - val_mae: 1416.3938\n",
      "Epoch 612/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1305.7267 - mae: 1305.7267 - val_loss: 1416.0217 - val_mae: 1416.0217\n",
      "Epoch 613/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1305.7118 - mae: 1305.7118 - val_loss: 1417.6846 - val_mae: 1417.6846\n",
      "Epoch 614/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1305.1216 - mae: 1305.1216 - val_loss: 1414.5784 - val_mae: 1414.5784\n",
      "Epoch 615/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1305.6506 - mae: 1305.6506 - val_loss: 1417.6166 - val_mae: 1417.6166\n",
      "Epoch 616/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1304.7672 - mae: 1304.7672 - val_loss: 1413.0472 - val_mae: 1413.0472\n",
      "Epoch 617/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1304.8840 - mae: 1304.8840 - val_loss: 1414.8285 - val_mae: 1414.8285\n",
      "Epoch 618/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1305.0682 - mae: 1305.0682 - val_loss: 1415.0376 - val_mae: 1415.0376\n",
      "Epoch 619/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1304.0789 - mae: 1304.0789 - val_loss: 1413.2562 - val_mae: 1413.2562\n",
      "Epoch 620/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1304.0150 - mae: 1304.0150 - val_loss: 1411.1337 - val_mae: 1411.1337\n",
      "Epoch 621/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1302.5273 - mae: 1302.5273 - val_loss: 1411.9249 - val_mae: 1411.9249\n",
      "Epoch 622/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1304.2870 - mae: 1304.2870 - val_loss: 1419.8799 - val_mae: 1419.8799\n",
      "Epoch 623/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1303.6558 - mae: 1303.6558 - val_loss: 1414.8586 - val_mae: 1414.8586\n",
      "Epoch 624/1000\n",
      "268/268 [==============================] - 9s 35ms/step - loss: 1303.1481 - mae: 1303.1481 - val_loss: 1410.0913 - val_mae: 1410.0913\n",
      "Epoch 625/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1302.3855 - mae: 1302.3855 - val_loss: 1411.5901 - val_mae: 1411.5901\n",
      "Epoch 626/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1303.0677 - mae: 1303.0677 - val_loss: 1409.7571 - val_mae: 1409.7571\n",
      "Epoch 627/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1302.0204 - mae: 1302.0204 - val_loss: 1410.7830 - val_mae: 1410.7830\n",
      "Epoch 628/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1302.3320 - mae: 1302.3320 - val_loss: 1410.7003 - val_mae: 1410.7003\n",
      "Epoch 629/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1300.9490 - mae: 1300.9490 - val_loss: 1408.6808 - val_mae: 1408.6808\n",
      "Epoch 630/1000\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 1301.2112 - mae: 1301.2112 - val_loss: 1406.6720 - val_mae: 1406.6720\n",
      "Epoch 631/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1300.9224 - mae: 1300.9224 - val_loss: 1410.0602 - val_mae: 1410.0602\n",
      "Epoch 632/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1300.2705 - mae: 1300.2705 - val_loss: 1410.2233 - val_mae: 1410.2233\n",
      "Epoch 633/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1300.0354 - mae: 1300.0354 - val_loss: 1410.9889 - val_mae: 1410.9889\n",
      "Epoch 634/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1300.3656 - mae: 1300.3656 - val_loss: 1406.5270 - val_mae: 1406.5270\n",
      "Epoch 635/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1300.6553 - mae: 1300.6553 - val_loss: 1408.6918 - val_mae: 1408.6918\n",
      "Epoch 636/1000\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 1299.9884 - mae: 1299.9884 - val_loss: 1406.4006 - val_mae: 1406.4006\n",
      "Epoch 637/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1299.3856 - mae: 1299.3856 - val_loss: 1408.4004 - val_mae: 1408.4004\n",
      "Epoch 638/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1299.7146 - mae: 1299.7146 - val_loss: 1403.2214 - val_mae: 1403.2214\n",
      "Epoch 639/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1298.8052 - mae: 1298.8052 - val_loss: 1406.3652 - val_mae: 1406.3652\n",
      "Epoch 640/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1298.5618 - mae: 1298.5618 - val_loss: 1407.1738 - val_mae: 1407.1738\n",
      "Epoch 641/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1298.2935 - mae: 1298.2935 - val_loss: 1408.7200 - val_mae: 1408.7200\n",
      "Epoch 642/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1298.1978 - mae: 1298.1978 - val_loss: 1405.7825 - val_mae: 1405.7825\n",
      "Epoch 643/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1297.7430 - mae: 1297.7430 - val_loss: 1406.7605 - val_mae: 1406.7605\n",
      "Epoch 644/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1298.2428 - mae: 1298.2428 - val_loss: 1403.3970 - val_mae: 1403.3970\n",
      "Epoch 645/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1297.3273 - mae: 1297.3273 - val_loss: 1406.5151 - val_mae: 1406.5151\n",
      "Epoch 646/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1297.5684 - mae: 1297.5684 - val_loss: 1406.6842 - val_mae: 1406.6842\n",
      "Epoch 647/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1297.1716 - mae: 1297.1716 - val_loss: 1404.4554 - val_mae: 1404.4554\n",
      "Epoch 648/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1297.0444 - mae: 1297.0444 - val_loss: 1405.1613 - val_mae: 1405.1613\n",
      "Epoch 649/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1296.6107 - mae: 1296.6107 - val_loss: 1409.0505 - val_mae: 1409.0505\n",
      "Epoch 650/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1296.3131 - mae: 1296.3131 - val_loss: 1403.6805 - val_mae: 1403.6805\n",
      "Epoch 651/1000\n",
      "268/268 [==============================] - 3s 12ms/step - loss: 1296.3043 - mae: 1296.3043 - val_loss: 1402.9382 - val_mae: 1402.9382\n",
      "Epoch 652/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1296.6163 - mae: 1296.6163 - val_loss: 1403.1335 - val_mae: 1403.1335\n",
      "Epoch 653/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1295.8898 - mae: 1295.8898 - val_loss: 1401.6113 - val_mae: 1401.6113\n",
      "Epoch 654/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1296.7395 - mae: 1296.7395 - val_loss: 1403.3251 - val_mae: 1403.3251\n",
      "Epoch 655/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1295.0243 - mae: 1295.0243 - val_loss: 1400.9960 - val_mae: 1400.9960\n",
      "Epoch 656/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1295.7321 - mae: 1295.7321 - val_loss: 1405.5741 - val_mae: 1405.5741\n",
      "Epoch 657/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1294.8219 - mae: 1294.8219 - val_loss: 1402.8881 - val_mae: 1402.8881\n",
      "Epoch 658/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1294.8193 - mae: 1294.8193 - val_loss: 1400.4462 - val_mae: 1400.4462\n",
      "Epoch 659/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1294.7488 - mae: 1294.7488 - val_loss: 1400.6429 - val_mae: 1400.6429\n",
      "Epoch 660/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1293.6167 - mae: 1293.6167 - val_loss: 1402.9185 - val_mae: 1402.9185\n",
      "Epoch 661/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1294.7776 - mae: 1294.7776 - val_loss: 1402.4037 - val_mae: 1402.4037\n",
      "Epoch 662/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1294.3577 - mae: 1294.3577 - val_loss: 1403.4053 - val_mae: 1403.4053\n",
      "Epoch 663/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1294.4567 - mae: 1294.4567 - val_loss: 1402.2473 - val_mae: 1402.2473\n",
      "Epoch 664/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1293.5372 - mae: 1293.5372 - val_loss: 1400.5936 - val_mae: 1400.5936\n",
      "Epoch 665/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1293.9010 - mae: 1293.9010 - val_loss: 1400.6752 - val_mae: 1400.6752\n",
      "Epoch 666/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1292.2819 - mae: 1292.2819 - val_loss: 1399.2162 - val_mae: 1399.2162\n",
      "Epoch 667/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1291.7891 - mae: 1291.7891 - val_loss: 1399.9244 - val_mae: 1399.9244\n",
      "Epoch 668/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1292.7285 - mae: 1292.7285 - val_loss: 1400.8687 - val_mae: 1400.8687\n",
      "Epoch 669/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1292.5159 - mae: 1292.5159 - val_loss: 1400.7233 - val_mae: 1400.7233\n",
      "Epoch 670/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1292.8965 - mae: 1292.8965 - val_loss: 1400.4176 - val_mae: 1400.4176\n",
      "Epoch 671/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1291.9338 - mae: 1291.9338 - val_loss: 1398.7063 - val_mae: 1398.7063\n",
      "Epoch 672/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1292.1854 - mae: 1292.1854 - val_loss: 1398.8774 - val_mae: 1398.8774\n",
      "Epoch 673/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1291.7064 - mae: 1291.7064 - val_loss: 1397.1704 - val_mae: 1397.1704\n",
      "Epoch 674/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1291.0195 - mae: 1291.0195 - val_loss: 1399.5129 - val_mae: 1399.5129\n",
      "Epoch 675/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1291.1517 - mae: 1291.1517 - val_loss: 1397.3517 - val_mae: 1397.3517\n",
      "Epoch 676/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1291.0857 - mae: 1291.0857 - val_loss: 1398.6074 - val_mae: 1398.6074\n",
      "Epoch 677/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1291.1046 - mae: 1291.1046 - val_loss: 1399.6848 - val_mae: 1399.6848\n",
      "Epoch 678/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1290.8724 - mae: 1290.8724 - val_loss: 1397.6124 - val_mae: 1397.6124\n",
      "Epoch 679/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1290.8977 - mae: 1290.8977 - val_loss: 1397.1494 - val_mae: 1397.1494\n",
      "Epoch 680/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1289.7975 - mae: 1289.7975 - val_loss: 1397.1586 - val_mae: 1397.1586\n",
      "Epoch 681/1000\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 1290.8718 - mae: 1290.8718 - val_loss: 1396.0668 - val_mae: 1396.0668\n",
      "Epoch 682/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1289.4479 - mae: 1289.4479 - val_loss: 1396.1143 - val_mae: 1396.1143\n",
      "Epoch 683/1000\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 1289.8403 - mae: 1289.8403 - val_loss: 1395.4165 - val_mae: 1395.4165\n",
      "Epoch 684/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1289.5479 - mae: 1289.5479 - val_loss: 1393.9375 - val_mae: 1393.9375\n",
      "Epoch 685/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1289.2605 - mae: 1289.2605 - val_loss: 1393.9670 - val_mae: 1393.9670\n",
      "Epoch 686/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1289.1383 - mae: 1289.1383 - val_loss: 1395.0004 - val_mae: 1395.0004\n",
      "Epoch 687/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1288.4039 - mae: 1288.4039 - val_loss: 1394.4824 - val_mae: 1394.4824\n",
      "Epoch 688/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1287.8838 - mae: 1287.8838 - val_loss: 1394.7551 - val_mae: 1394.7551\n",
      "Epoch 689/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1288.1342 - mae: 1288.1342 - val_loss: 1394.9708 - val_mae: 1394.9708\n",
      "Epoch 690/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1288.3621 - mae: 1288.3621 - val_loss: 1397.5856 - val_mae: 1397.5856\n",
      "Epoch 691/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1287.2526 - mae: 1287.2526 - val_loss: 1393.3477 - val_mae: 1393.3477\n",
      "Epoch 692/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1287.4528 - mae: 1287.4528 - val_loss: 1393.6538 - val_mae: 1393.6538\n",
      "Epoch 693/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1288.5032 - mae: 1288.5032 - val_loss: 1398.2621 - val_mae: 1398.2621\n",
      "Epoch 694/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1287.6771 - mae: 1287.6771 - val_loss: 1393.9019 - val_mae: 1393.9019\n",
      "Epoch 695/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1287.7637 - mae: 1287.7637 - val_loss: 1393.1224 - val_mae: 1393.1224\n",
      "Epoch 696/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1286.8772 - mae: 1286.8772 - val_loss: 1394.6339 - val_mae: 1394.6339\n",
      "Epoch 697/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1286.3665 - mae: 1286.3665 - val_loss: 1393.1479 - val_mae: 1393.1479\n",
      "Epoch 698/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1285.6095 - mae: 1285.6095 - val_loss: 1393.2756 - val_mae: 1393.2756\n",
      "Epoch 699/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1286.3422 - mae: 1286.3422 - val_loss: 1394.0032 - val_mae: 1394.0032\n",
      "Epoch 700/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1286.1431 - mae: 1286.1431 - val_loss: 1392.4128 - val_mae: 1392.4128\n",
      "Epoch 701/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1285.4452 - mae: 1285.4452 - val_loss: 1390.8693 - val_mae: 1390.8693\n",
      "Epoch 702/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1285.0112 - mae: 1285.0112 - val_loss: 1391.1040 - val_mae: 1391.1040\n",
      "Epoch 703/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1285.1121 - mae: 1285.1121 - val_loss: 1390.8021 - val_mae: 1390.8021\n",
      "Epoch 704/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1284.9153 - mae: 1284.9153 - val_loss: 1392.2565 - val_mae: 1392.2565\n",
      "Epoch 705/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1284.7334 - mae: 1284.7334 - val_loss: 1395.5481 - val_mae: 1395.5481\n",
      "Epoch 706/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1284.8293 - mae: 1284.8293 - val_loss: 1391.4227 - val_mae: 1391.4227\n",
      "Epoch 707/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1283.6816 - mae: 1283.6816 - val_loss: 1391.9709 - val_mae: 1391.9709\n",
      "Epoch 708/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1283.9165 - mae: 1283.9165 - val_loss: 1390.1259 - val_mae: 1390.1259\n",
      "Epoch 709/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1283.9651 - mae: 1283.9651 - val_loss: 1388.9335 - val_mae: 1388.9335\n",
      "Epoch 710/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1283.3289 - mae: 1283.3289 - val_loss: 1389.9429 - val_mae: 1389.9429\n",
      "Epoch 711/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1283.8627 - mae: 1283.8627 - val_loss: 1391.1569 - val_mae: 1391.1569\n",
      "Epoch 712/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1283.2332 - mae: 1283.2332 - val_loss: 1390.3191 - val_mae: 1390.3191\n",
      "Epoch 713/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1282.7966 - mae: 1282.7966 - val_loss: 1388.8765 - val_mae: 1388.8765\n",
      "Epoch 714/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1282.8291 - mae: 1282.8291 - val_loss: 1390.7833 - val_mae: 1390.7833\n",
      "Epoch 715/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1282.6602 - mae: 1282.6602 - val_loss: 1390.8497 - val_mae: 1390.8497\n",
      "Epoch 716/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1281.6765 - mae: 1281.6765 - val_loss: 1390.3380 - val_mae: 1390.3380\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 3ms/step - loss: 1282.3834 - mae: 1282.3834 - val_loss: 1388.7358 - val_mae: 1388.7358\n",
      "Epoch 718/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1281.6134 - mae: 1281.6134 - val_loss: 1389.4838 - val_mae: 1389.4838\n",
      "Epoch 719/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1281.6368 - mae: 1281.6368 - val_loss: 1388.9403 - val_mae: 1388.9403\n",
      "Epoch 720/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1281.9705 - mae: 1281.9705 - val_loss: 1388.2291 - val_mae: 1388.2291\n",
      "Epoch 721/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1280.8959 - mae: 1280.8959 - val_loss: 1385.3960 - val_mae: 1385.3960\n",
      "Epoch 722/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1280.2485 - mae: 1280.2485 - val_loss: 1387.7417 - val_mae: 1387.7417\n",
      "Epoch 723/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1281.2207 - mae: 1281.2207 - val_loss: 1389.0632 - val_mae: 1389.0632\n",
      "Epoch 724/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1280.2008 - mae: 1280.2008 - val_loss: 1386.8329 - val_mae: 1386.8329\n",
      "Epoch 725/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1280.6826 - mae: 1280.6826 - val_loss: 1387.6641 - val_mae: 1387.6641\n",
      "Epoch 726/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1280.0518 - mae: 1280.0518 - val_loss: 1385.8164 - val_mae: 1385.8164\n",
      "Epoch 727/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1279.6165 - mae: 1279.6165 - val_loss: 1387.6774 - val_mae: 1387.6774\n",
      "Epoch 728/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1280.0802 - mae: 1280.0802 - val_loss: 1387.9570 - val_mae: 1387.9570\n",
      "Epoch 729/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1279.4536 - mae: 1279.4536 - val_loss: 1386.7556 - val_mae: 1386.7556\n",
      "Epoch 730/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1278.4951 - mae: 1278.4951 - val_loss: 1387.5576 - val_mae: 1387.5576\n",
      "Epoch 731/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1279.6555 - mae: 1279.6555 - val_loss: 1385.8278 - val_mae: 1385.8278\n",
      "Epoch 732/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1279.4969 - mae: 1279.4969 - val_loss: 1388.0609 - val_mae: 1388.0609\n",
      "Epoch 733/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1279.3853 - mae: 1279.3853 - val_loss: 1386.2839 - val_mae: 1386.2839\n",
      "Epoch 734/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1278.9373 - mae: 1278.9373 - val_loss: 1383.9968 - val_mae: 1383.9968\n",
      "Epoch 735/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1278.9489 - mae: 1278.9489 - val_loss: 1384.7252 - val_mae: 1384.7252\n",
      "Epoch 736/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1278.2743 - mae: 1278.2743 - val_loss: 1383.4301 - val_mae: 1383.4301\n",
      "Epoch 737/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1277.2437 - mae: 1277.2437 - val_loss: 1383.6659 - val_mae: 1383.6659\n",
      "Epoch 738/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1277.4141 - mae: 1277.4141 - val_loss: 1383.0168 - val_mae: 1383.0168\n",
      "Epoch 739/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1277.7104 - mae: 1277.7104 - val_loss: 1384.5199 - val_mae: 1384.5199\n",
      "Epoch 740/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1278.1443 - mae: 1278.1443 - val_loss: 1385.3533 - val_mae: 1385.3533\n",
      "Epoch 741/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1276.6331 - mae: 1276.6331 - val_loss: 1388.0635 - val_mae: 1388.0635\n",
      "Epoch 742/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1277.1952 - mae: 1277.1952 - val_loss: 1382.3021 - val_mae: 1382.3021\n",
      "Epoch 743/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1278.1217 - mae: 1278.1217 - val_loss: 1382.6328 - val_mae: 1382.6328\n",
      "Epoch 744/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1276.7927 - mae: 1276.7927 - val_loss: 1383.5464 - val_mae: 1383.5464\n",
      "Epoch 745/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1277.0287 - mae: 1277.0287 - val_loss: 1382.9344 - val_mae: 1382.9344\n",
      "Epoch 746/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1276.6997 - mae: 1276.6997 - val_loss: 1383.6179 - val_mae: 1383.6179\n",
      "Epoch 747/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1276.0957 - mae: 1276.0957 - val_loss: 1385.4536 - val_mae: 1385.4536\n",
      "Epoch 748/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1275.5328 - mae: 1275.5328 - val_loss: 1381.8507 - val_mae: 1381.8507\n",
      "Epoch 749/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1275.1479 - mae: 1275.1479 - val_loss: 1382.8063 - val_mae: 1382.8063\n",
      "Epoch 750/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1275.3555 - mae: 1275.3555 - val_loss: 1382.7419 - val_mae: 1382.7419\n",
      "Epoch 751/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1275.2065 - mae: 1275.2065 - val_loss: 1388.4449 - val_mae: 1388.4449\n",
      "Epoch 752/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1275.1759 - mae: 1275.1759 - val_loss: 1380.0686 - val_mae: 1380.0686\n",
      "Epoch 753/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1275.3556 - mae: 1275.3556 - val_loss: 1386.7084 - val_mae: 1386.7084\n",
      "Epoch 754/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1275.1554 - mae: 1275.1554 - val_loss: 1379.2928 - val_mae: 1379.2928\n",
      "Epoch 755/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1274.2300 - mae: 1274.2300 - val_loss: 1379.6512 - val_mae: 1379.6512\n",
      "Epoch 756/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1273.7698 - mae: 1273.7698 - val_loss: 1384.2733 - val_mae: 1384.2733\n",
      "Epoch 757/1000\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1274.2858 - mae: 1274.2858 - val_loss: 1378.5641 - val_mae: 1378.5641\n",
      "Epoch 758/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1274.4154 - mae: 1274.4154 - val_loss: 1381.7465 - val_mae: 1381.7465\n",
      "Epoch 759/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1273.1787 - mae: 1273.1787 - val_loss: 1383.1036 - val_mae: 1383.1036\n",
      "Epoch 760/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1272.9695 - mae: 1272.9695 - val_loss: 1380.7079 - val_mae: 1380.7079\n",
      "Epoch 761/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1273.0558 - mae: 1273.0558 - val_loss: 1382.9203 - val_mae: 1382.9203\n",
      "Epoch 762/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1273.6396 - mae: 1273.6396 - val_loss: 1378.3914 - val_mae: 1378.3914\n",
      "Epoch 763/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1272.6162 - mae: 1272.6162 - val_loss: 1378.5576 - val_mae: 1378.5576\n",
      "Epoch 764/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1272.8451 - mae: 1272.8451 - val_loss: 1380.9585 - val_mae: 1380.9585\n",
      "Epoch 765/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1273.2059 - mae: 1273.2059 - val_loss: 1380.3584 - val_mae: 1380.3584\n",
      "Epoch 766/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1272.1403 - mae: 1272.1403 - val_loss: 1378.9254 - val_mae: 1378.9254\n",
      "Epoch 767/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1271.6422 - mae: 1271.6422 - val_loss: 1382.3225 - val_mae: 1382.3225\n",
      "Epoch 768/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1271.6952 - mae: 1271.6952 - val_loss: 1377.9231 - val_mae: 1377.9231\n",
      "Epoch 769/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1271.3925 - mae: 1271.3925 - val_loss: 1376.5471 - val_mae: 1376.5471\n",
      "Epoch 770/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1271.5289 - mae: 1271.5289 - val_loss: 1383.1473 - val_mae: 1383.1473\n",
      "Epoch 771/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1270.9420 - mae: 1270.9420 - val_loss: 1378.5020 - val_mae: 1378.5020\n",
      "Epoch 772/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1270.7068 - mae: 1270.7068 - val_loss: 1376.6559 - val_mae: 1376.6559\n",
      "Epoch 773/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1271.6290 - mae: 1271.6290 - val_loss: 1376.2058 - val_mae: 1376.2058\n",
      "Epoch 774/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1271.9012 - mae: 1271.9012 - val_loss: 1376.5616 - val_mae: 1376.5616\n",
      "Epoch 775/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1271.3860 - mae: 1271.3860 - val_loss: 1376.8627 - val_mae: 1376.8627\n",
      "Epoch 776/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1270.7347 - mae: 1270.7347 - val_loss: 1375.7485 - val_mae: 1375.7485\n",
      "Epoch 777/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1270.9305 - mae: 1270.9305 - val_loss: 1377.3494 - val_mae: 1377.3494\n",
      "Epoch 778/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1269.4174 - mae: 1269.4174 - val_loss: 1375.7648 - val_mae: 1375.7648\n",
      "Epoch 779/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1270.3500 - mae: 1270.3500 - val_loss: 1376.4851 - val_mae: 1376.4851\n",
      "Epoch 780/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1269.9965 - mae: 1269.9965 - val_loss: 1374.7064 - val_mae: 1374.7064\n",
      "Epoch 781/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1270.3182 - mae: 1270.3182 - val_loss: 1377.7086 - val_mae: 1377.7086\n",
      "Epoch 782/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1269.0797 - mae: 1269.0797 - val_loss: 1376.7256 - val_mae: 1376.7256\n",
      "Epoch 783/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1268.8586 - mae: 1268.8586 - val_loss: 1376.3661 - val_mae: 1376.3661\n",
      "Epoch 784/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1269.0427 - mae: 1269.0427 - val_loss: 1378.4891 - val_mae: 1378.4891\n",
      "Epoch 785/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1268.4209 - mae: 1268.4209 - val_loss: 1374.5498 - val_mae: 1374.5498\n",
      "Epoch 786/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1268.9314 - mae: 1268.9314 - val_loss: 1375.4065 - val_mae: 1375.4065\n",
      "Epoch 787/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1268.4187 - mae: 1268.4187 - val_loss: 1374.1909 - val_mae: 1374.1909\n",
      "Epoch 788/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1268.1017 - mae: 1268.1017 - val_loss: 1374.7744 - val_mae: 1374.7744\n",
      "Epoch 789/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1267.7025 - mae: 1267.7025 - val_loss: 1374.2726 - val_mae: 1374.2726\n",
      "Epoch 790/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1268.3281 - mae: 1268.3281 - val_loss: 1376.7025 - val_mae: 1376.7025\n",
      "Epoch 791/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1267.8087 - mae: 1267.8087 - val_loss: 1374.1167 - val_mae: 1374.1167\n",
      "Epoch 792/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1267.5730 - mae: 1267.5730 - val_loss: 1379.8997 - val_mae: 1379.8997\n",
      "Epoch 793/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1267.1349 - mae: 1267.1349 - val_loss: 1374.3246 - val_mae: 1374.3246\n",
      "Epoch 794/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1267.4069 - mae: 1267.4069 - val_loss: 1371.6326 - val_mae: 1371.6326\n",
      "Epoch 795/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1267.7186 - mae: 1267.7186 - val_loss: 1379.2987 - val_mae: 1379.2987\n",
      "Epoch 796/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1266.7748 - mae: 1266.7748 - val_loss: 1374.9192 - val_mae: 1374.9192\n",
      "Epoch 797/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1266.5488 - mae: 1266.5488 - val_loss: 1376.2134 - val_mae: 1376.2134\n",
      "Epoch 798/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1266.0491 - mae: 1266.0491 - val_loss: 1375.6365 - val_mae: 1375.6365\n",
      "Epoch 799/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1266.4952 - mae: 1266.4952 - val_loss: 1373.1256 - val_mae: 1373.1256\n",
      "Epoch 800/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1265.5660 - mae: 1265.5660 - val_loss: 1372.2933 - val_mae: 1372.2933\n",
      "Epoch 801/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1265.7705 - mae: 1265.7705 - val_loss: 1374.6604 - val_mae: 1374.6604\n",
      "Epoch 802/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1265.8044 - mae: 1265.8044 - val_loss: 1374.3552 - val_mae: 1374.3552\n",
      "Epoch 803/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1265.8358 - mae: 1265.8358 - val_loss: 1371.7847 - val_mae: 1371.7847\n",
      "Epoch 804/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1266.0006 - mae: 1266.0006 - val_loss: 1375.3245 - val_mae: 1375.3245\n",
      "Epoch 805/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1265.4316 - mae: 1265.4316 - val_loss: 1371.4648 - val_mae: 1371.4648\n",
      "Epoch 806/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1265.8079 - mae: 1265.8079 - val_loss: 1372.4233 - val_mae: 1372.4233\n",
      "Epoch 807/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1264.2567 - mae: 1264.2567 - val_loss: 1375.2615 - val_mae: 1375.2615\n",
      "Epoch 808/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1265.2107 - mae: 1265.2107 - val_loss: 1373.8846 - val_mae: 1373.8846\n",
      "Epoch 809/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1264.7358 - mae: 1264.7358 - val_loss: 1371.8582 - val_mae: 1371.8582\n",
      "Epoch 810/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1263.8931 - mae: 1263.8931 - val_loss: 1371.4338 - val_mae: 1371.4338\n",
      "Epoch 811/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1263.9263 - mae: 1263.9263 - val_loss: 1372.0238 - val_mae: 1372.0238\n",
      "Epoch 812/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1266.0208 - mae: 1266.0208 - val_loss: 1374.0023 - val_mae: 1374.0023\n",
      "Epoch 813/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1266.0132 - mae: 1266.0132 - val_loss: 1373.5386 - val_mae: 1373.5386\n",
      "Epoch 814/1000\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 1263.8639 - mae: 1263.8639 - val_loss: 1370.6052 - val_mae: 1370.6052\n",
      "Epoch 815/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1264.6130 - mae: 1264.6130 - val_loss: 1373.7358 - val_mae: 1373.7358\n",
      "Epoch 816/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1262.7510 - mae: 1262.7510 - val_loss: 1371.0267 - val_mae: 1371.0267\n",
      "Epoch 817/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1264.0701 - mae: 1264.0701 - val_loss: 1375.0190 - val_mae: 1375.0190\n",
      "Epoch 818/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1263.0654 - mae: 1263.0654 - val_loss: 1371.8162 - val_mae: 1371.8162\n",
      "Epoch 819/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1262.9651 - mae: 1262.9651 - val_loss: 1372.5490 - val_mae: 1372.5490\n",
      "Epoch 820/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1262.2283 - mae: 1262.2283 - val_loss: 1371.8942 - val_mae: 1371.8942\n",
      "Epoch 821/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1262.2673 - mae: 1262.2673 - val_loss: 1369.2820 - val_mae: 1369.2820\n",
      "Epoch 822/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1262.9700 - mae: 1262.9700 - val_loss: 1368.8641 - val_mae: 1368.8641\n",
      "Epoch 823/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1262.6967 - mae: 1262.6967 - val_loss: 1370.0526 - val_mae: 1370.0526\n",
      "Epoch 824/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1262.5078 - mae: 1262.5078 - val_loss: 1367.9873 - val_mae: 1367.9873\n",
      "Epoch 825/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1261.5330 - mae: 1261.5330 - val_loss: 1370.1000 - val_mae: 1370.1000\n",
      "Epoch 826/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1261.9878 - mae: 1261.9878 - val_loss: 1369.4034 - val_mae: 1369.4034\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 2ms/step - loss: 1261.2825 - mae: 1261.2825 - val_loss: 1369.1660 - val_mae: 1369.1660\n",
      "Epoch 828/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1261.3289 - mae: 1261.3289 - val_loss: 1370.5551 - val_mae: 1370.5551\n",
      "Epoch 829/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1260.6384 - mae: 1260.6384 - val_loss: 1371.1965 - val_mae: 1371.1965\n",
      "Epoch 830/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1261.2734 - mae: 1261.2734 - val_loss: 1371.9700 - val_mae: 1371.9700\n",
      "Epoch 831/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1261.6965 - mae: 1261.6965 - val_loss: 1368.8384 - val_mae: 1368.8384\n",
      "Epoch 832/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1261.2982 - mae: 1261.2982 - val_loss: 1368.6528 - val_mae: 1368.6528\n",
      "Epoch 833/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1260.1978 - mae: 1260.1978 - val_loss: 1368.2744 - val_mae: 1368.2744\n",
      "Epoch 834/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1259.7312 - mae: 1259.7312 - val_loss: 1371.5435 - val_mae: 1371.5435\n",
      "Epoch 835/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1260.2358 - mae: 1260.2358 - val_loss: 1369.1672 - val_mae: 1369.1672\n",
      "Epoch 836/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1260.3903 - mae: 1260.3903 - val_loss: 1368.9672 - val_mae: 1368.9672\n",
      "Epoch 837/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1259.2057 - mae: 1259.2057 - val_loss: 1370.1204 - val_mae: 1370.1204\n",
      "Epoch 838/1000\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 1259.4698 - mae: 1259.4698 - val_loss: 1367.6857 - val_mae: 1367.6857\n",
      "Epoch 839/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1259.8409 - mae: 1259.8409 - val_loss: 1375.9596 - val_mae: 1375.9596\n",
      "Epoch 840/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1259.0156 - mae: 1259.0156 - val_loss: 1371.1077 - val_mae: 1371.1077\n",
      "Epoch 841/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1259.0311 - mae: 1259.0311 - val_loss: 1367.3912 - val_mae: 1367.3912\n",
      "Epoch 842/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1258.5920 - mae: 1258.5920 - val_loss: 1367.6682 - val_mae: 1367.6682\n",
      "Epoch 843/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1258.7311 - mae: 1258.7311 - val_loss: 1368.2144 - val_mae: 1368.2144\n",
      "Epoch 844/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1257.7035 - mae: 1257.7035 - val_loss: 1368.4248 - val_mae: 1368.4248\n",
      "Epoch 845/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1258.7557 - mae: 1258.7557 - val_loss: 1369.0510 - val_mae: 1369.0510\n",
      "Epoch 846/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1257.5447 - mae: 1257.5447 - val_loss: 1369.0907 - val_mae: 1369.0907\n",
      "Epoch 847/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1258.3693 - mae: 1258.3693 - val_loss: 1368.3757 - val_mae: 1368.3757\n",
      "Epoch 848/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1257.2722 - mae: 1257.2722 - val_loss: 1372.3193 - val_mae: 1372.3193\n",
      "Epoch 849/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1258.3710 - mae: 1258.3710 - val_loss: 1368.8441 - val_mae: 1368.8441\n",
      "Epoch 850/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1257.5150 - mae: 1257.5150 - val_loss: 1366.0016 - val_mae: 1366.0016\n",
      "Epoch 851/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1257.9585 - mae: 1257.9585 - val_loss: 1365.8806 - val_mae: 1365.8806\n",
      "Epoch 852/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1256.8146 - mae: 1256.8146 - val_loss: 1368.7461 - val_mae: 1368.7461\n",
      "Epoch 853/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1257.7295 - mae: 1257.7295 - val_loss: 1365.3099 - val_mae: 1365.3099\n",
      "Epoch 854/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1256.7729 - mae: 1256.7729 - val_loss: 1366.7770 - val_mae: 1366.7770\n",
      "Epoch 855/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1256.2692 - mae: 1256.2692 - val_loss: 1365.2080 - val_mae: 1365.2080\n",
      "Epoch 856/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1256.5575 - mae: 1256.5575 - val_loss: 1366.8806 - val_mae: 1366.8806\n",
      "Epoch 857/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1255.8624 - mae: 1255.8624 - val_loss: 1368.7603 - val_mae: 1368.7603\n",
      "Epoch 858/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1255.8582 - mae: 1255.8582 - val_loss: 1367.7942 - val_mae: 1367.7942\n",
      "Epoch 859/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1255.7498 - mae: 1255.7498 - val_loss: 1367.3884 - val_mae: 1367.3884\n",
      "Epoch 860/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1256.5120 - mae: 1256.5120 - val_loss: 1365.2228 - val_mae: 1365.2228\n",
      "Epoch 861/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1256.1653 - mae: 1256.1653 - val_loss: 1362.6051 - val_mae: 1362.6051\n",
      "Epoch 862/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1255.3009 - mae: 1255.3009 - val_loss: 1362.3632 - val_mae: 1362.3632\n",
      "Epoch 863/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1254.9650 - mae: 1254.9650 - val_loss: 1362.4366 - val_mae: 1362.4366\n",
      "Epoch 864/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1255.7318 - mae: 1255.7318 - val_loss: 1364.8301 - val_mae: 1364.8301\n",
      "Epoch 865/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1254.6985 - mae: 1254.6985 - val_loss: 1362.6306 - val_mae: 1362.6306\n",
      "Epoch 866/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1254.8506 - mae: 1254.8506 - val_loss: 1365.4601 - val_mae: 1365.4601\n",
      "Epoch 867/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1254.1975 - mae: 1254.1975 - val_loss: 1364.4398 - val_mae: 1364.4398\n",
      "Epoch 868/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1254.2812 - mae: 1254.2812 - val_loss: 1363.8833 - val_mae: 1363.8833\n",
      "Epoch 869/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1254.5961 - mae: 1254.5961 - val_loss: 1363.9387 - val_mae: 1363.9387\n",
      "Epoch 870/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1254.2401 - mae: 1254.2401 - val_loss: 1366.8843 - val_mae: 1366.8843\n",
      "Epoch 871/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1254.2708 - mae: 1254.2708 - val_loss: 1365.6648 - val_mae: 1365.6648\n",
      "Epoch 872/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1253.8428 - mae: 1253.8428 - val_loss: 1362.5452 - val_mae: 1362.5452\n",
      "Epoch 873/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1253.1941 - mae: 1253.1941 - val_loss: 1365.9744 - val_mae: 1365.9744\n",
      "Epoch 874/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1252.8428 - mae: 1252.8428 - val_loss: 1362.2867 - val_mae: 1362.2867\n",
      "Epoch 875/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1253.4922 - mae: 1253.4922 - val_loss: 1362.5884 - val_mae: 1362.5884\n",
      "Epoch 876/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1253.9360 - mae: 1253.9360 - val_loss: 1360.9767 - val_mae: 1360.9767\n",
      "Epoch 877/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1253.2606 - mae: 1253.2606 - val_loss: 1360.1898 - val_mae: 1360.1898\n",
      "Epoch 878/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1253.9111 - mae: 1253.9111 - val_loss: 1364.0968 - val_mae: 1364.0968\n",
      "Epoch 879/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1253.1643 - mae: 1253.1643 - val_loss: 1363.4462 - val_mae: 1363.4462\n",
      "Epoch 880/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1253.2482 - mae: 1253.2482 - val_loss: 1366.8257 - val_mae: 1366.8257\n",
      "Epoch 881/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1252.8785 - mae: 1252.8785 - val_loss: 1363.4855 - val_mae: 1363.4855\n",
      "Epoch 882/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1252.8738 - mae: 1252.8738 - val_loss: 1362.5792 - val_mae: 1362.5792\n",
      "Epoch 883/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1252.9253 - mae: 1252.9253 - val_loss: 1363.7036 - val_mae: 1363.7036\n",
      "Epoch 884/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1252.5029 - mae: 1252.5029 - val_loss: 1364.2075 - val_mae: 1364.2075\n",
      "Epoch 885/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1252.1495 - mae: 1252.1495 - val_loss: 1364.2505 - val_mae: 1364.2505\n",
      "Epoch 886/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1251.2056 - mae: 1251.2056 - val_loss: 1369.8623 - val_mae: 1369.8623\n",
      "Epoch 887/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1252.0424 - mae: 1252.0424 - val_loss: 1361.4298 - val_mae: 1361.4298\n",
      "Epoch 888/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1251.8042 - mae: 1251.8042 - val_loss: 1366.4110 - val_mae: 1366.4110\n",
      "Epoch 889/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1252.0787 - mae: 1252.0787 - val_loss: 1363.5452 - val_mae: 1363.5452\n",
      "Epoch 890/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1251.2357 - mae: 1251.2357 - val_loss: 1368.7202 - val_mae: 1368.7202\n",
      "Epoch 891/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1251.1394 - mae: 1251.1394 - val_loss: 1361.8132 - val_mae: 1361.8132\n",
      "Epoch 892/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1251.5951 - mae: 1251.5951 - val_loss: 1365.6874 - val_mae: 1365.6874\n",
      "Epoch 893/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1250.0157 - mae: 1250.0157 - val_loss: 1363.4918 - val_mae: 1363.4918\n",
      "Epoch 894/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1250.8080 - mae: 1250.8080 - val_loss: 1361.2544 - val_mae: 1361.2544\n",
      "Epoch 895/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1250.9788 - mae: 1250.9788 - val_loss: 1363.2878 - val_mae: 1363.2878\n",
      "Epoch 896/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1250.0969 - mae: 1250.0969 - val_loss: 1361.5758 - val_mae: 1361.5758\n",
      "Epoch 897/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1249.9712 - mae: 1249.9712 - val_loss: 1360.1101 - val_mae: 1360.1101\n",
      "Epoch 898/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1250.1920 - mae: 1250.1920 - val_loss: 1363.3099 - val_mae: 1363.3099\n",
      "Epoch 899/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1250.2947 - mae: 1250.2947 - val_loss: 1360.0291 - val_mae: 1360.0291\n",
      "Epoch 900/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1249.9037 - mae: 1249.9037 - val_loss: 1359.1884 - val_mae: 1359.1884\n",
      "Epoch 901/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1250.1960 - mae: 1250.1960 - val_loss: 1359.5664 - val_mae: 1359.5664\n",
      "Epoch 902/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1249.5919 - mae: 1249.5919 - val_loss: 1359.4287 - val_mae: 1359.4287\n",
      "Epoch 903/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1249.6366 - mae: 1249.6366 - val_loss: 1361.6085 - val_mae: 1361.6085\n",
      "Epoch 904/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1249.6683 - mae: 1249.6683 - val_loss: 1359.9823 - val_mae: 1359.9823\n",
      "Epoch 905/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1248.7059 - mae: 1248.7059 - val_loss: 1360.2354 - val_mae: 1360.2354\n",
      "Epoch 906/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1248.9622 - mae: 1248.9622 - val_loss: 1360.3041 - val_mae: 1360.3041\n",
      "Epoch 907/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1248.9778 - mae: 1248.9778 - val_loss: 1359.9438 - val_mae: 1359.9438\n",
      "Epoch 908/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1248.3865 - mae: 1248.3865 - val_loss: 1363.9745 - val_mae: 1363.9745\n",
      "Epoch 909/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1248.7340 - mae: 1248.7340 - val_loss: 1358.4198 - val_mae: 1358.4198\n",
      "Epoch 910/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1247.7446 - mae: 1247.7446 - val_loss: 1357.6464 - val_mae: 1357.6464\n",
      "Epoch 911/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1247.6771 - mae: 1247.6771 - val_loss: 1358.0802 - val_mae: 1358.0802\n",
      "Epoch 912/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1248.1389 - mae: 1248.1389 - val_loss: 1358.4557 - val_mae: 1358.4557\n",
      "Epoch 913/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1247.7152 - mae: 1247.7152 - val_loss: 1359.8651 - val_mae: 1359.8651\n",
      "Epoch 914/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1247.7312 - mae: 1247.7312 - val_loss: 1358.4670 - val_mae: 1358.4670\n",
      "Epoch 915/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1247.2659 - mae: 1247.2659 - val_loss: 1358.4452 - val_mae: 1358.4452\n",
      "Epoch 916/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1247.8624 - mae: 1247.8624 - val_loss: 1358.5857 - val_mae: 1358.5857\n",
      "Epoch 917/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1247.3132 - mae: 1247.3132 - val_loss: 1360.3372 - val_mae: 1360.3372\n",
      "Epoch 918/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1246.5504 - mae: 1246.5504 - val_loss: 1360.4371 - val_mae: 1360.4371\n",
      "Epoch 919/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1246.1515 - mae: 1246.1515 - val_loss: 1361.3695 - val_mae: 1361.3695\n",
      "Epoch 920/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1247.0912 - mae: 1247.0912 - val_loss: 1361.1090 - val_mae: 1361.1090\n",
      "Epoch 921/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1247.0905 - mae: 1247.0905 - val_loss: 1358.6049 - val_mae: 1358.6049\n",
      "Epoch 922/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1247.4240 - mae: 1247.4240 - val_loss: 1357.9148 - val_mae: 1357.9148\n",
      "Epoch 923/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1247.8240 - mae: 1247.8240 - val_loss: 1357.1215 - val_mae: 1357.1215\n",
      "Epoch 924/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1245.8557 - mae: 1245.8557 - val_loss: 1360.0970 - val_mae: 1360.0970\n",
      "Epoch 925/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1246.0363 - mae: 1246.0363 - val_loss: 1357.8907 - val_mae: 1357.8907\n",
      "Epoch 926/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1245.7858 - mae: 1245.7858 - val_loss: 1359.0280 - val_mae: 1359.0280\n",
      "Epoch 927/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1246.1102 - mae: 1246.1102 - val_loss: 1362.4915 - val_mae: 1362.4915\n",
      "Epoch 928/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1245.1527 - mae: 1245.1527 - val_loss: 1357.3213 - val_mae: 1357.3213\n",
      "Epoch 929/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1245.3260 - mae: 1245.3260 - val_loss: 1356.1449 - val_mae: 1356.1449\n",
      "Epoch 930/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1245.5049 - mae: 1245.5049 - val_loss: 1359.4490 - val_mae: 1359.4490\n",
      "Epoch 931/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1245.8003 - mae: 1245.8003 - val_loss: 1359.2122 - val_mae: 1359.2122\n",
      "Epoch 932/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1245.0367 - mae: 1245.0367 - val_loss: 1360.0833 - val_mae: 1360.0833\n",
      "Epoch 933/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1244.4802 - mae: 1244.4802 - val_loss: 1357.1427 - val_mae: 1357.1427\n",
      "Epoch 934/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1243.8275 - mae: 1243.8275 - val_loss: 1359.0342 - val_mae: 1359.0342\n",
      "Epoch 935/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1244.5759 - mae: 1244.5759 - val_loss: 1359.0116 - val_mae: 1359.0116\n",
      "Epoch 936/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1243.8004 - mae: 1243.8004 - val_loss: 1358.7704 - val_mae: 1358.7704\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 2ms/step - loss: 1244.3911 - mae: 1244.3911 - val_loss: 1362.9336 - val_mae: 1362.9336\n",
      "Epoch 938/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1243.7069 - mae: 1243.7069 - val_loss: 1357.5443 - val_mae: 1357.5443\n",
      "Epoch 939/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1244.0222 - mae: 1244.0222 - val_loss: 1357.4236 - val_mae: 1357.4236\n",
      "Epoch 940/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1243.7725 - mae: 1243.7725 - val_loss: 1355.1501 - val_mae: 1355.1501\n",
      "Epoch 941/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1243.4374 - mae: 1243.4374 - val_loss: 1354.8702 - val_mae: 1354.8702\n",
      "Epoch 942/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1242.9135 - mae: 1242.9135 - val_loss: 1356.9854 - val_mae: 1356.9854\n",
      "Epoch 943/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1243.2717 - mae: 1243.2717 - val_loss: 1356.7086 - val_mae: 1356.7086\n",
      "Epoch 944/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1243.3193 - mae: 1243.3193 - val_loss: 1354.9066 - val_mae: 1354.9066\n",
      "Epoch 945/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1242.3607 - mae: 1242.3607 - val_loss: 1355.1901 - val_mae: 1355.1901\n",
      "Epoch 946/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1242.2590 - mae: 1242.2590 - val_loss: 1357.2443 - val_mae: 1357.2443\n",
      "Epoch 947/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1242.3633 - mae: 1242.3633 - val_loss: 1353.6523 - val_mae: 1353.6523\n",
      "Epoch 948/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1242.9099 - mae: 1242.9099 - val_loss: 1357.6237 - val_mae: 1357.6237\n",
      "Epoch 949/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1241.8826 - mae: 1241.8826 - val_loss: 1353.5525 - val_mae: 1353.5525\n",
      "Epoch 950/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1242.2098 - mae: 1242.2098 - val_loss: 1365.0858 - val_mae: 1365.0858\n",
      "Epoch 951/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1242.8259 - mae: 1242.8259 - val_loss: 1354.0414 - val_mae: 1354.0414\n",
      "Epoch 952/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1242.0066 - mae: 1242.0066 - val_loss: 1355.3666 - val_mae: 1355.3666\n",
      "Epoch 953/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1241.0742 - mae: 1241.0742 - val_loss: 1354.5729 - val_mae: 1354.5729\n",
      "Epoch 954/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1241.1827 - mae: 1241.1827 - val_loss: 1355.2549 - val_mae: 1355.2549\n",
      "Epoch 955/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1241.7432 - mae: 1241.7432 - val_loss: 1354.5936 - val_mae: 1354.5936\n",
      "Epoch 956/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1241.3651 - mae: 1241.3651 - val_loss: 1353.4187 - val_mae: 1353.4187\n",
      "Epoch 957/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1241.9800 - mae: 1241.9800 - val_loss: 1354.7742 - val_mae: 1354.7742\n",
      "Epoch 958/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1241.2516 - mae: 1241.2516 - val_loss: 1355.9326 - val_mae: 1355.9326\n",
      "Epoch 959/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1240.9470 - mae: 1240.9470 - val_loss: 1355.7876 - val_mae: 1355.7876\n",
      "Epoch 960/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1240.2603 - mae: 1240.2603 - val_loss: 1356.2103 - val_mae: 1356.2103\n",
      "Epoch 961/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1240.5847 - mae: 1240.5847 - val_loss: 1359.0991 - val_mae: 1359.0991\n",
      "Epoch 962/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1239.8611 - mae: 1239.8611 - val_loss: 1358.8048 - val_mae: 1358.8048\n",
      "Epoch 963/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1240.8007 - mae: 1240.8007 - val_loss: 1358.5527 - val_mae: 1358.5527\n",
      "Epoch 964/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1241.1913 - mae: 1241.1913 - val_loss: 1355.1877 - val_mae: 1355.1877\n",
      "Epoch 965/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1240.0060 - mae: 1240.0060 - val_loss: 1354.5282 - val_mae: 1354.5282\n",
      "Epoch 966/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1239.9661 - mae: 1239.9661 - val_loss: 1354.7001 - val_mae: 1354.7001\n",
      "Epoch 967/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1239.8192 - mae: 1239.8192 - val_loss: 1357.6412 - val_mae: 1357.6412\n",
      "Epoch 968/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1239.1869 - mae: 1239.1869 - val_loss: 1356.4247 - val_mae: 1356.4247\n",
      "Epoch 969/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1239.4484 - mae: 1239.4484 - val_loss: 1354.8395 - val_mae: 1354.8395\n",
      "Epoch 970/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1238.7937 - mae: 1238.7937 - val_loss: 1359.0277 - val_mae: 1359.0277\n",
      "Epoch 971/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1239.3516 - mae: 1239.3516 - val_loss: 1355.3794 - val_mae: 1355.3794\n",
      "Epoch 972/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1238.8796 - mae: 1238.8796 - val_loss: 1355.7506 - val_mae: 1355.7506\n",
      "Epoch 973/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1239.4658 - mae: 1239.4658 - val_loss: 1355.1721 - val_mae: 1355.1721\n",
      "Epoch 974/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1238.2885 - mae: 1238.2885 - val_loss: 1356.6868 - val_mae: 1356.6868\n",
      "Epoch 975/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1238.1866 - mae: 1238.1866 - val_loss: 1353.9575 - val_mae: 1353.9575\n",
      "Epoch 976/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1238.4592 - mae: 1238.4592 - val_loss: 1359.6390 - val_mae: 1359.6390\n",
      "Epoch 977/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1238.8759 - mae: 1238.8759 - val_loss: 1355.2742 - val_mae: 1355.2742\n",
      "Epoch 978/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1238.1644 - mae: 1238.1644 - val_loss: 1352.5963 - val_mae: 1352.5963\n",
      "Epoch 979/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1238.3142 - mae: 1238.3142 - val_loss: 1356.4587 - val_mae: 1356.4587\n",
      "Epoch 980/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1237.5576 - mae: 1237.5576 - val_loss: 1356.7924 - val_mae: 1356.7924\n",
      "Epoch 981/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1238.4290 - mae: 1238.4290 - val_loss: 1354.7913 - val_mae: 1354.7913\n",
      "Epoch 982/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1238.0269 - mae: 1238.0269 - val_loss: 1352.5641 - val_mae: 1352.5641\n",
      "Epoch 983/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1236.8513 - mae: 1236.8513 - val_loss: 1358.7324 - val_mae: 1358.7324\n",
      "Epoch 984/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1237.3163 - mae: 1237.3163 - val_loss: 1352.6000 - val_mae: 1352.6000\n",
      "Epoch 985/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1237.3805 - mae: 1237.3805 - val_loss: 1350.8691 - val_mae: 1350.8691\n",
      "Epoch 986/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1236.6761 - mae: 1236.6761 - val_loss: 1355.0723 - val_mae: 1355.0723\n",
      "Epoch 987/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1237.2582 - mae: 1237.2582 - val_loss: 1354.2284 - val_mae: 1354.2284\n",
      "Epoch 988/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1236.7860 - mae: 1236.7860 - val_loss: 1353.1605 - val_mae: 1353.1605\n",
      "Epoch 989/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1236.6162 - mae: 1236.6162 - val_loss: 1353.0159 - val_mae: 1353.0159\n",
      "Epoch 990/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1236.8672 - mae: 1236.8672 - val_loss: 1352.8077 - val_mae: 1352.8077\n",
      "Epoch 991/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1236.5862 - mae: 1236.5862 - val_loss: 1356.4109 - val_mae: 1356.4109\n",
      "Epoch 992/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1236.5721 - mae: 1236.5721 - val_loss: 1352.1771 - val_mae: 1352.1771\n",
      "Epoch 993/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1235.0219 - mae: 1235.0219 - val_loss: 1349.5907 - val_mae: 1349.5907\n",
      "Epoch 994/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1235.7081 - mae: 1235.7081 - val_loss: 1351.1925 - val_mae: 1351.1925\n",
      "Epoch 995/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1236.5350 - mae: 1236.5350 - val_loss: 1350.5823 - val_mae: 1350.5823\n",
      "Epoch 996/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1235.2046 - mae: 1235.2046 - val_loss: 1351.7960 - val_mae: 1351.7960\n",
      "Epoch 997/1000\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 1235.1995 - mae: 1235.1995 - val_loss: 1352.6234 - val_mae: 1352.6234\n",
      "Epoch 998/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1235.4470 - mae: 1235.4470 - val_loss: 1351.4528 - val_mae: 1351.4528\n",
      "Epoch 999/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1234.3490 - mae: 1234.3490 - val_loss: 1356.7117 - val_mae: 1356.7117\n",
      "Epoch 1000/1000\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 1235.2140 - mae: 1235.2140 - val_loss: 1351.2072 - val_mae: 1351.2072\n"
     ]
    }
   ],
   "source": [
    "# Base model-2\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model2.h5\", save_best_only=True)\n",
    "\n",
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=x_train_scaled.shape[1:]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model2.compile(loss=keras.losses.mean_absolute_error,\n",
    "             optimizer=keras.optimizers.Adam(),\n",
    "             metrics=[\"mae\"])\n",
    "\n",
    "history2 = model2.fit(x_train_scaled,y_train,\n",
    "                   epochs=1000,\n",
    "                   validation_data=(x_test_scaled,y_test),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7912227587986583\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred_model2 = model2.predict(x_test_scaled)\n",
    "print(metrics.r2_score(y_test, y_pred_model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "    \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.plot(epochs, loss, color=\"green\", label=\"loss\")\n",
    "    plt.plot(epochs, val_loss, color=\"red\", label=\"val_loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_curves(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the prediction Curve\n",
    "def plot_prediction_curve(model, train_data, test_data, train_target, test_target):\n",
    "    \n",
    "    # plot the training curve\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(2,1,1)\n",
    "    train_predict = model.predict(train_data)\n",
    "    plt.scatter(train_target, train_predict)\n",
    "    plt.plot([train_target.min(),train_target.max()], [train_target.min(),train_target.max()],\n",
    "            color=\"red\", linestyle=\"dashed\")\n",
    "    plt.title(\"Train-Data\")\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"predicted\")\n",
    "    plt.show()\n",
    "    \n",
    "    # plotting the test curve\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(2,1,2)\n",
    "    test_predict = model.predict(test_data)\n",
    "    plt.scatter(test_target, test_predict)\n",
    "    plt.plot([test_target.min(),test_target.max()], [test_target.min(),test_target.max()],\n",
    "            color=\"red\", linestyle=\"dashed\")\n",
    "    plt.title(\"Test-Data\")\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"predicted\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_prediction_curve(model2, x_train_scaled, x_test_scaled, y_train, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  1/268 [..............................] - ETA: 0s - loss: 8366.6768WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0040s). Check your callbacks.\n",
      "262/268 [============================>.] - ETA: 0s - loss: 4786.4229WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 4731.4985 - val_loss: 2039.3875\n",
      "Epoch 2/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1893.6702 - val_loss: 1973.1547\n",
      "Epoch 3/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1795.8444 - val_loss: 1828.6400\n",
      "Epoch 4/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1740.8877 - val_loss: 1788.9048\n",
      "Epoch 5/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1704.8369 - val_loss: 1768.1033\n",
      "Epoch 6/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1679.2148 - val_loss: 1736.8866\n",
      "Epoch 7/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1659.2939 - val_loss: 1712.5891\n",
      "Epoch 8/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1636.7014 - val_loss: 1712.8672\n",
      "Epoch 9/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1623.4193 - val_loss: 1695.0995\n",
      "Epoch 10/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1611.1809 - val_loss: 1689.5323\n",
      "Epoch 11/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1595.8141 - val_loss: 1664.0410\n",
      "Epoch 12/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1583.6438 - val_loss: 1665.3865\n",
      "Epoch 13/1000\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 1575.3237 - val_loss: 1657.3553\n",
      "Epoch 14/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1567.3987 - val_loss: 1633.7723\n",
      "Epoch 15/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1558.4755 - val_loss: 1634.1586\n",
      "Epoch 16/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1547.5765 - val_loss: 1615.1678\n",
      "Epoch 17/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1533.9871 - val_loss: 1637.5211\n",
      "Epoch 18/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1529.4805 - val_loss: 1595.6354\n",
      "Epoch 19/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1518.1432 - val_loss: 1599.8278\n",
      "Epoch 20/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1518.5146 - val_loss: 1587.5353\n",
      "Epoch 21/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1505.1010 - val_loss: 1583.8776\n",
      "Epoch 22/1000\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 1499.0406 - val_loss: 1571.9495\n",
      "Epoch 23/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1491.4388 - val_loss: 1573.8265\n",
      "Epoch 24/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1489.6979 - val_loss: 1583.8009\n",
      "Epoch 25/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1477.0367 - val_loss: 1572.9418\n",
      "Epoch 26/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1475.7411 - val_loss: 1551.2756\n",
      "Epoch 27/1000\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 1466.3815 - val_loss: 1544.9868\n",
      "Epoch 28/1000\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 1457.8119 - val_loss: 1540.0182\n",
      "Epoch 29/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1452.9735 - val_loss: 1540.9956\n",
      "Epoch 30/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1450.6788 - val_loss: 1531.0594\n",
      "Epoch 31/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1436.8113 - val_loss: 1538.9731\n",
      "Epoch 32/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1432.2063 - val_loss: 1513.9204\n",
      "Epoch 33/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1425.6572 - val_loss: 1513.7441\n",
      "Epoch 34/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1422.5978 - val_loss: 1517.6157\n",
      "Epoch 35/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1416.0864 - val_loss: 1504.6556\n",
      "Epoch 36/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1411.2417 - val_loss: 1502.7335\n",
      "Epoch 37/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1404.8755 - val_loss: 1502.5018\n",
      "Epoch 38/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1398.0907 - val_loss: 1492.1836\n",
      "Epoch 39/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1394.3070 - val_loss: 1499.4879\n",
      "Epoch 40/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1392.5883 - val_loss: 1520.9402\n",
      "Epoch 41/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1385.7379 - val_loss: 1482.7266\n",
      "Epoch 42/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1384.5254 - val_loss: 1484.5492\n",
      "Epoch 43/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1377.3839 - val_loss: 1481.9543\n",
      "Epoch 44/1000\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 1375.2885 - val_loss: 1462.1689\n",
      "Epoch 45/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1372.9913 - val_loss: 1463.1285\n",
      "Epoch 46/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1372.3682 - val_loss: 1453.3801\n",
      "Epoch 47/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1360.3961 - val_loss: 1482.9277\n",
      "Epoch 48/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1359.7164 - val_loss: 1452.3947\n",
      "Epoch 49/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1355.0483 - val_loss: 1465.7604\n",
      "Epoch 50/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1354.9529 - val_loss: 1458.0602\n",
      "Epoch 51/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1344.9230 - val_loss: 1453.2725\n",
      "Epoch 52/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1343.0734 - val_loss: 1444.5828\n",
      "Epoch 53/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1338.9818 - val_loss: 1456.9971\n",
      "Epoch 54/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1340.7017 - val_loss: 1455.1907\n",
      "Epoch 55/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1336.1749 - val_loss: 1447.1229\n",
      "Epoch 56/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1328.9631 - val_loss: 1446.1327\n",
      "Epoch 57/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1326.6782 - val_loss: 1430.1102\n",
      "Epoch 58/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1319.2111 - val_loss: 1446.2632\n",
      "Epoch 59/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1317.3098 - val_loss: 1453.8241\n",
      "Epoch 60/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1315.7244 - val_loss: 1450.1992\n",
      "Epoch 61/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1312.8740 - val_loss: 1422.6312\n",
      "Epoch 62/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1306.6531 - val_loss: 1416.8391\n",
      "Epoch 63/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1305.8805 - val_loss: 1414.8944\n",
      "Epoch 64/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1302.0920 - val_loss: 1420.7094\n",
      "Epoch 65/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1297.5646 - val_loss: 1409.0522\n",
      "Epoch 66/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1299.6354 - val_loss: 1415.2618\n",
      "Epoch 67/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1296.8743 - val_loss: 1421.3799\n",
      "Epoch 68/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1289.7947 - val_loss: 1394.8992\n",
      "Epoch 69/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1287.5557 - val_loss: 1403.5846\n",
      "Epoch 70/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1291.0532 - val_loss: 1422.2148\n",
      "Epoch 71/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1278.5878 - val_loss: 1404.2936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1284.8136 - val_loss: 1399.3871\n",
      "Epoch 73/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1281.6333 - val_loss: 1381.3678\n",
      "Epoch 74/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1276.4747 - val_loss: 1403.2753\n",
      "Epoch 75/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1271.1237 - val_loss: 1380.8864\n",
      "Epoch 76/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1269.0372 - val_loss: 1404.7603\n",
      "Epoch 77/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1268.6263 - val_loss: 1415.4470\n",
      "Epoch 78/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1269.2977 - val_loss: 1406.4526\n",
      "Epoch 79/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1264.1536 - val_loss: 1384.4707\n",
      "Epoch 80/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1256.4128 - val_loss: 1375.3528\n",
      "Epoch 81/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1252.6919 - val_loss: 1370.1763\n",
      "Epoch 82/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1250.6841 - val_loss: 1430.9065\n",
      "Epoch 83/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1248.7997 - val_loss: 1370.6238\n",
      "Epoch 84/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1243.8824 - val_loss: 1382.0374\n",
      "Epoch 85/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1245.0295 - val_loss: 1375.1887\n",
      "Epoch 86/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1238.4537 - val_loss: 1371.8278\n",
      "Epoch 87/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1241.9135 - val_loss: 1369.3827\n",
      "Epoch 88/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1240.4227 - val_loss: 1371.3192\n",
      "Epoch 89/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1233.5010 - val_loss: 1357.6688\n",
      "Epoch 90/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1227.6493 - val_loss: 1392.0715\n",
      "Epoch 91/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1238.1570 - val_loss: 1353.2378\n",
      "Epoch 92/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1220.3850 - val_loss: 1364.5042\n",
      "Epoch 93/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1230.8220 - val_loss: 1366.1653\n",
      "Epoch 94/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1226.9655 - val_loss: 1401.5034\n",
      "Epoch 95/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1230.8573 - val_loss: 1409.6112\n",
      "Epoch 96/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1221.8711 - val_loss: 1374.4523\n",
      "Epoch 97/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1223.7408 - val_loss: 1366.5906\n",
      "Epoch 98/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1220.5306 - val_loss: 1335.4260\n",
      "Epoch 99/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1213.9796 - val_loss: 1375.3457\n",
      "Epoch 100/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1208.5911 - val_loss: 1372.1915\n",
      "Epoch 101/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1210.7531 - val_loss: 1345.7235\n",
      "Epoch 102/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1208.8822 - val_loss: 1350.6871\n",
      "Epoch 103/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1205.6494 - val_loss: 1349.5303\n",
      "Epoch 104/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1208.5059 - val_loss: 1356.6099\n",
      "Epoch 105/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1202.4084 - val_loss: 1345.0829\n",
      "Epoch 106/1000\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 1199.8953 - val_loss: 1333.6188\n",
      "Epoch 107/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1194.3519 - val_loss: 1340.8540\n",
      "Epoch 108/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1195.5397 - val_loss: 1338.4233\n",
      "Epoch 109/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1200.2361 - val_loss: 1340.5812\n",
      "Epoch 110/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1191.8528 - val_loss: 1346.3944\n",
      "Epoch 111/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1198.8846 - val_loss: 1339.7714\n",
      "Epoch 112/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1192.9827 - val_loss: 1385.2289\n",
      "Epoch 113/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1183.2952 - val_loss: 1330.6920\n",
      "Epoch 114/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1182.2141 - val_loss: 1358.5421\n",
      "Epoch 115/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1181.1550 - val_loss: 1339.0522\n",
      "Epoch 116/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1183.8628 - val_loss: 1356.9709\n",
      "Epoch 117/1000\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 1181.0669 - val_loss: 1324.9307\n",
      "Epoch 118/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1186.5646 - val_loss: 1326.9563\n",
      "Epoch 119/1000\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 1176.5597 - val_loss: 1323.9547\n",
      "Epoch 120/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1166.0427 - val_loss: 1321.9553\n",
      "Epoch 121/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1173.4930 - val_loss: 1329.7263\n",
      "Epoch 122/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1166.6946 - val_loss: 1319.9604\n",
      "Epoch 123/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1174.4327 - val_loss: 1362.4410\n",
      "Epoch 124/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1174.9071 - val_loss: 1332.8942\n",
      "Epoch 125/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1175.1951 - val_loss: 1324.3407\n",
      "Epoch 126/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1168.5229 - val_loss: 1313.8110\n",
      "Epoch 127/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1164.7970 - val_loss: 1340.7799\n",
      "Epoch 128/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1164.5007 - val_loss: 1326.3613\n",
      "Epoch 129/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1162.3533 - val_loss: 1320.1744\n",
      "Epoch 130/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1163.1686 - val_loss: 1318.8190\n",
      "Epoch 131/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1165.1567 - val_loss: 1329.9127\n",
      "Epoch 132/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1156.2247 - val_loss: 1339.7723\n",
      "Epoch 133/1000\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 1166.8822 - val_loss: 1302.1556\n",
      "Epoch 134/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1164.0632 - val_loss: 1306.1968\n",
      "Epoch 135/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1153.3218 - val_loss: 1325.1178\n",
      "Epoch 136/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1156.0006 - val_loss: 1309.6901\n",
      "Epoch 137/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1146.5518 - val_loss: 1326.8911\n",
      "Epoch 138/1000\n",
      "268/268 [==============================] - 6s 24ms/step - loss: 1152.9980 - val_loss: 1299.7064\n",
      "Epoch 139/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1153.5862 - val_loss: 1313.4414\n",
      "Epoch 140/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1148.1307 - val_loss: 1316.3693\n",
      "Epoch 141/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1148.4388 - val_loss: 1306.0339\n",
      "Epoch 142/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1142.3607 - val_loss: 1296.6199\n",
      "Epoch 143/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1145.2056 - val_loss: 1309.2549\n",
      "Epoch 144/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1144.1848 - val_loss: 1314.4069\n",
      "Epoch 145/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1137.7563 - val_loss: 1326.7675\n",
      "Epoch 146/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1138.2505 - val_loss: 1307.9720\n",
      "Epoch 147/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1142.7766 - val_loss: 1335.0649\n",
      "Epoch 148/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1140.7002 - val_loss: 1314.1270\n",
      "Epoch 149/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1142.3363 - val_loss: 1299.4374\n",
      "Epoch 150/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1140.0575 - val_loss: 1306.6736\n",
      "Epoch 151/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1139.0514 - val_loss: 1314.5895\n",
      "Epoch 152/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1135.6921 - val_loss: 1324.2318\n",
      "Epoch 153/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1148.2496 - val_loss: 1308.5864\n",
      "Epoch 154/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1130.0380 - val_loss: 1318.2441\n",
      "Epoch 155/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1135.3141 - val_loss: 1326.2230\n",
      "Epoch 156/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1129.8145 - val_loss: 1295.9761\n",
      "Epoch 157/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1135.2250 - val_loss: 1310.5417\n",
      "Epoch 158/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1131.2811 - val_loss: 1342.2705\n",
      "Epoch 159/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1132.3799 - val_loss: 1315.9705\n",
      "Epoch 160/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1130.7352 - val_loss: 1330.4131\n",
      "Epoch 161/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1129.0811 - val_loss: 1352.3188\n",
      "Epoch 162/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1131.4440 - val_loss: 1308.4199\n",
      "Epoch 163/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1117.3519 - val_loss: 1316.3422\n",
      "Epoch 164/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1126.8496 - val_loss: 1395.6427\n",
      "Epoch 165/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1124.3584 - val_loss: 1311.0015\n",
      "Epoch 166/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1117.7177 - val_loss: 1288.2295\n",
      "Epoch 167/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1121.3293 - val_loss: 1305.1002\n",
      "Epoch 168/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1118.9657 - val_loss: 1295.4143\n",
      "Epoch 169/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1121.6284 - val_loss: 1305.7262\n",
      "Epoch 170/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1110.8383 - val_loss: 1318.5745\n",
      "Epoch 171/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1117.8251 - val_loss: 1298.0903\n",
      "Epoch 172/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1119.2211 - val_loss: 1327.4763\n",
      "Epoch 173/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1120.1642 - val_loss: 1306.0294\n",
      "Epoch 174/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1113.6337 - val_loss: 1329.0336\n",
      "Epoch 175/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1111.7114 - val_loss: 1300.2284\n",
      "Epoch 176/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1108.3889 - val_loss: 1282.1864\n",
      "Epoch 177/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1106.7860 - val_loss: 1360.3320\n",
      "Epoch 178/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1109.8053 - val_loss: 1293.3843\n",
      "Epoch 179/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1104.7573 - val_loss: 1301.1377\n",
      "Epoch 180/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1107.1786 - val_loss: 1295.4076\n",
      "Epoch 181/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1102.8801 - val_loss: 1282.1755\n",
      "Epoch 182/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1107.7117 - val_loss: 1295.9811\n",
      "Epoch 183/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1105.6523 - val_loss: 1299.8387\n",
      "Epoch 184/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1104.1523 - val_loss: 1309.8674\n",
      "Epoch 185/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1107.7611 - val_loss: 1295.1987\n",
      "Epoch 186/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1102.4891 - val_loss: 1289.5162\n",
      "Epoch 187/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1105.2948 - val_loss: 1281.3958\n",
      "Epoch 188/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1101.6608 - val_loss: 1309.5746\n",
      "Epoch 189/1000\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1106.3892 - val_loss: 1280.1290\n",
      "Epoch 190/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1106.1962 - val_loss: 1307.1520\n",
      "Epoch 191/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1105.4103 - val_loss: 1287.2021\n",
      "Epoch 192/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1096.1990 - val_loss: 1299.7615\n",
      "Epoch 193/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1096.0294 - val_loss: 1287.6230\n",
      "Epoch 194/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1106.6116 - val_loss: 1288.8315\n",
      "Epoch 195/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1093.8198 - val_loss: 1332.2500\n",
      "Epoch 196/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1109.2532 - val_loss: 1328.8440\n",
      "Epoch 197/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1089.8405 - val_loss: 1286.0363\n",
      "Epoch 198/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1088.9849 - val_loss: 1275.1552\n",
      "Epoch 199/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1090.3699 - val_loss: 1302.5938\n",
      "Epoch 200/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1094.4453 - val_loss: 1296.0889\n",
      "Epoch 201/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1097.4066 - val_loss: 1336.6986\n",
      "Epoch 202/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1089.8425 - val_loss: 1292.0212\n",
      "Epoch 203/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1090.6741 - val_loss: 1294.7932\n",
      "Epoch 204/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1087.6490 - val_loss: 1275.9253\n",
      "Epoch 205/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1091.3284 - val_loss: 1276.1183\n",
      "Epoch 206/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1085.0074 - val_loss: 1301.1414\n",
      "Epoch 207/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1083.3228 - val_loss: 1289.3629\n",
      "Epoch 208/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1086.0642 - val_loss: 1279.0935\n",
      "Epoch 209/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1087.2897 - val_loss: 1308.8665\n",
      "Epoch 210/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1081.8594 - val_loss: 1317.7849\n",
      "Epoch 211/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1085.2065 - val_loss: 1279.2048\n",
      "Epoch 212/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1078.1953 - val_loss: 1296.1552\n",
      "Epoch 213/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1076.5724 - val_loss: 1346.2445\n",
      "Epoch 214/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1081.1819 - val_loss: 1280.8253\n",
      "Epoch 215/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1081.4160 - val_loss: 1286.2205\n",
      "Epoch 216/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1089.2502 - val_loss: 1309.0145\n",
      "Epoch 217/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1082.9702 - val_loss: 1275.6957\n",
      "Epoch 218/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1077.2709 - val_loss: 1289.5360\n",
      "Epoch 219/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1076.0499 - val_loss: 1278.2655\n",
      "Epoch 220/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 3ms/step - loss: 1091.2363 - val_loss: 1294.3662\n",
      "Epoch 221/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1076.2277 - val_loss: 1297.6975\n",
      "Epoch 222/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1081.5504 - val_loss: 1278.4834\n",
      "Epoch 223/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1068.1860 - val_loss: 1304.2253\n",
      "Epoch 224/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1068.5140 - val_loss: 1282.6858\n",
      "Epoch 225/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1069.5490 - val_loss: 1281.0840\n",
      "Epoch 226/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1070.4482 - val_loss: 1297.3822\n",
      "Epoch 227/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1070.9705 - val_loss: 1337.1893\n",
      "Epoch 228/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1077.7626 - val_loss: 1300.0494\n",
      "Epoch 229/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1073.8165 - val_loss: 1299.4907\n",
      "Epoch 230/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1071.1906 - val_loss: 1270.3446\n",
      "Epoch 231/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1072.3145 - val_loss: 1304.2780\n",
      "Epoch 232/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1078.7773 - val_loss: 1277.2555\n",
      "Epoch 233/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1071.8009 - val_loss: 1302.1366\n",
      "Epoch 234/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1073.0358 - val_loss: 1273.2787\n",
      "Epoch 235/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1068.1418 - val_loss: 1302.0092\n",
      "Epoch 236/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1076.2014 - val_loss: 1273.5649\n",
      "Epoch 237/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1064.2933 - val_loss: 1337.3700\n",
      "Epoch 238/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1074.0068 - val_loss: 1286.0261\n",
      "Epoch 239/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1067.9790 - val_loss: 1289.3593\n",
      "Epoch 240/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1065.3420 - val_loss: 1275.6860\n",
      "Epoch 241/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1060.4028 - val_loss: 1316.8448\n",
      "Epoch 242/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1062.0398 - val_loss: 1284.4397\n",
      "Epoch 243/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1066.2201 - val_loss: 1308.3605\n",
      "Epoch 244/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1072.6775 - val_loss: 1296.1560\n",
      "Epoch 245/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1068.9453 - val_loss: 1295.2607\n",
      "Epoch 246/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1061.0919 - val_loss: 1281.8271\n",
      "Epoch 247/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1063.4376 - val_loss: 1289.8870\n",
      "Epoch 248/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1068.2698 - val_loss: 1274.3911\n",
      "Epoch 249/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1055.2649 - val_loss: 1290.2423\n",
      "Epoch 250/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1063.9751 - val_loss: 1293.4847\n",
      "Epoch 251/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1068.4523 - val_loss: 1288.9319\n",
      "Epoch 252/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1062.9895 - val_loss: 1264.1111\n",
      "Epoch 253/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1059.3994 - val_loss: 1275.3789\n",
      "Epoch 254/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1063.8734 - val_loss: 1290.9143\n",
      "Epoch 255/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1053.3956 - val_loss: 1283.3063\n",
      "Epoch 256/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1057.0852 - val_loss: 1324.7374\n",
      "Epoch 257/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1053.7885 - val_loss: 1281.3208\n",
      "Epoch 258/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1060.0277 - val_loss: 1274.2391\n",
      "Epoch 259/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1052.8154 - val_loss: 1271.8325\n",
      "Epoch 260/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1059.2014 - val_loss: 1278.7241\n",
      "Epoch 261/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1047.5776 - val_loss: 1294.5919\n",
      "Epoch 262/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1050.9513 - val_loss: 1283.0295\n",
      "Epoch 263/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1052.6942 - val_loss: 1354.0876\n",
      "Epoch 264/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1059.1608 - val_loss: 1296.5907\n",
      "Epoch 265/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1051.3030 - val_loss: 1296.0989\n",
      "Epoch 266/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1050.9597 - val_loss: 1261.5745\n",
      "Epoch 267/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1054.6711 - val_loss: 1289.1635\n",
      "Epoch 268/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1039.7948 - val_loss: 1275.3634\n",
      "Epoch 269/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1055.7982 - val_loss: 1281.5320\n",
      "Epoch 270/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1060.4514 - val_loss: 1300.1967\n",
      "Epoch 271/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1042.5933 - val_loss: 1313.8099\n",
      "Epoch 272/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1045.2142 - val_loss: 1311.0698\n",
      "Epoch 273/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1045.0504 - val_loss: 1289.6412\n",
      "Epoch 274/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1039.3435 - val_loss: 1264.6385\n",
      "Epoch 275/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1047.0837 - val_loss: 1282.3798\n",
      "Epoch 276/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1055.9326 - val_loss: 1296.4735\n",
      "Epoch 277/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1041.9126 - val_loss: 1284.1409\n",
      "Epoch 278/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1040.6997 - val_loss: 1278.5796\n",
      "Epoch 279/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1047.6017 - val_loss: 1276.6775\n",
      "Epoch 280/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1037.5872 - val_loss: 1268.7448\n",
      "Epoch 281/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1045.2910 - val_loss: 1275.6982\n",
      "Epoch 282/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1043.7125 - val_loss: 1291.6475\n",
      "Epoch 283/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1051.3357 - val_loss: 1289.2819\n",
      "Epoch 284/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1046.9229 - val_loss: 1279.5464\n",
      "Epoch 285/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1036.8291 - val_loss: 1270.8953\n",
      "Epoch 286/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1040.6196 - val_loss: 1276.3441\n",
      "Epoch 287/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1036.6578 - val_loss: 1292.9070\n",
      "Epoch 288/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1035.9634 - val_loss: 1264.3700\n",
      "Epoch 289/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1033.5874 - val_loss: 1281.5280\n",
      "Epoch 290/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1039.4740 - val_loss: 1297.5010\n",
      "Epoch 291/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1031.4757 - val_loss: 1286.3528\n",
      "Epoch 292/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1033.7074 - val_loss: 1276.7832\n",
      "Epoch 293/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1030.7480 - val_loss: 1271.5951\n",
      "Epoch 294/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1042.0487 - val_loss: 1292.5520\n",
      "Epoch 295/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1031.1670 - val_loss: 1262.8706\n",
      "Epoch 296/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1029.5665 - val_loss: 1281.4844\n",
      "Epoch 297/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1050.3069 - val_loss: 1271.7747\n",
      "Epoch 298/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1028.9915 - val_loss: 1270.5334\n",
      "Epoch 299/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1027.4315 - val_loss: 1271.6193\n",
      "Epoch 300/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1030.7604 - val_loss: 1280.1082\n",
      "Epoch 301/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1030.6074 - val_loss: 1286.1327\n",
      "Epoch 302/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1037.3496 - val_loss: 1265.8518\n",
      "Epoch 303/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1029.8386 - val_loss: 1324.7906\n",
      "Epoch 304/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1027.1230 - val_loss: 1279.3279\n",
      "Epoch 305/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1025.4731 - val_loss: 1310.4382\n",
      "Epoch 306/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1043.6293 - val_loss: 1287.7502\n",
      "Epoch 307/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1027.4800 - val_loss: 1306.9623\n",
      "Epoch 308/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1021.0477 - val_loss: 1272.5795\n",
      "Epoch 309/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1023.7773 - val_loss: 1286.9989\n",
      "Epoch 310/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1022.5335 - val_loss: 1272.1772\n",
      "Epoch 311/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1021.0757 - val_loss: 1283.2113\n",
      "Epoch 312/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1023.5387 - val_loss: 1285.7660\n",
      "Epoch 313/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1029.1136 - val_loss: 1280.1615\n",
      "Epoch 314/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1019.2404 - val_loss: 1288.1904\n",
      "Epoch 315/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1022.7737 - val_loss: 1257.9857\n",
      "Epoch 316/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1015.7606 - val_loss: 1340.4452\n",
      "Epoch 317/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1033.1398 - val_loss: 1270.7789\n",
      "Epoch 318/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1026.1320 - val_loss: 1318.6306\n",
      "Epoch 319/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1020.4613 - val_loss: 1262.7850\n",
      "Epoch 320/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1026.5073 - val_loss: 1271.7244\n",
      "Epoch 321/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1015.0662 - val_loss: 1254.4384\n",
      "Epoch 322/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1015.6183 - val_loss: 1295.5929\n",
      "Epoch 323/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1025.2726 - val_loss: 1268.4647\n",
      "Epoch 324/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1022.4469 - val_loss: 1270.1672\n",
      "Epoch 325/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1016.9177 - val_loss: 1285.4139\n",
      "Epoch 326/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1027.5775 - val_loss: 1291.1799\n",
      "Epoch 327/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1016.5826 - val_loss: 1266.5504\n",
      "Epoch 328/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1016.2712 - val_loss: 1322.8116\n",
      "Epoch 329/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1026.0165 - val_loss: 1262.6289\n",
      "Epoch 330/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1029.4844 - val_loss: 1266.0215\n",
      "Epoch 331/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1010.7898 - val_loss: 1261.3214\n",
      "Epoch 332/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1019.3902 - val_loss: 1262.9561\n",
      "Epoch 333/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1003.1477 - val_loss: 1269.9199\n",
      "Epoch 334/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1005.9107 - val_loss: 1305.6085\n",
      "Epoch 335/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1012.2839 - val_loss: 1270.6423\n",
      "Epoch 336/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1007.3721 - val_loss: 1259.3030\n",
      "Epoch 337/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1000.8152 - val_loss: 1269.3473\n",
      "Epoch 338/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1012.8931 - val_loss: 1282.9324\n",
      "Epoch 339/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1000.6307 - val_loss: 1259.5610\n",
      "Epoch 340/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1000.5404 - val_loss: 1293.9521\n",
      "Epoch 341/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1006.9600 - val_loss: 1263.1053\n",
      "Epoch 342/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 999.8896 - val_loss: 1266.6675\n",
      "Epoch 343/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1006.2137 - val_loss: 1251.0029\n",
      "Epoch 344/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1007.8300 - val_loss: 1287.2609\n",
      "Epoch 345/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1006.7816 - val_loss: 1252.5155\n",
      "Epoch 346/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1002.2903 - val_loss: 1263.5946\n",
      "Epoch 347/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1005.4991 - val_loss: 1266.6354\n",
      "Epoch 348/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 993.7408 - val_loss: 1270.9709\n",
      "Epoch 349/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1003.8716 - val_loss: 1295.8163\n",
      "Epoch 350/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1004.3039 - val_loss: 1262.9335\n",
      "Epoch 351/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1008.6403 - val_loss: 1265.2015\n",
      "Epoch 352/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1012.8179 - val_loss: 1262.7729\n",
      "Epoch 353/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 994.2125 - val_loss: 1275.1587\n",
      "Epoch 354/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 999.8760 - val_loss: 1260.5265\n",
      "Epoch 355/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 992.1077 - val_loss: 1265.1609\n",
      "Epoch 356/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 995.5642 - val_loss: 1285.5956\n",
      "Epoch 357/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1001.1046 - val_loss: 1244.3495\n",
      "Epoch 358/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 998.6849 - val_loss: 1279.7063\n",
      "Epoch 359/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 997.5930 - val_loss: 1263.9194\n",
      "Epoch 360/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1004.9889 - val_loss: 1260.3101\n",
      "Epoch 361/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 986.5418 - val_loss: 1260.4374\n",
      "Epoch 362/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 992.2841 - val_loss: 1269.5035\n",
      "Epoch 363/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 996.5202 - val_loss: 1314.6603\n",
      "Epoch 364/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 996.1644 - val_loss: 1268.1318\n",
      "Epoch 365/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1000.0598 - val_loss: 1308.5409\n",
      "Epoch 366/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 994.8568 - val_loss: 1262.9757\n",
      "Epoch 367/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 980.3275 - val_loss: 1255.0487\n",
      "Epoch 368/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 3ms/step - loss: 1009.0485 - val_loss: 1268.5002\n",
      "Epoch 369/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 989.3969 - val_loss: 1276.8958\n",
      "Epoch 370/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 987.8340 - val_loss: 1265.1122\n",
      "Epoch 371/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 988.7106 - val_loss: 1292.3815\n",
      "Epoch 372/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 997.6790 - val_loss: 1242.3104\n",
      "Epoch 373/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 985.7992 - val_loss: 1261.3607\n",
      "Epoch 374/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 982.9454 - val_loss: 1246.5267\n",
      "Epoch 375/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 995.1804 - val_loss: 1243.7720\n",
      "Epoch 376/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 991.0505 - val_loss: 1242.7544\n",
      "Epoch 377/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 992.4832 - val_loss: 1267.5459\n",
      "Epoch 378/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 986.3948 - val_loss: 1235.9901\n",
      "Epoch 379/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 979.8616 - val_loss: 1242.0570\n",
      "Epoch 380/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 985.9270 - val_loss: 1261.9675\n",
      "Epoch 381/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 985.3221 - val_loss: 1251.1884\n",
      "Epoch 382/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 987.6219 - val_loss: 1294.0525\n",
      "Epoch 383/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 981.0311 - val_loss: 1254.0662\n",
      "Epoch 384/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 973.0240 - val_loss: 1240.1561\n",
      "Epoch 385/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 971.6034 - val_loss: 1252.4091\n",
      "Epoch 386/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 984.4867 - val_loss: 1254.0028\n",
      "Epoch 387/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 978.9868 - val_loss: 1246.2252\n",
      "Epoch 388/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 974.1852 - val_loss: 1278.7330\n",
      "Epoch 389/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 970.9446 - val_loss: 1257.0338\n",
      "Epoch 390/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 983.6652 - val_loss: 1254.0739\n",
      "Epoch 391/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 973.8822 - val_loss: 1289.1475\n",
      "Epoch 392/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 980.1438 - val_loss: 1239.1151\n",
      "Epoch 393/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 969.3403 - val_loss: 1250.5183\n",
      "Epoch 394/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 969.1013 - val_loss: 1250.8004\n",
      "Epoch 395/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 969.2877 - val_loss: 1248.4355\n",
      "Epoch 396/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 975.7905 - val_loss: 1241.5782\n",
      "Epoch 397/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 970.2025 - val_loss: 1266.8889\n",
      "Epoch 398/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 963.7888 - val_loss: 1306.6213\n",
      "Epoch 399/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 975.4319 - val_loss: 1266.2076\n",
      "Epoch 400/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 972.0775 - val_loss: 1249.3160\n",
      "Epoch 401/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 962.4432 - val_loss: 1239.1697\n",
      "Epoch 402/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 964.9481 - val_loss: 1278.4692\n",
      "Epoch 403/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 967.0694 - val_loss: 1251.6559\n",
      "Epoch 404/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 975.7294 - val_loss: 1265.0159\n",
      "Epoch 405/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 969.6324 - val_loss: 1244.7710\n",
      "Epoch 406/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 970.0095 - val_loss: 1255.2993\n",
      "Epoch 407/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 966.8576 - val_loss: 1242.9583\n",
      "Epoch 408/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 979.8353 - val_loss: 1273.8914\n",
      "Epoch 409/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 969.4469 - val_loss: 1253.9020\n",
      "Epoch 410/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 974.9902 - val_loss: 1250.2532\n",
      "Epoch 411/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 962.4205 - val_loss: 1257.1187\n",
      "Epoch 412/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 960.7981 - val_loss: 1258.4912\n",
      "Epoch 413/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 963.8337 - val_loss: 1264.0729\n",
      "Epoch 414/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 967.8367 - val_loss: 1244.3328\n",
      "Epoch 415/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 966.3450 - val_loss: 1255.2242\n",
      "Epoch 416/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 967.0701 - val_loss: 1251.8816\n",
      "Epoch 417/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 963.8843 - val_loss: 1340.3829\n",
      "Epoch 418/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 961.7913 - val_loss: 1240.1504\n",
      "Epoch 419/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 954.9728 - val_loss: 1251.2006\n",
      "Epoch 420/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 973.3836 - val_loss: 1257.2806\n",
      "Epoch 421/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 965.3762 - val_loss: 1251.5082\n",
      "Epoch 422/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 958.5632 - val_loss: 1262.7781\n",
      "Epoch 423/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 954.9229 - val_loss: 1283.1324\n",
      "Epoch 424/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 959.0766 - val_loss: 1227.9106\n",
      "Epoch 425/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 948.5416 - val_loss: 1257.5573\n",
      "Epoch 426/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 970.0120 - val_loss: 1248.3297\n",
      "Epoch 427/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 950.8425 - val_loss: 1266.8124\n",
      "Epoch 428/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 956.8726 - val_loss: 1241.4098\n",
      "Epoch 429/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 955.9178 - val_loss: 1272.8973\n",
      "Epoch 430/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 959.6700 - val_loss: 1254.5696\n",
      "Epoch 431/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 958.1202 - val_loss: 1269.5436\n",
      "Epoch 432/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 967.0764 - val_loss: 1273.5726\n",
      "Epoch 433/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 958.3577 - val_loss: 1246.2223\n",
      "Epoch 434/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 951.6978 - val_loss: 1233.5363\n",
      "Epoch 435/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 947.6063 - val_loss: 1269.4962\n",
      "Epoch 436/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 941.4878 - val_loss: 1240.3500\n",
      "Epoch 437/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 951.2159 - val_loss: 1323.9124\n",
      "Epoch 438/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 960.3016 - val_loss: 1256.1306\n",
      "Epoch 439/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 958.7131 - val_loss: 1235.3467\n",
      "Epoch 440/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 938.6811 - val_loss: 1240.8871\n",
      "Epoch 441/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 948.5229 - val_loss: 1265.2507\n",
      "Epoch 442/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 962.6663 - val_loss: 1265.7202\n",
      "Epoch 443/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 943.4340 - val_loss: 1235.1565\n",
      "Epoch 444/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 942.2998 - val_loss: 1238.6816\n",
      "Epoch 445/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 938.6921 - val_loss: 1251.0397\n",
      "Epoch 446/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 950.6259 - val_loss: 1261.2894\n",
      "Epoch 447/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 953.6430 - val_loss: 1244.9111\n",
      "Epoch 448/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 952.9118 - val_loss: 1278.8162\n",
      "Epoch 449/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 943.3975 - val_loss: 1242.8431\n",
      "Epoch 450/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 945.4423 - val_loss: 1237.9116\n",
      "Epoch 451/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 943.1563 - val_loss: 1241.8357\n",
      "Epoch 452/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 931.8661 - val_loss: 1238.8436\n",
      "Epoch 453/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 933.9537 - val_loss: 1258.7656\n",
      "Epoch 454/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 944.5184 - val_loss: 1253.1785\n",
      "Epoch 455/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 947.2645 - val_loss: 1260.6450\n",
      "Epoch 456/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 937.6848 - val_loss: 1242.9233\n",
      "Epoch 457/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 952.9384 - val_loss: 1249.0659\n",
      "Epoch 458/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 934.2431 - val_loss: 1273.1666\n",
      "Epoch 459/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 939.1951 - val_loss: 1238.7953\n",
      "Epoch 460/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 946.8223 - val_loss: 1243.0203\n",
      "Epoch 461/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 934.1430 - val_loss: 1236.6549\n",
      "Epoch 462/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 935.8850 - val_loss: 1240.0913\n",
      "Epoch 463/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 945.4965 - val_loss: 1227.9340\n",
      "Epoch 464/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 935.7178 - val_loss: 1279.8784\n",
      "Epoch 465/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 935.5844 - val_loss: 1238.3597\n",
      "Epoch 466/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 939.3621 - val_loss: 1267.6254\n",
      "Epoch 467/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 933.1915 - val_loss: 1241.5919\n",
      "Epoch 468/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 930.3289 - val_loss: 1230.7126\n",
      "Epoch 469/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 942.9123 - val_loss: 1256.4799\n",
      "Epoch 470/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 935.9457 - val_loss: 1265.0161\n",
      "Epoch 471/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 932.9140 - val_loss: 1248.4319\n",
      "Epoch 472/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 940.9291 - val_loss: 1372.6788\n",
      "Epoch 473/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 937.8365 - val_loss: 1270.6215\n",
      "Epoch 474/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 925.4030 - val_loss: 1244.9540\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model3.h5\", save_best_only=True)\n",
    "\n",
    "model_3 = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=x_train_scaled.shape[1:]),\n",
    "    keras.layers.Dense(120, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(120, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(120, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_3.compile(loss=\"mae\",\n",
    "               optimizer=\"adam\")\n",
    "\n",
    "history3 = model_3.fit(x_train_scaled, y_train,\n",
    "                      epochs=1000,\n",
    "                      validation_data=(x_test_scaled,y_test),\n",
    "                      callbacks=[early_stopping_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8576572118595593\n",
      "0.8158083936492445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_test_predict = model_3.predict(x_test_scaled)\n",
    "y_train_predict = model_3.predict(x_train_scaled)\n",
    "print(r2_score(y_train, y_train_predict))\n",
    "print(r2_score(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_curves(history3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 4785.9429 - val_loss: 2048.1196\n",
      "Epoch 2/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1905.5286 - val_loss: 1902.3654\n",
      "Epoch 3/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1813.9731 - val_loss: 1843.2336\n",
      "Epoch 4/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1762.1338 - val_loss: 1809.4662\n",
      "Epoch 5/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1727.0056 - val_loss: 1780.0306\n",
      "Epoch 6/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1696.2252 - val_loss: 1757.2061\n",
      "Epoch 7/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1673.9757 - val_loss: 1736.0780\n",
      "Epoch 8/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1649.9581 - val_loss: 1745.2913\n",
      "Epoch 9/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1638.0621 - val_loss: 1700.1022\n",
      "Epoch 10/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1619.3824 - val_loss: 1698.5510\n",
      "Epoch 11/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1606.3524 - val_loss: 1680.5237\n",
      "Epoch 12/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1596.8605 - val_loss: 1665.0490\n",
      "Epoch 13/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1585.8693 - val_loss: 1733.0790\n",
      "Epoch 14/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1574.4348 - val_loss: 1650.6924\n",
      "Epoch 15/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1564.2135 - val_loss: 1679.7599\n",
      "Epoch 16/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1557.6234 - val_loss: 1656.5353\n",
      "Epoch 17/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1547.1074 - val_loss: 1620.7626\n",
      "Epoch 18/1000\n",
      "268/268 [==============================] - 3s 12ms/step - loss: 1538.0616 - val_loss: 1615.6367\n",
      "Epoch 19/1000\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1530.0314 - val_loss: 1608.4392\n",
      "Epoch 20/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1520.1930 - val_loss: 1606.4390\n",
      "Epoch 21/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1515.7635 - val_loss: 1606.0446\n",
      "Epoch 22/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1504.0964 - val_loss: 1598.6182\n",
      "Epoch 23/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1498.1926 - val_loss: 1586.0994\n",
      "Epoch 24/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1485.5502 - val_loss: 1598.9249\n",
      "Epoch 25/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1480.6781 - val_loss: 1559.8093\n",
      "Epoch 26/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1474.1884 - val_loss: 1580.1049\n",
      "Epoch 27/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1465.2112 - val_loss: 1555.8469\n",
      "Epoch 28/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1459.1471 - val_loss: 1558.3148\n",
      "Epoch 29/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1446.9006 - val_loss: 1538.8271\n",
      "Epoch 30/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1439.1075 - val_loss: 1537.4279\n",
      "Epoch 31/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1434.6597 - val_loss: 1571.9557\n",
      "Epoch 32/1000\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 1428.3442 - val_loss: 1536.6542\n",
      "Epoch 33/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1422.7214 - val_loss: 1532.9790\n",
      "Epoch 34/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1420.9442 - val_loss: 1517.2933\n",
      "Epoch 35/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1414.6342 - val_loss: 1505.4351\n",
      "Epoch 36/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1403.6221 - val_loss: 1500.1040\n",
      "Epoch 37/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1405.1936 - val_loss: 1529.8917\n",
      "Epoch 38/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1391.7783 - val_loss: 1521.7438\n",
      "Epoch 39/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1388.8046 - val_loss: 1489.1594\n",
      "Epoch 40/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1383.2710 - val_loss: 1475.7968\n",
      "Epoch 41/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1380.1088 - val_loss: 1486.2639\n",
      "Epoch 42/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1371.4196 - val_loss: 1467.9182\n",
      "Epoch 43/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1373.7415 - val_loss: 1484.6593\n",
      "Epoch 44/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1365.5009 - val_loss: 1477.6100\n",
      "Epoch 45/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1359.2313 - val_loss: 1490.3971\n",
      "Epoch 46/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1357.6760 - val_loss: 1459.9199\n",
      "Epoch 47/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1354.7925 - val_loss: 1493.3539\n",
      "Epoch 48/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1345.7689 - val_loss: 1443.9299\n",
      "Epoch 49/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1341.5652 - val_loss: 1451.2661\n",
      "Epoch 50/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1335.3269 - val_loss: 1455.5953\n",
      "Epoch 51/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1334.3151 - val_loss: 1446.3856\n",
      "Epoch 52/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1331.6819 - val_loss: 1449.0641\n",
      "Epoch 53/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1324.0127 - val_loss: 1432.5062\n",
      "Epoch 54/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1320.2422 - val_loss: 1442.3729\n",
      "Epoch 55/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1316.5452 - val_loss: 1423.2345\n",
      "Epoch 56/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1309.8940 - val_loss: 1442.2588\n",
      "Epoch 57/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1309.5303 - val_loss: 1415.7429\n",
      "Epoch 58/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1301.3615 - val_loss: 1414.5945\n",
      "Epoch 59/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1298.7463 - val_loss: 1428.7711\n",
      "Epoch 60/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1297.2013 - val_loss: 1405.6024\n",
      "Epoch 61/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1291.6248 - val_loss: 1405.1572\n",
      "Epoch 62/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1286.3608 - val_loss: 1401.5665\n",
      "Epoch 63/1000\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 1277.5280 - val_loss: 1396.5513\n",
      "Epoch 64/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1277.9041 - val_loss: 1411.3490\n",
      "Epoch 65/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1274.3275 - val_loss: 1416.6304\n",
      "Epoch 66/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1278.8248 - val_loss: 1394.1594\n",
      "Epoch 67/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1272.3451 - val_loss: 1396.5662\n",
      "Epoch 68/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1266.0404 - val_loss: 1391.3510\n",
      "Epoch 69/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1262.8929 - val_loss: 1389.8883\n",
      "Epoch 70/1000\n",
      "268/268 [==============================] - ETA: 0s - loss: 1263.59 - 1s 3ms/step - loss: 1261.6973 - val_loss: 1403.7013\n",
      "Epoch 71/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1251.8230 - val_loss: 1388.7264\n",
      "Epoch 72/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1252.9729 - val_loss: 1395.8051\n",
      "Epoch 73/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1250.0695 - val_loss: 1406.6433\n",
      "Epoch 74/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1245.5737 - val_loss: 1386.4596\n",
      "Epoch 75/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1252.9967 - val_loss: 1379.8870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1240.0406 - val_loss: 1380.7377\n",
      "Epoch 77/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1236.7194 - val_loss: 1369.5708\n",
      "Epoch 78/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1239.4320 - val_loss: 1379.3536\n",
      "Epoch 79/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1235.0906 - val_loss: 1400.6027\n",
      "Epoch 80/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1222.5919 - val_loss: 1360.0574\n",
      "Epoch 81/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1224.0166 - val_loss: 1391.5308\n",
      "Epoch 82/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1222.7380 - val_loss: 1351.4019\n",
      "Epoch 83/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1222.9904 - val_loss: 1371.6089\n",
      "Epoch 84/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1217.4625 - val_loss: 1356.0240\n",
      "Epoch 85/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1217.6039 - val_loss: 1366.5793\n",
      "Epoch 86/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1212.1396 - val_loss: 1373.1609\n",
      "Epoch 87/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1206.6931 - val_loss: 1355.7708\n",
      "Epoch 88/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1211.2307 - val_loss: 1356.8135\n",
      "Epoch 89/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1214.8339 - val_loss: 1364.6688\n",
      "Epoch 90/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1204.3785 - val_loss: 1357.0015\n",
      "Epoch 91/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1208.3079 - val_loss: 1343.2355\n",
      "Epoch 92/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1194.6350 - val_loss: 1355.5045\n",
      "Epoch 93/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1202.3739 - val_loss: 1348.2645\n",
      "Epoch 94/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1194.8013 - val_loss: 1378.4615\n",
      "Epoch 95/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1190.7445 - val_loss: 1360.1075\n",
      "Epoch 96/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1186.9727 - val_loss: 1354.2198\n",
      "Epoch 97/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1183.6656 - val_loss: 1372.6140\n",
      "Epoch 98/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1184.2128 - val_loss: 1343.5972\n",
      "Epoch 99/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1184.3517 - val_loss: 1348.0432\n",
      "Epoch 100/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1185.1469 - val_loss: 1349.1047\n",
      "Epoch 101/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1178.4915 - val_loss: 1353.1241\n",
      "Epoch 102/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1182.3674 - val_loss: 1342.9156\n",
      "Epoch 103/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1174.7965 - val_loss: 1320.1001\n",
      "Epoch 104/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1167.0637 - val_loss: 1345.3149\n",
      "Epoch 105/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1171.9469 - val_loss: 1379.8495\n",
      "Epoch 106/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1175.1223 - val_loss: 1337.8138\n",
      "Epoch 107/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1170.5680 - val_loss: 1332.6024\n",
      "Epoch 108/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1166.0049 - val_loss: 1330.1844\n",
      "Epoch 109/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1170.9600 - val_loss: 1353.1105\n",
      "Epoch 110/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1163.9135 - val_loss: 1339.5544\n",
      "Epoch 111/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1164.9780 - val_loss: 1341.7761\n",
      "Epoch 112/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1152.3602 - val_loss: 1321.1686\n",
      "Epoch 113/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1159.6210 - val_loss: 1330.1730\n",
      "Epoch 114/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1160.6973 - val_loss: 1346.3350\n",
      "Epoch 115/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1157.2745 - val_loss: 1352.6210\n",
      "Epoch 116/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1153.2937 - val_loss: 1317.5297\n",
      "Epoch 117/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1149.8601 - val_loss: 1329.5099\n",
      "Epoch 118/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1149.4426 - val_loss: 1322.2299\n",
      "Epoch 119/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1145.3416 - val_loss: 1330.8450\n",
      "Epoch 120/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1150.9463 - val_loss: 1321.8289\n",
      "Epoch 121/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1156.1531 - val_loss: 1379.7412\n",
      "Epoch 122/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1154.8308 - val_loss: 1324.3596\n",
      "Epoch 123/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1141.8998 - val_loss: 1318.8494\n",
      "Epoch 124/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1142.8625 - val_loss: 1334.3934\n",
      "Epoch 125/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1139.9277 - val_loss: 1328.8892\n",
      "Epoch 126/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1138.3011 - val_loss: 1341.5336\n",
      "Epoch 127/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1142.3313 - val_loss: 1337.8722\n",
      "Epoch 128/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1135.1709 - val_loss: 1324.6681\n",
      "Epoch 129/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1139.5203 - val_loss: 1318.1650\n",
      "Epoch 130/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1134.7098 - val_loss: 1320.3535\n",
      "Epoch 131/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1129.3383 - val_loss: 1340.2223\n",
      "Epoch 132/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1127.6509 - val_loss: 1318.6447\n",
      "Epoch 133/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1131.8452 - val_loss: 1322.0342\n",
      "Epoch 134/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1125.0259 - val_loss: 1304.9430\n",
      "Epoch 135/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1136.4492 - val_loss: 1296.0732\n",
      "Epoch 136/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1126.8210 - val_loss: 1311.3662\n",
      "Epoch 137/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1120.4497 - val_loss: 1321.4900\n",
      "Epoch 138/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1126.1359 - val_loss: 1316.1388\n",
      "Epoch 139/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1111.5712 - val_loss: 1312.3048\n",
      "Epoch 140/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1119.0264 - val_loss: 1309.7874\n",
      "Epoch 141/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1125.0107 - val_loss: 1317.2971\n",
      "Epoch 142/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1115.5667 - val_loss: 1327.3075\n",
      "Epoch 143/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1124.2589 - val_loss: 1311.3242\n",
      "Epoch 144/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1115.4860 - val_loss: 1310.1812\n",
      "Epoch 145/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1108.7219 - val_loss: 1322.2904\n",
      "Epoch 146/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1115.8512 - val_loss: 1337.8773\n",
      "Epoch 147/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1122.6860 - val_loss: 1291.6703\n",
      "Epoch 148/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1104.6514 - val_loss: 1305.5826\n",
      "Epoch 149/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1105.2596 - val_loss: 1341.8202\n",
      "Epoch 150/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1121.9316 - val_loss: 1313.4670\n",
      "Epoch 151/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1117.3334 - val_loss: 1309.7166\n",
      "Epoch 152/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1102.3744 - val_loss: 1296.0123\n",
      "Epoch 153/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1106.1052 - val_loss: 1323.4905\n",
      "Epoch 154/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1113.0876 - val_loss: 1307.0724\n",
      "Epoch 155/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1106.7692 - val_loss: 1316.2975\n",
      "Epoch 156/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1103.4318 - val_loss: 1335.4587\n",
      "Epoch 157/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1103.1560 - val_loss: 1318.5503\n",
      "Epoch 158/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1102.2727 - val_loss: 1329.0071\n",
      "Epoch 159/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1107.8308 - val_loss: 1319.4299\n",
      "Epoch 160/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1096.5253 - val_loss: 1339.0386\n",
      "Epoch 161/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1094.8193 - val_loss: 1332.4598\n",
      "Epoch 162/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1101.9957 - val_loss: 1328.7174\n",
      "Epoch 163/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1096.8372 - val_loss: 1323.5609\n",
      "Epoch 164/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1086.6613 - val_loss: 1290.6370\n",
      "Epoch 165/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1094.9607 - val_loss: 1343.6011\n",
      "Epoch 166/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1091.7515 - val_loss: 1340.1049\n",
      "Epoch 167/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1092.9233 - val_loss: 1315.3180\n",
      "Epoch 168/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1080.8580 - val_loss: 1302.8372\n",
      "Epoch 169/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1097.7572 - val_loss: 1320.9243\n",
      "Epoch 170/1000\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 1087.8314 - val_loss: 1290.4141\n",
      "Epoch 171/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1082.6807 - val_loss: 1286.2091\n",
      "Epoch 172/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1082.7239 - val_loss: 1336.6952\n",
      "Epoch 173/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1084.0038 - val_loss: 1287.0345\n",
      "Epoch 174/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1087.6288 - val_loss: 1299.6393\n",
      "Epoch 175/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1083.1741 - val_loss: 1316.8389\n",
      "Epoch 176/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1083.5519 - val_loss: 1314.0214\n",
      "Epoch 177/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1082.9054 - val_loss: 1304.2694\n",
      "Epoch 178/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1086.1116 - val_loss: 1296.9983\n",
      "Epoch 179/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1073.4397 - val_loss: 1308.2925\n",
      "Epoch 180/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1076.2666 - val_loss: 1292.7758\n",
      "Epoch 181/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1071.1697 - val_loss: 1288.7509\n",
      "Epoch 182/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1075.9524 - val_loss: 1286.0927\n",
      "Epoch 183/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1063.5104 - val_loss: 1296.9794\n",
      "Epoch 184/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1070.1147 - val_loss: 1303.5836\n",
      "Epoch 185/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1069.1128 - val_loss: 1302.5649\n",
      "Epoch 186/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1074.6793 - val_loss: 1286.1908\n",
      "Epoch 187/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1062.9901 - val_loss: 1281.9136\n",
      "Epoch 188/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1070.2640 - val_loss: 1278.8685\n",
      "Epoch 189/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1069.9120 - val_loss: 1297.1699\n",
      "Epoch 190/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1065.7510 - val_loss: 1287.0421\n",
      "Epoch 191/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1069.8046 - val_loss: 1289.4608\n",
      "Epoch 192/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1063.6871 - val_loss: 1307.0345\n",
      "Epoch 193/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1064.1821 - val_loss: 1290.6523\n",
      "Epoch 194/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1058.6257 - val_loss: 1285.2631\n",
      "Epoch 195/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1064.3032 - val_loss: 1292.1227\n",
      "Epoch 196/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1062.5616 - val_loss: 1291.4342\n",
      "Epoch 197/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1056.1714 - val_loss: 1284.6124\n",
      "Epoch 198/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1064.8085 - val_loss: 1268.7083\n",
      "Epoch 199/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1056.5548 - val_loss: 1281.0680\n",
      "Epoch 200/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1052.2310 - val_loss: 1283.8752\n",
      "Epoch 201/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1048.6555 - val_loss: 1274.6481\n",
      "Epoch 202/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1055.8035 - val_loss: 1293.4951\n",
      "Epoch 203/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1051.1321 - val_loss: 1276.4520\n",
      "Epoch 204/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1044.4423 - val_loss: 1280.7108\n",
      "Epoch 205/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1048.8365 - val_loss: 1277.5175\n",
      "Epoch 206/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1052.0369 - val_loss: 1273.6854\n",
      "Epoch 207/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1051.6620 - val_loss: 1278.4060\n",
      "Epoch 208/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1050.4735 - val_loss: 1371.0234\n",
      "Epoch 209/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1059.3014 - val_loss: 1337.5208\n",
      "Epoch 210/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1048.6624 - val_loss: 1265.9546\n",
      "Epoch 211/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1046.8588 - val_loss: 1315.7288\n",
      "Epoch 212/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1046.8026 - val_loss: 1294.3059\n",
      "Epoch 213/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1045.1934 - val_loss: 1316.8236\n",
      "Epoch 214/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1036.7721 - val_loss: 1270.7538\n",
      "Epoch 215/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1042.5179 - val_loss: 1266.1178\n",
      "Epoch 216/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1036.6364 - val_loss: 1288.7087\n",
      "Epoch 217/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1058.3379 - val_loss: 1292.9980\n",
      "Epoch 218/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1055.6082 - val_loss: 1286.7279\n",
      "Epoch 219/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1038.3361 - val_loss: 1268.6108\n",
      "Epoch 220/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1036.9167 - val_loss: 1290.6016\n",
      "Epoch 221/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1033.8196 - val_loss: 1265.6171\n",
      "Epoch 222/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1038.3329 - val_loss: 1263.7477\n",
      "Epoch 223/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1032.5532 - val_loss: 1280.1517\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 3ms/step - loss: 1042.6997 - val_loss: 1273.5476\n",
      "Epoch 225/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1033.3823 - val_loss: 1293.8196\n",
      "Epoch 226/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1034.3579 - val_loss: 1272.0002\n",
      "Epoch 227/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1028.8132 - val_loss: 1284.3907\n",
      "Epoch 228/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1040.5419 - val_loss: 1285.9286\n",
      "Epoch 229/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1033.8348 - val_loss: 1272.5822\n",
      "Epoch 230/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1032.0625 - val_loss: 1273.0153\n",
      "Epoch 231/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1031.6943 - val_loss: 1278.8262\n",
      "Epoch 232/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1032.9340 - val_loss: 1269.0193\n",
      "Epoch 233/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1033.7438 - val_loss: 1268.3535\n",
      "Epoch 234/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1031.3884 - val_loss: 1317.2139\n",
      "Epoch 235/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1033.0736 - val_loss: 1272.3883\n",
      "Epoch 236/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1024.3240 - val_loss: 1288.0148\n",
      "Epoch 237/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1027.8755 - val_loss: 1272.2961\n",
      "Epoch 238/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1028.8544 - val_loss: 1281.3837\n",
      "Epoch 239/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1024.0380 - val_loss: 1282.9923\n",
      "Epoch 240/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1036.5222 - val_loss: 1291.8237\n",
      "Epoch 241/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1022.9001 - val_loss: 1285.7478\n",
      "Epoch 242/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1026.2463 - val_loss: 1272.1151\n",
      "Epoch 243/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1024.2644 - val_loss: 1327.6046\n",
      "Epoch 244/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1021.7650 - val_loss: 1277.6354\n",
      "Epoch 245/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1019.4373 - val_loss: 1262.1699\n",
      "Epoch 246/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1020.2186 - val_loss: 1263.6287\n",
      "Epoch 247/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1018.7559 - val_loss: 1276.4523\n",
      "Epoch 248/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1012.1187 - val_loss: 1333.6254\n",
      "Epoch 249/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1025.6261 - val_loss: 1273.2915\n",
      "Epoch 250/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1010.5266 - val_loss: 1259.8225\n",
      "Epoch 251/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1016.4914 - val_loss: 1310.6166\n",
      "Epoch 252/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1015.9424 - val_loss: 1273.4612\n",
      "Epoch 253/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1008.0570 - val_loss: 1283.3069\n",
      "Epoch 254/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1022.0994 - val_loss: 1336.5073\n",
      "Epoch 255/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1015.4350 - val_loss: 1263.1477\n",
      "Epoch 256/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1015.8866 - val_loss: 1280.5432\n",
      "Epoch 257/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1029.9802 - val_loss: 1267.7432\n",
      "Epoch 258/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1019.1588 - val_loss: 1282.3376\n",
      "Epoch 259/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1008.2725 - val_loss: 1282.4786\n",
      "Epoch 260/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1012.1013 - val_loss: 1296.0483\n",
      "Epoch 261/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1010.4719 - val_loss: 1277.9083\n",
      "Epoch 262/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1009.7999 - val_loss: 1266.8574\n",
      "Epoch 263/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1005.2886 - val_loss: 1277.2161\n",
      "Epoch 264/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1005.9064 - val_loss: 1271.2627\n",
      "Epoch 265/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1007.6998 - val_loss: 1277.9614\n",
      "Epoch 266/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1005.5231 - val_loss: 1270.9299\n",
      "Epoch 267/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1008.9856 - val_loss: 1294.4626\n",
      "Epoch 268/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1009.0088 - val_loss: 1259.3809\n",
      "Epoch 269/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1001.0898 - val_loss: 1340.2612\n",
      "Epoch 270/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1011.8830 - val_loss: 1284.5408\n",
      "Epoch 271/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1010.5890 - val_loss: 1285.8231\n",
      "Epoch 272/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1005.2230 - val_loss: 1289.5419\n",
      "Epoch 273/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1005.8575 - val_loss: 1286.5182\n",
      "Epoch 274/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1004.6012 - val_loss: 1301.3981\n",
      "Epoch 275/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1002.2981 - val_loss: 1287.4437\n",
      "Epoch 276/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 999.5080 - val_loss: 1304.4110\n",
      "Epoch 277/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 999.8548 - val_loss: 1262.7635\n",
      "Epoch 278/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1002.7822 - val_loss: 1267.9388\n",
      "Epoch 279/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1005.0245 - val_loss: 1272.4263\n",
      "Epoch 280/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1000.2600 - val_loss: 1279.3433\n",
      "Epoch 281/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1005.8750 - val_loss: 1309.0927\n",
      "Epoch 282/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 997.9316 - val_loss: 1365.0787\n",
      "Epoch 283/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1006.3699 - val_loss: 1334.8994\n",
      "Epoch 284/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1003.1240 - val_loss: 1280.4668\n",
      "Epoch 285/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 993.5378 - val_loss: 1260.0455\n",
      "Epoch 286/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 999.2889 - val_loss: 1263.4417\n",
      "Epoch 287/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1002.7795 - val_loss: 1315.8557\n",
      "Epoch 288/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 998.8838 - val_loss: 1287.0847\n",
      "Epoch 289/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 998.6188 - val_loss: 1278.3721\n",
      "Epoch 290/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 992.4791 - val_loss: 1259.4280\n",
      "Epoch 291/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 990.7279 - val_loss: 1295.2880\n",
      "Epoch 292/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 993.2946 - val_loss: 1294.2255\n",
      "Epoch 293/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 990.3059 - val_loss: 1272.0288\n",
      "Epoch 294/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 995.1181 - val_loss: 1286.6097\n",
      "Epoch 295/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 994.2017 - val_loss: 1287.6915\n",
      "Epoch 296/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 997.6411 - val_loss: 1277.7177\n",
      "Epoch 297/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1000.7243 - val_loss: 1290.4348\n",
      "Epoch 298/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 994.8134 - val_loss: 1275.1261\n",
      "Epoch 299/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 991.1400 - val_loss: 1269.1294\n",
      "Epoch 300/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 984.8000 - val_loss: 1297.4852\n",
      "Epoch 301/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 992.7045 - val_loss: 1295.7317\n",
      "Epoch 302/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 983.9931 - val_loss: 1259.9119\n",
      "Epoch 303/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 984.1724 - val_loss: 1285.7078\n",
      "Epoch 304/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 985.5026 - val_loss: 1309.4030\n",
      "Epoch 305/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 992.9572 - val_loss: 1305.1439\n",
      "Epoch 306/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 991.4998 - val_loss: 1256.6722\n",
      "Epoch 307/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 974.9543 - val_loss: 1307.1934\n",
      "Epoch 308/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 987.2248 - val_loss: 1257.9344\n",
      "Epoch 309/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 980.5496 - val_loss: 1300.0033\n",
      "Epoch 310/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 989.6937 - val_loss: 1330.5154\n",
      "Epoch 311/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 985.9130 - val_loss: 1269.2162\n",
      "Epoch 312/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 982.7690 - val_loss: 1278.3877\n",
      "Epoch 313/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 981.9080 - val_loss: 1266.6104\n",
      "Epoch 314/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 983.8491 - val_loss: 1260.4247\n",
      "Epoch 315/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 980.3043 - val_loss: 1285.2261\n",
      "Epoch 316/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 992.7068 - val_loss: 1277.8101\n",
      "Epoch 317/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 982.8080 - val_loss: 1263.4844\n",
      "Epoch 318/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 979.2093 - val_loss: 1273.2802\n",
      "Epoch 319/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 967.6887 - val_loss: 1307.0435\n",
      "Epoch 320/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 983.3890 - val_loss: 1284.5054\n",
      "Epoch 321/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 979.2596 - val_loss: 1313.7496\n",
      "Epoch 322/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 987.3120 - val_loss: 1284.2537\n",
      "Epoch 323/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 973.9026 - val_loss: 1265.5082\n",
      "Epoch 324/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 977.1458 - val_loss: 1271.0818\n",
      "Epoch 325/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 978.7548 - val_loss: 1280.8466\n",
      "Epoch 326/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 974.0613 - val_loss: 1279.0594\n",
      "Epoch 327/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 974.8656 - val_loss: 1281.4149\n",
      "Epoch 328/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 972.1177 - val_loss: 1274.9424\n",
      "Epoch 329/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 980.8120 - val_loss: 1265.4406\n",
      "Epoch 330/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 967.1411 - val_loss: 1320.8457\n",
      "Epoch 331/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 975.1520 - val_loss: 1302.7683\n",
      "Epoch 332/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 972.0679 - val_loss: 1274.2426\n",
      "Epoch 333/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 970.2168 - val_loss: 1260.3699\n",
      "Epoch 334/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 971.8528 - val_loss: 1265.2753\n",
      "Epoch 335/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 968.9277 - val_loss: 1267.1442\n",
      "Epoch 336/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 974.1576 - val_loss: 1305.3055\n",
      "Epoch 337/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 974.4192 - val_loss: 1265.9281\n",
      "Epoch 338/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 972.1438 - val_loss: 1302.2341\n",
      "Epoch 339/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 966.2767 - val_loss: 1273.1841\n",
      "Epoch 340/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 972.0480 - val_loss: 1274.8666\n",
      "Epoch 341/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 962.3774 - val_loss: 1363.4735\n",
      "Epoch 342/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 969.9951 - val_loss: 1258.6873\n",
      "Epoch 343/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 959.6962 - val_loss: 1308.1249\n",
      "Epoch 344/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 961.3620 - val_loss: 1274.3889\n",
      "Epoch 345/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 968.1525 - val_loss: 1249.2682\n",
      "Epoch 346/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 964.8164 - val_loss: 1288.9899\n",
      "Epoch 347/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 974.9323 - val_loss: 1302.0217\n",
      "Epoch 348/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 963.3829 - val_loss: 1292.9298\n",
      "Epoch 349/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 974.3433 - val_loss: 1310.0405\n",
      "Epoch 350/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 964.4516 - val_loss: 1278.8137\n",
      "Epoch 351/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 960.2538 - val_loss: 1269.6490\n",
      "Epoch 352/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 957.4433 - val_loss: 1271.5897\n",
      "Epoch 353/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 974.8491 - val_loss: 1286.4023\n",
      "Epoch 354/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 964.5966 - val_loss: 1300.5756\n",
      "Epoch 355/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 964.5092 - val_loss: 1286.7821\n",
      "Epoch 356/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 971.7586 - val_loss: 1276.3114\n",
      "Epoch 357/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 953.6241 - val_loss: 1289.5140\n",
      "Epoch 358/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 953.7051 - val_loss: 1267.2344\n",
      "Epoch 359/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 956.8343 - val_loss: 1278.9423\n",
      "Epoch 360/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 955.7571 - val_loss: 1263.1635\n",
      "Epoch 361/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 954.1702 - val_loss: 1260.2227\n",
      "Epoch 362/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 946.8054 - val_loss: 1278.7974\n",
      "Epoch 363/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 957.9906 - val_loss: 1281.1924\n",
      "Epoch 364/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 963.6984 - val_loss: 1263.0552\n",
      "Epoch 365/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 959.3809 - val_loss: 1272.4963\n",
      "Epoch 366/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 964.9983 - val_loss: 1292.7338\n",
      "Epoch 367/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 950.6026 - val_loss: 1259.6949\n",
      "Epoch 368/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 955.9874 - val_loss: 1266.5404\n",
      "Epoch 369/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 956.0985 - val_loss: 1284.2681\n",
      "Epoch 370/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 954.4088 - val_loss: 1256.6420\n",
      "Epoch 371/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 945.8085 - val_loss: 1268.2871\n",
      "Epoch 372/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 960.1380 - val_loss: 1267.2742\n",
      "Epoch 373/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 3ms/step - loss: 946.3829 - val_loss: 1277.8895\n",
      "Epoch 374/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 961.2791 - val_loss: 1277.3442\n",
      "Epoch 375/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 956.8840 - val_loss: 1280.1718\n",
      "Epoch 376/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 952.3241 - val_loss: 1261.2743\n",
      "Epoch 377/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 954.4027 - val_loss: 1265.2128\n",
      "Epoch 378/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 950.9961 - val_loss: 1256.0258\n",
      "Epoch 379/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 949.6396 - val_loss: 1258.4735\n",
      "Epoch 380/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 949.8917 - val_loss: 1280.9214\n",
      "Epoch 381/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 946.2362 - val_loss: 1273.7476\n",
      "Epoch 382/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 940.3591 - val_loss: 1250.2445\n",
      "Epoch 383/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 944.8373 - val_loss: 1272.4406\n",
      "Epoch 384/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 944.6871 - val_loss: 1268.6896\n",
      "Epoch 385/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 949.9205 - val_loss: 1272.6870\n",
      "Epoch 386/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 949.9704 - val_loss: 1260.5214\n",
      "Epoch 387/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 942.1843 - val_loss: 1265.0520\n",
      "Epoch 388/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 944.8606 - val_loss: 1290.7795\n",
      "Epoch 389/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 946.6807 - val_loss: 1291.8981\n",
      "Epoch 390/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 953.2168 - val_loss: 1258.3413\n",
      "Epoch 391/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 935.0506 - val_loss: 1289.3865\n",
      "Epoch 392/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 960.6171 - val_loss: 1268.7866\n",
      "Epoch 393/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 945.8378 - val_loss: 1338.9714\n",
      "Epoch 394/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 948.2585 - val_loss: 1249.8719\n",
      "Epoch 395/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 936.4859 - val_loss: 1265.6334\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model4.h5\", save_best_only=True)\n",
    "\n",
    "model4 = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=x_train_scaled.shape[1:]),\n",
    "    keras.layers.Dense(120, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(120, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(120, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model4.compile(loss=\"mae\",\n",
    "              optimizer=\"adam\")\n",
    "\n",
    "history4 = model4.fit(x_train_scaled, y_train,\n",
    "                      epochs=1000,\n",
    "                      validation_data=(x_test_scaled,y_test),\n",
    "                      callbacks=[early_stopping_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8583509848830604\n",
      "0.8138359611916897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_test_predict = model4.predict(x_test_scaled)\n",
    "y_train_predict = model4.predict(x_train_scaled)\n",
    "print(r2_score(y_train, y_train_predict))\n",
    "print(r2_score(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_curves(history4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 4986.4111 - val_loss: 1997.8706\n",
      "Epoch 2/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1888.9751 - val_loss: 1889.1506\n",
      "Epoch 3/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1806.0720 - val_loss: 1836.4937\n",
      "Epoch 4/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1762.7474 - val_loss: 1824.6144\n",
      "Epoch 5/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1733.2328 - val_loss: 1793.2258\n",
      "Epoch 6/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1708.7072 - val_loss: 1765.8304\n",
      "Epoch 7/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1690.3442 - val_loss: 1739.6365\n",
      "Epoch 8/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1673.4872 - val_loss: 1727.7986\n",
      "Epoch 9/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1660.5894 - val_loss: 1727.2290\n",
      "Epoch 10/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1652.4066 - val_loss: 1708.2467\n",
      "Epoch 11/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1641.8519 - val_loss: 1731.0752\n",
      "Epoch 12/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1633.4338 - val_loss: 1692.4021\n",
      "Epoch 13/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1623.7318 - val_loss: 1703.1552\n",
      "Epoch 14/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1621.1216 - val_loss: 1689.6469\n",
      "Epoch 15/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1615.8307 - val_loss: 1679.5049\n",
      "Epoch 16/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1607.6183 - val_loss: 1682.6251\n",
      "Epoch 17/1000\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 1607.6375 - val_loss: 1671.1908\n",
      "Epoch 18/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1600.0400 - val_loss: 1720.8413\n",
      "Epoch 19/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1592.8029 - val_loss: 1663.3069\n",
      "Epoch 20/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1593.9976 - val_loss: 1665.9025\n",
      "Epoch 21/1000\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 1588.6858 - val_loss: 1657.4835\n",
      "Epoch 22/1000\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1583.7572 - val_loss: 1652.5380\n",
      "Epoch 23/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1575.4377 - val_loss: 1670.1261\n",
      "Epoch 24/1000\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 1573.2150 - val_loss: 1650.7477\n",
      "Epoch 25/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1569.6544 - val_loss: 1660.0621\n",
      "Epoch 26/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1565.0405 - val_loss: 1653.0925\n",
      "Epoch 27/1000\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 1563.5654 - val_loss: 1635.5627\n",
      "Epoch 28/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1557.6376 - val_loss: 1629.6200\n",
      "Epoch 29/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1559.9811 - val_loss: 1650.4225\n",
      "Epoch 30/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1557.2720 - val_loss: 1634.3766\n",
      "Epoch 31/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1553.8395 - val_loss: 1670.4993\n",
      "Epoch 32/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1549.9138 - val_loss: 1630.9119\n",
      "Epoch 33/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1546.0231 - val_loss: 1637.3424\n",
      "Epoch 34/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1542.2458 - val_loss: 1619.3276\n",
      "Epoch 35/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1539.2610 - val_loss: 1621.3142\n",
      "Epoch 36/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1536.5424 - val_loss: 1623.4508\n",
      "Epoch 37/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1538.0751 - val_loss: 1627.9906\n",
      "Epoch 38/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1531.6296 - val_loss: 1622.5759\n",
      "Epoch 39/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1527.1161 - val_loss: 1619.5737\n",
      "Epoch 40/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1527.0208 - val_loss: 1624.4888\n",
      "Epoch 41/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1523.4521 - val_loss: 1635.0455\n",
      "Epoch 42/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1520.9202 - val_loss: 1605.9652\n",
      "Epoch 43/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1517.7101 - val_loss: 1608.3833\n",
      "Epoch 44/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1515.0435 - val_loss: 1602.7605\n",
      "Epoch 45/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1514.4871 - val_loss: 1652.9985\n",
      "Epoch 46/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1511.9811 - val_loss: 1600.5437\n",
      "Epoch 47/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1506.9598 - val_loss: 1610.1543\n",
      "Epoch 48/1000\n",
      "268/268 [==============================] - 3s 13ms/step - loss: 1508.3889 - val_loss: 1590.9480\n",
      "Epoch 49/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1501.4631 - val_loss: 1599.4686\n",
      "Epoch 50/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1502.5726 - val_loss: 1606.6110\n",
      "Epoch 51/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1502.4188 - val_loss: 1594.0065\n",
      "Epoch 52/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1497.8541 - val_loss: 1587.9133\n",
      "Epoch 53/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1491.4679 - val_loss: 1593.0818\n",
      "Epoch 54/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1496.1392 - val_loss: 1595.1713\n",
      "Epoch 55/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1491.2886 - val_loss: 1592.8850\n",
      "Epoch 56/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1490.6437 - val_loss: 1585.1798\n",
      "Epoch 57/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1485.7046 - val_loss: 1590.5728\n",
      "Epoch 58/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1483.5879 - val_loss: 1581.2249\n",
      "Epoch 59/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1482.2395 - val_loss: 1622.9938\n",
      "Epoch 60/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1486.1005 - val_loss: 1575.1660\n",
      "Epoch 61/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1480.8280 - val_loss: 1581.9688\n",
      "Epoch 62/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1474.4789 - val_loss: 1570.3778\n",
      "Epoch 63/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1481.4082 - val_loss: 1603.1337\n",
      "Epoch 64/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1478.0566 - val_loss: 1573.0439\n",
      "Epoch 65/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1474.9340 - val_loss: 1597.1433\n",
      "Epoch 66/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1474.3966 - val_loss: 1602.0342\n",
      "Epoch 67/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1470.3257 - val_loss: 1570.6265\n",
      "Epoch 68/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1470.0958 - val_loss: 1571.1560\n",
      "Epoch 69/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1466.3811 - val_loss: 1605.3553\n",
      "Epoch 70/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1466.4561 - val_loss: 1613.0985\n",
      "Epoch 71/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1462.8860 - val_loss: 1604.1167\n",
      "Epoch 72/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1458.8204 - val_loss: 1588.1255\n",
      "Epoch 73/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1456.8182 - val_loss: 1561.8975\n",
      "Epoch 74/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1453.9390 - val_loss: 1562.7281\n",
      "Epoch 75/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1458.4762 - val_loss: 1559.6290\n",
      "Epoch 76/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1453.4469 - val_loss: 1551.6985\n",
      "Epoch 77/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1451.0709 - val_loss: 1561.3722\n",
      "Epoch 78/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1450.9573 - val_loss: 1591.7368\n",
      "Epoch 79/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1452.7942 - val_loss: 1568.6395\n",
      "Epoch 80/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1444.5149 - val_loss: 1541.0717\n",
      "Epoch 81/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1442.7386 - val_loss: 1555.5647\n",
      "Epoch 82/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1443.5682 - val_loss: 1548.8396\n",
      "Epoch 83/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1440.2091 - val_loss: 1559.7604\n",
      "Epoch 84/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1438.0876 - val_loss: 1546.7493\n",
      "Epoch 85/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1432.1603 - val_loss: 1574.5206\n",
      "Epoch 86/1000\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 1432.1802 - val_loss: 1527.1891\n",
      "Epoch 87/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1432.2719 - val_loss: 1552.5262\n",
      "Epoch 88/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1425.7823 - val_loss: 1537.7092\n",
      "Epoch 89/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1424.0380 - val_loss: 1532.7195\n",
      "Epoch 90/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1423.6146 - val_loss: 1532.9187\n",
      "Epoch 91/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1420.2083 - val_loss: 1529.3301\n",
      "Epoch 92/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1421.6543 - val_loss: 1544.2317\n",
      "Epoch 93/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1418.3267 - val_loss: 1529.1785\n",
      "Epoch 94/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1411.0165 - val_loss: 1525.3242\n",
      "Epoch 95/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1414.0624 - val_loss: 1527.7783\n",
      "Epoch 96/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1410.1953 - val_loss: 1517.1472\n",
      "Epoch 97/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1409.5786 - val_loss: 1580.9330\n",
      "Epoch 98/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1407.7429 - val_loss: 1539.0503\n",
      "Epoch 99/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1401.5991 - val_loss: 1501.9410\n",
      "Epoch 100/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1400.4036 - val_loss: 1527.7068\n",
      "Epoch 101/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1400.2529 - val_loss: 1503.6324\n",
      "Epoch 102/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1404.4652 - val_loss: 1503.7633\n",
      "Epoch 103/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1398.4233 - val_loss: 1525.8524\n",
      "Epoch 104/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1395.6108 - val_loss: 1517.1198\n",
      "Epoch 105/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1390.6066 - val_loss: 1522.5781\n",
      "Epoch 106/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1390.4229 - val_loss: 1504.2891\n",
      "Epoch 107/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1388.3790 - val_loss: 1521.2649\n",
      "Epoch 108/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1387.6560 - val_loss: 1491.3582\n",
      "Epoch 109/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1383.0378 - val_loss: 1517.6185\n",
      "Epoch 110/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1379.9536 - val_loss: 1514.4620\n",
      "Epoch 111/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1381.2332 - val_loss: 1491.2866\n",
      "Epoch 112/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1374.9932 - val_loss: 1515.8391\n",
      "Epoch 113/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1378.8405 - val_loss: 1508.1417\n",
      "Epoch 114/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1368.0768 - val_loss: 1488.8190\n",
      "Epoch 115/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1368.6982 - val_loss: 1497.0381\n",
      "Epoch 116/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1369.1155 - val_loss: 1472.7139\n",
      "Epoch 117/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1363.4346 - val_loss: 1490.5328\n",
      "Epoch 118/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1361.3481 - val_loss: 1492.1672\n",
      "Epoch 119/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1360.3906 - val_loss: 1493.7877\n",
      "Epoch 120/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1360.3950 - val_loss: 1475.1801\n",
      "Epoch 121/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1356.7485 - val_loss: 1483.0961\n",
      "Epoch 122/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1360.8754 - val_loss: 1481.8737\n",
      "Epoch 123/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1352.8652 - val_loss: 1472.9442\n",
      "Epoch 124/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1351.8470 - val_loss: 1486.0132\n",
      "Epoch 125/1000\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 1351.3774 - val_loss: 1464.5690\n",
      "Epoch 126/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1349.8484 - val_loss: 1469.3572\n",
      "Epoch 127/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1347.3754 - val_loss: 1456.0099\n",
      "Epoch 128/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1344.0061 - val_loss: 1473.8446\n",
      "Epoch 129/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1342.4431 - val_loss: 1464.2786\n",
      "Epoch 130/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1341.7950 - val_loss: 1488.8610\n",
      "Epoch 131/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1340.2218 - val_loss: 1446.6876\n",
      "Epoch 132/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1332.7491 - val_loss: 1464.4589\n",
      "Epoch 133/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1336.6506 - val_loss: 1472.5515\n",
      "Epoch 134/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1332.6859 - val_loss: 1461.9476\n",
      "Epoch 135/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1325.7726 - val_loss: 1472.4055\n",
      "Epoch 136/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1331.0243 - val_loss: 1447.6993\n",
      "Epoch 137/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1325.8285 - val_loss: 1505.2329\n",
      "Epoch 138/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1327.1042 - val_loss: 1458.7379\n",
      "Epoch 139/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1317.5779 - val_loss: 1453.5980\n",
      "Epoch 140/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1316.2687 - val_loss: 1477.8442\n",
      "Epoch 141/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1315.0590 - val_loss: 1425.2754\n",
      "Epoch 142/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1312.8115 - val_loss: 1476.5380\n",
      "Epoch 143/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1314.3538 - val_loss: 1435.1710\n",
      "Epoch 144/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1318.0769 - val_loss: 1431.3229\n",
      "Epoch 145/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1309.2482 - val_loss: 1444.8616\n",
      "Epoch 146/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1309.2452 - val_loss: 1443.5997\n",
      "Epoch 147/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1308.7068 - val_loss: 1423.8597\n",
      "Epoch 148/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1310.3530 - val_loss: 1421.8282\n",
      "Epoch 149/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1301.8638 - val_loss: 1462.2921\n",
      "Epoch 150/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1302.8645 - val_loss: 1418.5929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1310.6345 - val_loss: 1438.2665\n",
      "Epoch 152/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1299.3804 - val_loss: 1442.9094\n",
      "Epoch 153/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1297.8619 - val_loss: 1419.4315\n",
      "Epoch 154/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1293.7450 - val_loss: 1430.1511\n",
      "Epoch 155/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1288.3047 - val_loss: 1430.2861\n",
      "Epoch 156/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1294.7209 - val_loss: 1461.5762\n",
      "Epoch 157/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1285.5743 - val_loss: 1438.0594\n",
      "Epoch 158/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1294.7390 - val_loss: 1411.8890\n",
      "Epoch 159/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1289.0438 - val_loss: 1422.9698\n",
      "Epoch 160/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1288.4188 - val_loss: 1400.4489\n",
      "Epoch 161/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1288.2061 - val_loss: 1393.4471\n",
      "Epoch 162/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1285.7157 - val_loss: 1432.6294\n",
      "Epoch 163/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1282.1228 - val_loss: 1396.9546\n",
      "Epoch 164/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1283.5021 - val_loss: 1403.5354\n",
      "Epoch 165/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1283.1826 - val_loss: 1412.7640\n",
      "Epoch 166/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1282.1421 - val_loss: 1417.8866\n",
      "Epoch 167/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1273.4255 - val_loss: 1406.0532\n",
      "Epoch 168/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1272.2726 - val_loss: 1450.0623\n",
      "Epoch 169/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1281.7578 - val_loss: 1384.5327\n",
      "Epoch 170/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1267.8287 - val_loss: 1425.5986\n",
      "Epoch 171/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1267.2961 - val_loss: 1399.9023\n",
      "Epoch 172/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1268.2257 - val_loss: 1417.8102\n",
      "Epoch 173/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1261.7712 - val_loss: 1396.3778\n",
      "Epoch 174/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1265.6591 - val_loss: 1394.8313\n",
      "Epoch 175/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1258.3531 - val_loss: 1400.6191\n",
      "Epoch 176/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1260.9106 - val_loss: 1390.9103\n",
      "Epoch 177/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1259.3063 - val_loss: 1413.5225\n",
      "Epoch 178/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1263.1561 - val_loss: 1400.8409\n",
      "Epoch 179/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1260.8154 - val_loss: 1389.7460\n",
      "Epoch 180/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1261.3232 - val_loss: 1395.1349\n",
      "Epoch 181/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1256.6774 - val_loss: 1390.2859\n",
      "Epoch 182/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1252.8546 - val_loss: 1408.4491\n",
      "Epoch 183/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1256.4858 - val_loss: 1390.5383\n",
      "Epoch 184/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1252.9951 - val_loss: 1418.6530\n",
      "Epoch 185/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1251.5454 - val_loss: 1377.1531\n",
      "Epoch 186/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1250.8613 - val_loss: 1414.0905\n",
      "Epoch 187/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1256.3038 - val_loss: 1406.1241\n",
      "Epoch 188/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1250.3894 - val_loss: 1411.3773\n",
      "Epoch 189/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1251.1484 - val_loss: 1380.0660\n",
      "Epoch 190/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1244.9142 - val_loss: 1414.0215\n",
      "Epoch 191/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1248.3282 - val_loss: 1429.8856\n",
      "Epoch 192/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1249.5377 - val_loss: 1391.0305\n",
      "Epoch 193/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1241.2487 - val_loss: 1373.6993\n",
      "Epoch 194/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1234.1921 - val_loss: 1395.5211\n",
      "Epoch 195/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1240.0596 - val_loss: 1369.9972\n",
      "Epoch 196/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1239.9069 - val_loss: 1373.8772\n",
      "Epoch 197/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1237.6573 - val_loss: 1373.3230\n",
      "Epoch 198/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1244.6636 - val_loss: 1387.5696\n",
      "Epoch 199/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1233.2010 - val_loss: 1369.4897\n",
      "Epoch 200/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1235.1796 - val_loss: 1401.0973\n",
      "Epoch 201/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1248.5736 - val_loss: 1400.9923\n",
      "Epoch 202/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1230.4370 - val_loss: 1409.7095\n",
      "Epoch 203/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1231.1017 - val_loss: 1366.9144\n",
      "Epoch 204/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1228.6984 - val_loss: 1429.7139\n",
      "Epoch 205/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1236.5306 - val_loss: 1387.7535\n",
      "Epoch 206/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1233.6475 - val_loss: 1375.3961\n",
      "Epoch 207/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1226.9576 - val_loss: 1364.5326\n",
      "Epoch 208/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1225.5437 - val_loss: 1386.4464\n",
      "Epoch 209/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1237.8363 - val_loss: 1384.7849\n",
      "Epoch 210/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1223.8888 - val_loss: 1393.9501\n",
      "Epoch 211/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1234.7048 - val_loss: 1366.3549\n",
      "Epoch 212/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1222.9020 - val_loss: 1372.9269\n",
      "Epoch 213/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1229.2747 - val_loss: 1376.0986\n",
      "Epoch 214/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1221.7617 - val_loss: 1390.1285\n",
      "Epoch 215/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1231.9539 - val_loss: 1393.6960\n",
      "Epoch 216/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1223.5269 - val_loss: 1418.6104\n",
      "Epoch 217/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1231.6748 - val_loss: 1368.4235\n",
      "Epoch 218/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1219.5951 - val_loss: 1386.1187\n",
      "Epoch 219/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1212.7279 - val_loss: 1420.9690\n",
      "Epoch 220/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1217.0304 - val_loss: 1382.7000\n",
      "Epoch 221/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1218.4926 - val_loss: 1379.4471\n",
      "Epoch 222/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1209.5864 - val_loss: 1365.9509\n",
      "Epoch 223/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1214.1639 - val_loss: 1394.0583\n",
      "Epoch 224/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1211.9744 - val_loss: 1393.1584\n",
      "Epoch 225/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1215.7302 - val_loss: 1379.4087\n",
      "Epoch 226/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1209.3563 - val_loss: 1381.2080\n",
      "Epoch 227/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1216.3513 - val_loss: 1370.2484\n",
      "Epoch 228/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1208.5719 - val_loss: 1358.7236\n",
      "Epoch 229/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1212.7832 - val_loss: 1370.5439\n",
      "Epoch 230/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1212.5614 - val_loss: 1375.4694\n",
      "Epoch 231/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1206.5951 - val_loss: 1350.2098\n",
      "Epoch 232/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1213.2677 - val_loss: 1372.0936\n",
      "Epoch 233/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1201.8121 - val_loss: 1404.9066\n",
      "Epoch 234/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1208.3501 - val_loss: 1357.9913\n",
      "Epoch 235/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1200.5997 - val_loss: 1361.8170\n",
      "Epoch 236/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1204.0745 - val_loss: 1357.9841\n",
      "Epoch 237/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1206.7251 - val_loss: 1385.7931\n",
      "Epoch 238/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1206.5178 - val_loss: 1348.6393\n",
      "Epoch 239/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1192.1274 - val_loss: 1422.5177\n",
      "Epoch 240/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1206.6876 - val_loss: 1360.2090\n",
      "Epoch 241/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1198.0829 - val_loss: 1362.4996\n",
      "Epoch 242/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1198.5405 - val_loss: 1344.3036\n",
      "Epoch 243/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1197.8937 - val_loss: 1361.5468\n",
      "Epoch 244/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1202.3386 - val_loss: 1409.0770\n",
      "Epoch 245/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1206.2164 - val_loss: 1388.3031\n",
      "Epoch 246/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1197.8519 - val_loss: 1398.6503\n",
      "Epoch 247/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1207.4214 - val_loss: 1356.5999\n",
      "Epoch 248/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1201.8372 - val_loss: 1365.5205\n",
      "Epoch 249/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1197.7079 - val_loss: 1352.3625\n",
      "Epoch 250/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1190.0471 - val_loss: 1352.5923\n",
      "Epoch 251/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1183.6252 - val_loss: 1370.2644\n",
      "Epoch 252/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1191.2007 - val_loss: 1360.0242\n",
      "Epoch 253/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1198.0107 - val_loss: 1349.1761\n",
      "Epoch 254/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1191.0924 - val_loss: 1363.8639\n",
      "Epoch 255/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1190.1875 - val_loss: 1359.2531\n",
      "Epoch 256/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1187.4205 - val_loss: 1349.3390\n",
      "Epoch 257/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1188.7982 - val_loss: 1335.3951\n",
      "Epoch 258/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1185.8870 - val_loss: 1355.1749\n",
      "Epoch 259/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1196.7867 - val_loss: 1373.8641\n",
      "Epoch 260/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1185.8580 - val_loss: 1352.5808\n",
      "Epoch 261/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1183.3684 - val_loss: 1365.5265\n",
      "Epoch 262/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1181.4575 - val_loss: 1344.5889\n",
      "Epoch 263/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1181.1648 - val_loss: 1355.6406\n",
      "Epoch 264/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1188.4886 - val_loss: 1366.2340\n",
      "Epoch 265/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1185.8787 - val_loss: 1344.4174\n",
      "Epoch 266/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1178.4399 - val_loss: 1345.9736\n",
      "Epoch 267/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1185.0764 - val_loss: 1367.6552\n",
      "Epoch 268/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1175.3894 - val_loss: 1362.8262\n",
      "Epoch 269/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1183.9202 - val_loss: 1376.2992\n",
      "Epoch 270/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1168.7692 - val_loss: 1363.4718\n",
      "Epoch 271/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1182.3361 - val_loss: 1389.0413\n",
      "Epoch 272/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1183.5027 - val_loss: 1358.9420\n",
      "Epoch 273/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1178.8630 - val_loss: 1435.1071\n",
      "Epoch 274/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1171.4153 - val_loss: 1346.9159\n",
      "Epoch 275/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1182.8125 - val_loss: 1333.7548\n",
      "Epoch 276/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1173.9576 - val_loss: 1352.9679\n",
      "Epoch 277/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1186.2966 - val_loss: 1346.6854\n",
      "Epoch 278/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1167.0490 - val_loss: 1339.9380\n",
      "Epoch 279/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1174.5656 - val_loss: 1355.5454\n",
      "Epoch 280/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1167.6459 - val_loss: 1355.5963\n",
      "Epoch 281/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1179.1973 - val_loss: 1353.6022\n",
      "Epoch 282/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1165.1448 - val_loss: 1346.0801\n",
      "Epoch 283/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1170.5066 - val_loss: 1365.6201\n",
      "Epoch 284/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1172.8245 - val_loss: 1336.8562\n",
      "Epoch 285/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1160.9628 - val_loss: 1366.9753\n",
      "Epoch 286/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1174.2909 - val_loss: 1350.1871\n",
      "Epoch 287/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1165.6351 - val_loss: 1381.2570\n",
      "Epoch 288/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1168.5582 - val_loss: 1336.0287\n",
      "Epoch 289/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1157.5339 - val_loss: 1340.8156\n",
      "Epoch 290/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1172.8210 - val_loss: 1334.7789\n",
      "Epoch 291/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1166.6570 - val_loss: 1346.6882\n",
      "Epoch 292/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1165.5857 - val_loss: 1351.2870\n",
      "Epoch 293/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1166.3314 - val_loss: 1401.6205\n",
      "Epoch 294/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1168.9242 - val_loss: 1349.9170\n",
      "Epoch 295/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1164.3660 - val_loss: 1339.9091\n",
      "Epoch 296/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1166.0417 - val_loss: 1342.4193\n",
      "Epoch 297/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1159.1777 - val_loss: 1331.8247\n",
      "Epoch 298/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1155.4108 - val_loss: 1350.3649\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 3ms/step - loss: 1152.2275 - val_loss: 1363.2277\n",
      "Epoch 300/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1157.1361 - val_loss: 1381.5486\n",
      "Epoch 301/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1166.8053 - val_loss: 1341.1075\n",
      "Epoch 302/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1147.6198 - val_loss: 1342.0977\n",
      "Epoch 303/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1158.5486 - val_loss: 1355.3767\n",
      "Epoch 304/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1160.7498 - val_loss: 1321.9302\n",
      "Epoch 305/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1157.0641 - val_loss: 1347.7406\n",
      "Epoch 306/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1157.8428 - val_loss: 1409.7510\n",
      "Epoch 307/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1161.1056 - val_loss: 1349.7806\n",
      "Epoch 308/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1165.7100 - val_loss: 1341.2504\n",
      "Epoch 309/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1151.1067 - val_loss: 1330.4154\n",
      "Epoch 310/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1156.9956 - val_loss: 1381.4816\n",
      "Epoch 311/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1146.9554 - val_loss: 1337.2362\n",
      "Epoch 312/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1149.3851 - val_loss: 1348.9740\n",
      "Epoch 313/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1153.9076 - val_loss: 1344.0885\n",
      "Epoch 314/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1154.2570 - val_loss: 1317.3712\n",
      "Epoch 315/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1145.4990 - val_loss: 1343.6439\n",
      "Epoch 316/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1152.5220 - val_loss: 1321.9406\n",
      "Epoch 317/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1143.6456 - val_loss: 1328.2054\n",
      "Epoch 318/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1148.6676 - val_loss: 1332.3601\n",
      "Epoch 319/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1144.8047 - val_loss: 1336.2544\n",
      "Epoch 320/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1148.2441 - val_loss: 1355.2672\n",
      "Epoch 321/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1149.8427 - val_loss: 1347.2327\n",
      "Epoch 322/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1138.9487 - val_loss: 1354.2141\n",
      "Epoch 323/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1149.3029 - val_loss: 1356.4045\n",
      "Epoch 324/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1162.9670 - val_loss: 1368.3983\n",
      "Epoch 325/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1153.7448 - val_loss: 1323.9897\n",
      "Epoch 326/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1140.3989 - val_loss: 1329.8693\n",
      "Epoch 327/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1142.1954 - val_loss: 1364.5693\n",
      "Epoch 328/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1137.4307 - val_loss: 1354.4871\n",
      "Epoch 329/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1147.6609 - val_loss: 1326.3165\n",
      "Epoch 330/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1140.4667 - val_loss: 1359.3640\n",
      "Epoch 331/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1138.6649 - val_loss: 1326.1606\n",
      "Epoch 332/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1138.2620 - val_loss: 1328.1521\n",
      "Epoch 333/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1143.9624 - val_loss: 1332.1403\n",
      "Epoch 334/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1136.6515 - val_loss: 1321.9786\n",
      "Epoch 335/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1146.1333 - val_loss: 1329.6951\n",
      "Epoch 336/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1135.7297 - val_loss: 1317.0381\n",
      "Epoch 337/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1147.6713 - val_loss: 1338.8975\n",
      "Epoch 338/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1132.0631 - val_loss: 1346.4614\n",
      "Epoch 339/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1144.4822 - val_loss: 1326.6030\n",
      "Epoch 340/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1135.4259 - val_loss: 1331.3286\n",
      "Epoch 341/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1143.9052 - val_loss: 1326.1342\n",
      "Epoch 342/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1138.0830 - val_loss: 1324.0549\n",
      "Epoch 343/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1130.0582 - val_loss: 1320.8203\n",
      "Epoch 344/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1133.2548 - val_loss: 1332.7334\n",
      "Epoch 345/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1132.9528 - val_loss: 1356.0369\n",
      "Epoch 346/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1133.9717 - val_loss: 1323.6660\n",
      "Epoch 347/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1137.1011 - val_loss: 1322.8048\n",
      "Epoch 348/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1137.0114 - val_loss: 1352.6995\n",
      "Epoch 349/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1126.5652 - val_loss: 1334.0524\n",
      "Epoch 350/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1124.0405 - val_loss: 1336.9584\n",
      "Epoch 351/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1133.2396 - val_loss: 1334.2080\n",
      "Epoch 352/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1131.5793 - val_loss: 1321.3506\n",
      "Epoch 353/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1126.0868 - val_loss: 1328.0797\n",
      "Epoch 354/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1130.5618 - val_loss: 1324.9381\n",
      "Epoch 355/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1124.4034 - val_loss: 1308.1010\n",
      "Epoch 356/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1115.8944 - val_loss: 1319.6327\n",
      "Epoch 357/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1125.0720 - val_loss: 1336.5266\n",
      "Epoch 358/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1126.3601 - val_loss: 1335.7604\n",
      "Epoch 359/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1121.0571 - val_loss: 1360.0547\n",
      "Epoch 360/1000\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 1146.6755 - val_loss: 1306.6838\n",
      "Epoch 361/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1118.1453 - val_loss: 1305.1138\n",
      "Epoch 362/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1118.3921 - val_loss: 1311.0977\n",
      "Epoch 363/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1128.5686 - val_loss: 1324.1501\n",
      "Epoch 364/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1133.4949 - val_loss: 1309.7325\n",
      "Epoch 365/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1114.6392 - val_loss: 1320.5035\n",
      "Epoch 366/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1126.7068 - val_loss: 1298.4147\n",
      "Epoch 367/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1117.2950 - val_loss: 1314.1984\n",
      "Epoch 368/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1122.5303 - val_loss: 1328.4319\n",
      "Epoch 369/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1114.7979 - val_loss: 1337.9802\n",
      "Epoch 370/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1120.3282 - val_loss: 1306.5297\n",
      "Epoch 371/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1122.2357 - val_loss: 1333.1741\n",
      "Epoch 372/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1114.6489 - val_loss: 1330.4354\n",
      "Epoch 373/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1117.3413 - val_loss: 1328.1992\n",
      "Epoch 374/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1114.3813 - val_loss: 1347.1039\n",
      "Epoch 375/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1106.3101 - val_loss: 1308.6410\n",
      "Epoch 376/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1123.6803 - val_loss: 1350.4041\n",
      "Epoch 377/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1116.9197 - val_loss: 1302.0917\n",
      "Epoch 378/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1118.3260 - val_loss: 1307.5087\n",
      "Epoch 379/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1110.0640 - val_loss: 1316.7815\n",
      "Epoch 380/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1114.3441 - val_loss: 1386.9958\n",
      "Epoch 381/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1126.5312 - val_loss: 1355.3663\n",
      "Epoch 382/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1118.5802 - val_loss: 1346.0541\n",
      "Epoch 383/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1105.1713 - val_loss: 1319.3596\n",
      "Epoch 384/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1121.0076 - val_loss: 1320.7150\n",
      "Epoch 385/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1116.6078 - val_loss: 1311.6121\n",
      "Epoch 386/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1107.4930 - val_loss: 1309.4387\n",
      "Epoch 387/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1105.0150 - val_loss: 1306.8077\n",
      "Epoch 388/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1108.2764 - val_loss: 1363.1860\n",
      "Epoch 389/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1117.5176 - val_loss: 1323.5160\n",
      "Epoch 390/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1109.9689 - val_loss: 1325.1862\n",
      "Epoch 391/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1103.9305 - val_loss: 1316.3737\n",
      "Epoch 392/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1107.0472 - val_loss: 1354.2932\n",
      "Epoch 393/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1121.1776 - val_loss: 1308.7755\n",
      "Epoch 394/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1102.6589 - val_loss: 1347.1539\n",
      "Epoch 395/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1116.0718 - val_loss: 1316.4984\n",
      "Epoch 396/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1106.6484 - val_loss: 1319.3765\n",
      "Epoch 397/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1102.6851 - val_loss: 1307.6053\n",
      "Epoch 398/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1104.2629 - val_loss: 1312.6874\n",
      "Epoch 399/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1108.0608 - val_loss: 1297.0138\n",
      "Epoch 400/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1099.3499 - val_loss: 1309.5801\n",
      "Epoch 401/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1099.1400 - val_loss: 1296.0040\n",
      "Epoch 402/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1094.4750 - val_loss: 1326.0745\n",
      "Epoch 403/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1106.6272 - val_loss: 1325.0330\n",
      "Epoch 404/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1122.1322 - val_loss: 1293.3710\n",
      "Epoch 405/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1099.6008 - val_loss: 1315.6157\n",
      "Epoch 406/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1096.6304 - val_loss: 1325.2136\n",
      "Epoch 407/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1110.1202 - val_loss: 1305.3221\n",
      "Epoch 408/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1097.9493 - val_loss: 1316.9873\n",
      "Epoch 409/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1091.4406 - val_loss: 1320.1504\n",
      "Epoch 410/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1097.8052 - val_loss: 1309.3965\n",
      "Epoch 411/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1092.8429 - val_loss: 1308.0659\n",
      "Epoch 412/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1101.4791 - val_loss: 1295.7236\n",
      "Epoch 413/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1096.0808 - val_loss: 1304.9854\n",
      "Epoch 414/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1093.6602 - val_loss: 1297.3409\n",
      "Epoch 415/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1091.7633 - val_loss: 1294.0568\n",
      "Epoch 416/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1095.6987 - val_loss: 1294.7975\n",
      "Epoch 417/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1097.1201 - val_loss: 1324.7065\n",
      "Epoch 418/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1099.7472 - val_loss: 1306.4961\n",
      "Epoch 419/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1093.9974 - val_loss: 1315.6174\n",
      "Epoch 420/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1098.1862 - val_loss: 1281.7283\n",
      "Epoch 421/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1083.4784 - val_loss: 1349.7308\n",
      "Epoch 422/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1092.3976 - val_loss: 1293.3098\n",
      "Epoch 423/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1090.8601 - val_loss: 1314.0693\n",
      "Epoch 424/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1095.5977 - val_loss: 1296.7090\n",
      "Epoch 425/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1090.4490 - val_loss: 1306.7809\n",
      "Epoch 426/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1086.3901 - val_loss: 1305.8198\n",
      "Epoch 427/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1085.7959 - val_loss: 1295.1560\n",
      "Epoch 428/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1093.9578 - val_loss: 1298.8164\n",
      "Epoch 429/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1089.1514 - val_loss: 1303.5819\n",
      "Epoch 430/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1080.8936 - val_loss: 1345.3093\n",
      "Epoch 431/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1084.1366 - val_loss: 1306.8971\n",
      "Epoch 432/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1079.6360 - val_loss: 1304.6644\n",
      "Epoch 433/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1090.3700 - val_loss: 1309.5421\n",
      "Epoch 434/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1079.5547 - val_loss: 1326.3168\n",
      "Epoch 435/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1093.9392 - val_loss: 1294.9952\n",
      "Epoch 436/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1079.7114 - val_loss: 1301.2943\n",
      "Epoch 437/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1079.6874 - val_loss: 1287.5916\n",
      "Epoch 438/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1078.8528 - val_loss: 1264.1719\n",
      "Epoch 439/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1075.3423 - val_loss: 1278.2802\n",
      "Epoch 440/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1071.1956 - val_loss: 1288.1093\n",
      "Epoch 441/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1080.9233 - val_loss: 1302.5454\n",
      "Epoch 442/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1075.8892 - val_loss: 1292.3309\n",
      "Epoch 443/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1073.6221 - val_loss: 1342.3884\n",
      "Epoch 444/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1084.4005 - val_loss: 1302.0868\n",
      "Epoch 445/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1068.2380 - val_loss: 1318.4525\n",
      "Epoch 446/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1076.3364 - val_loss: 1276.8667\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 3ms/step - loss: 1074.8451 - val_loss: 1297.5889\n",
      "Epoch 448/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1076.9961 - val_loss: 1279.0735\n",
      "Epoch 449/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1082.9828 - val_loss: 1292.2407\n",
      "Epoch 450/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1068.9202 - val_loss: 1285.5402\n",
      "Epoch 451/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1067.3442 - val_loss: 1300.8292\n",
      "Epoch 452/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1069.3867 - val_loss: 1287.0057\n",
      "Epoch 453/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1075.8391 - val_loss: 1302.2795\n",
      "Epoch 454/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1065.6580 - val_loss: 1277.7289\n",
      "Epoch 455/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1062.5060 - val_loss: 1280.9961\n",
      "Epoch 456/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1067.9832 - val_loss: 1304.5602\n",
      "Epoch 457/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1078.0190 - val_loss: 1352.8708\n",
      "Epoch 458/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1077.3712 - val_loss: 1271.9631\n",
      "Epoch 459/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1069.3699 - val_loss: 1270.8435\n",
      "Epoch 460/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1070.4624 - val_loss: 1320.1656\n",
      "Epoch 461/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1067.2621 - val_loss: 1289.1671\n",
      "Epoch 462/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1055.7786 - val_loss: 1309.9491\n",
      "Epoch 463/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1067.0786 - val_loss: 1264.2948\n",
      "Epoch 464/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1059.0243 - val_loss: 1297.9800\n",
      "Epoch 465/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1054.0374 - val_loss: 1278.9255\n",
      "Epoch 466/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1066.5486 - val_loss: 1286.4541\n",
      "Epoch 467/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1069.0016 - val_loss: 1289.8534\n",
      "Epoch 468/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1065.3639 - val_loss: 1300.1719\n",
      "Epoch 469/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1059.6796 - val_loss: 1266.4569\n",
      "Epoch 470/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1058.9781 - val_loss: 1294.0944\n",
      "Epoch 471/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1055.5469 - val_loss: 1290.1752\n",
      "Epoch 472/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1068.8416 - val_loss: 1286.2124\n",
      "Epoch 473/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1071.4146 - val_loss: 1275.6246\n",
      "Epoch 474/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1053.7050 - val_loss: 1349.7300\n",
      "Epoch 475/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1066.9667 - val_loss: 1289.0991\n",
      "Epoch 476/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1063.2699 - val_loss: 1284.6622\n",
      "Epoch 477/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1056.5986 - val_loss: 1291.6403\n",
      "Epoch 478/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1056.0143 - val_loss: 1278.4689\n",
      "Epoch 479/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1062.0989 - val_loss: 1279.4349\n",
      "Epoch 480/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1065.1497 - val_loss: 1271.4595\n",
      "Epoch 481/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1057.6315 - val_loss: 1278.5653\n",
      "Epoch 482/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1072.6396 - val_loss: 1278.9536\n",
      "Epoch 483/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1052.6450 - val_loss: 1333.0352\n",
      "Epoch 484/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1053.0448 - val_loss: 1260.3229\n",
      "Epoch 485/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1062.7468 - val_loss: 1281.8962\n",
      "Epoch 486/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1056.8632 - val_loss: 1292.1704\n",
      "Epoch 487/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1060.1316 - val_loss: 1306.4575\n",
      "Epoch 488/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1056.5487 - val_loss: 1333.9683\n",
      "Epoch 489/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1069.9359 - val_loss: 1263.3811\n",
      "Epoch 490/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1066.7609 - val_loss: 1271.5718\n",
      "Epoch 491/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1047.3871 - val_loss: 1250.4595\n",
      "Epoch 492/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1055.2275 - val_loss: 1272.2933\n",
      "Epoch 493/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1047.9519 - val_loss: 1275.4492\n",
      "Epoch 494/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1043.9448 - val_loss: 1262.1823\n",
      "Epoch 495/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1052.8685 - val_loss: 1295.7499\n",
      "Epoch 496/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1039.0382 - val_loss: 1278.3055\n",
      "Epoch 497/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1056.3455 - val_loss: 1288.2812\n",
      "Epoch 498/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1056.1688 - val_loss: 1294.4705\n",
      "Epoch 499/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1061.2764 - val_loss: 1259.3441\n",
      "Epoch 500/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1039.6486 - val_loss: 1280.3391\n",
      "Epoch 501/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1047.4640 - val_loss: 1277.1897\n",
      "Epoch 502/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1038.7239 - val_loss: 1272.9250\n",
      "Epoch 503/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1049.9093 - val_loss: 1272.6052\n",
      "Epoch 504/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1051.9871 - val_loss: 1283.5787\n",
      "Epoch 505/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1046.1837 - val_loss: 1292.1437\n",
      "Epoch 506/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1046.3091 - val_loss: 1253.4398\n",
      "Epoch 507/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1044.8650 - val_loss: 1274.8207\n",
      "Epoch 508/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1044.5433 - val_loss: 1281.7349\n",
      "Epoch 509/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1046.2974 - val_loss: 1284.9927\n",
      "Epoch 510/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1045.6743 - val_loss: 1263.7048\n",
      "Epoch 511/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1039.6841 - val_loss: 1301.3512\n",
      "Epoch 512/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1046.4905 - val_loss: 1302.2546\n",
      "Epoch 513/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1045.4667 - val_loss: 1305.8867\n",
      "Epoch 514/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1044.9501 - val_loss: 1272.9575\n",
      "Epoch 515/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1039.2529 - val_loss: 1255.2354\n",
      "Epoch 516/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1038.1066 - val_loss: 1268.5421\n",
      "Epoch 517/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1036.1852 - val_loss: 1298.2849\n",
      "Epoch 518/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1042.0775 - val_loss: 1243.2107\n",
      "Epoch 519/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1029.8508 - val_loss: 1309.9662\n",
      "Epoch 520/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1043.3948 - val_loss: 1261.9276\n",
      "Epoch 521/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1038.1613 - val_loss: 1318.4840\n",
      "Epoch 522/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1046.5193 - val_loss: 1263.6273\n",
      "Epoch 523/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1028.7484 - val_loss: 1271.6014\n",
      "Epoch 524/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1049.1069 - val_loss: 1275.6564\n",
      "Epoch 525/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1034.1130 - val_loss: 1250.4087\n",
      "Epoch 526/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1033.8456 - val_loss: 1297.9005\n",
      "Epoch 527/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1043.4237 - val_loss: 1301.7888\n",
      "Epoch 528/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1044.5258 - val_loss: 1280.4984\n",
      "Epoch 529/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1027.7811 - val_loss: 1264.1854\n",
      "Epoch 530/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1026.4827 - val_loss: 1261.5752\n",
      "Epoch 531/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1032.1606 - val_loss: 1276.3083\n",
      "Epoch 532/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1039.0892 - val_loss: 1277.9248\n",
      "Epoch 533/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1038.9983 - val_loss: 1266.9038\n",
      "Epoch 534/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1020.9818 - val_loss: 1260.8330\n",
      "Epoch 535/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1030.2249 - val_loss: 1319.7075\n",
      "Epoch 536/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1053.3563 - val_loss: 1253.7002\n",
      "Epoch 537/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1035.2444 - val_loss: 1293.1821\n",
      "Epoch 538/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1026.4135 - val_loss: 1272.3364\n",
      "Epoch 539/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1041.8101 - val_loss: 1276.5107\n",
      "Epoch 540/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1026.6909 - val_loss: 1271.7053\n",
      "Epoch 541/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1033.3568 - val_loss: 1259.0961\n",
      "Epoch 542/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1024.1256 - val_loss: 1272.9795\n",
      "Epoch 543/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1036.5397 - val_loss: 1254.9940\n",
      "Epoch 544/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1031.5325 - val_loss: 1288.6387\n",
      "Epoch 545/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1020.1111 - val_loss: 1260.1494\n",
      "Epoch 546/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1049.3145 - val_loss: 1283.6418\n",
      "Epoch 547/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1038.9161 - val_loss: 1294.4269\n",
      "Epoch 548/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1037.7711 - val_loss: 1269.2723\n",
      "Epoch 549/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1036.8203 - val_loss: 1254.3771\n",
      "Epoch 550/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1022.1111 - val_loss: 1272.6061\n",
      "Epoch 551/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1019.9795 - val_loss: 1278.5966\n",
      "Epoch 552/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1039.5309 - val_loss: 1231.0648\n",
      "Epoch 553/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1023.3721 - val_loss: 1260.9249\n",
      "Epoch 554/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1028.1538 - val_loss: 1242.4572\n",
      "Epoch 555/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1010.9097 - val_loss: 1238.7256\n",
      "Epoch 556/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1019.3926 - val_loss: 1296.9897\n",
      "Epoch 557/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1035.6044 - val_loss: 1283.6382\n",
      "Epoch 558/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1020.3533 - val_loss: 1274.2202\n",
      "Epoch 559/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1026.1276 - val_loss: 1309.7650\n",
      "Epoch 560/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1023.7908 - val_loss: 1261.0605\n",
      "Epoch 561/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1022.6498 - val_loss: 1262.8884\n",
      "Epoch 562/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1021.9774 - val_loss: 1254.2301\n",
      "Epoch 563/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1017.1610 - val_loss: 1260.0957\n",
      "Epoch 564/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1008.7949 - val_loss: 1271.5267\n",
      "Epoch 565/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1026.6320 - val_loss: 1241.0797\n",
      "Epoch 566/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1017.9422 - val_loss: 1272.6594\n",
      "Epoch 567/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1009.2651 - val_loss: 1282.2242\n",
      "Epoch 568/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1021.9611 - val_loss: 1268.8042\n",
      "Epoch 569/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1012.6894 - val_loss: 1240.5859\n",
      "Epoch 570/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1015.0984 - val_loss: 1256.4651\n",
      "Epoch 571/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1012.7204 - val_loss: 1267.9758\n",
      "Epoch 572/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1015.6115 - val_loss: 1277.2296\n",
      "Epoch 573/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1025.4764 - val_loss: 1283.4507\n",
      "Epoch 574/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1034.7266 - val_loss: 1232.0675\n",
      "Epoch 575/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1010.9343 - val_loss: 1241.4601\n",
      "Epoch 576/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1010.6358 - val_loss: 1271.4836\n",
      "Epoch 577/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1013.3053 - val_loss: 1281.3416\n",
      "Epoch 578/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1019.3840 - val_loss: 1300.4186\n",
      "Epoch 579/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1021.4642 - val_loss: 1267.7936\n",
      "Epoch 580/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1016.4895 - val_loss: 1252.3799\n",
      "Epoch 581/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1007.3479 - val_loss: 1274.1831\n",
      "Epoch 582/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1009.7991 - val_loss: 1284.3224\n",
      "Epoch 583/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1016.6377 - val_loss: 1254.5675\n",
      "Epoch 584/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1004.6900 - val_loss: 1275.3555\n",
      "Epoch 585/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1008.8585 - val_loss: 1261.0900\n",
      "Epoch 586/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1016.4558 - val_loss: 1256.2550\n",
      "Epoch 587/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1010.2287 - val_loss: 1255.6166\n",
      "Epoch 588/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1017.2010 - val_loss: 1226.9816\n",
      "Epoch 589/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1002.8672 - val_loss: 1232.8479\n",
      "Epoch 590/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1002.6632 - val_loss: 1253.0692\n",
      "Epoch 591/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1011.7728 - val_loss: 1272.1633\n",
      "Epoch 592/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1006.8094 - val_loss: 1250.8208\n",
      "Epoch 593/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1012.0760 - val_loss: 1262.5947\n",
      "Epoch 594/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1018.4008 - val_loss: 1293.5706\n",
      "Epoch 595/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 3ms/step - loss: 1004.7571 - val_loss: 1243.6036\n",
      "Epoch 596/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1002.6074 - val_loss: 1289.9150\n",
      "Epoch 597/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1017.2216 - val_loss: 1230.5520\n",
      "Epoch 598/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1004.6312 - val_loss: 1251.4366\n",
      "Epoch 599/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 997.9719 - val_loss: 1248.1924\n",
      "Epoch 600/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1018.2642 - val_loss: 1237.7292\n",
      "Epoch 601/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1000.3206 - val_loss: 1259.1353\n",
      "Epoch 602/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1013.4202 - val_loss: 1283.6475\n",
      "Epoch 603/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 999.7769 - val_loss: 1243.2854\n",
      "Epoch 604/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1006.2922 - val_loss: 1265.8480\n",
      "Epoch 605/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1013.1653 - val_loss: 1254.3004\n",
      "Epoch 606/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 998.2523 - val_loss: 1267.3370\n",
      "Epoch 607/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1019.0488 - val_loss: 1237.7244\n",
      "Epoch 608/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1002.7239 - val_loss: 1320.2921\n",
      "Epoch 609/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1005.7011 - val_loss: 1238.2769\n",
      "Epoch 610/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1013.4263 - val_loss: 1248.5601\n",
      "Epoch 611/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1010.0952 - val_loss: 1273.8175\n",
      "Epoch 612/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1009.6703 - val_loss: 1280.1222\n",
      "Epoch 613/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 998.0305 - val_loss: 1238.4733\n",
      "Epoch 614/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1001.0826 - val_loss: 1229.5215\n",
      "Epoch 615/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1007.6105 - val_loss: 1253.7235\n",
      "Epoch 616/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1010.7968 - val_loss: 1230.6954\n",
      "Epoch 617/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 990.3272 - val_loss: 1277.8950\n",
      "Epoch 618/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1013.9783 - val_loss: 1253.7527\n",
      "Epoch 619/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1004.4873 - val_loss: 1251.6079\n",
      "Epoch 620/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 992.9641 - val_loss: 1229.1593\n",
      "Epoch 621/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1001.6673 - val_loss: 1283.0171\n",
      "Epoch 622/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1011.0621 - val_loss: 1255.2637\n",
      "Epoch 623/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 988.1885 - val_loss: 1263.1272\n",
      "Epoch 624/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1001.3980 - val_loss: 1299.4412\n",
      "Epoch 625/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1011.0329 - val_loss: 1288.9039\n",
      "Epoch 626/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 996.1083 - val_loss: 1244.4928\n",
      "Epoch 627/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 990.6990 - val_loss: 1271.7710\n",
      "Epoch 628/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 992.0851 - val_loss: 1246.2283\n",
      "Epoch 629/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 991.1282 - val_loss: 1274.4504\n",
      "Epoch 630/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1006.6641 - val_loss: 1246.3114\n",
      "Epoch 631/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 991.0054 - val_loss: 1258.6119\n",
      "Epoch 632/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 997.1880 - val_loss: 1243.5195\n",
      "Epoch 633/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 987.9415 - val_loss: 1256.0861\n",
      "Epoch 634/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1004.4041 - val_loss: 1240.3230\n",
      "Epoch 635/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1003.4096 - val_loss: 1254.9019\n",
      "Epoch 636/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 996.5415 - val_loss: 1270.6936\n",
      "Epoch 637/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 989.4526 - val_loss: 1254.0125\n",
      "Epoch 638/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 988.1909 - val_loss: 1238.3921\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model5.h5\", save_best_only=True)\n",
    "\n",
    "model5 = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=x_train_scaled.shape[1:]),\n",
    "    keras.layers.Dense(120, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Dense(120, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Dense(120, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model5.compile(loss=\"mae\",\n",
    "              optimizer=\"adam\")\n",
    "\n",
    "history5 = model5.fit(x_train_scaled, y_train,\n",
    "                      epochs=1000,\n",
    "                      validation_data=(x_test_scaled,y_test),\n",
    "                      callbacks=[early_stopping_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8483181353512436\n",
      "0.8205676531335896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_test_predict = model5.predict(x_test_scaled)\n",
    "y_train_predict = model5.predict(x_train_scaled)\n",
    "print(r2_score(y_train, y_train_predict))\n",
    "print(r2_score(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 9071.7207 - val_loss: 9103.1875\n",
      "Epoch 2/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 9038.1709 - val_loss: 9044.6963\n",
      "Epoch 3/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 8971.6484 - val_loss: 8961.9072\n",
      "Epoch 4/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 8882.4072 - val_loss: 8857.5469\n",
      "Epoch 5/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 8773.8975 - val_loss: 8721.6055\n",
      "Epoch 6/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 8647.2441 - val_loss: 8598.5000\n",
      "Epoch 7/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 8504.1797 - val_loss: 8419.1074\n",
      "Epoch 8/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 8344.3154 - val_loss: 8266.1846\n",
      "Epoch 9/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 8169.8594 - val_loss: 8077.6753\n",
      "Epoch 10/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 7982.3784 - val_loss: 7882.7749\n",
      "Epoch 11/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 7779.7290 - val_loss: 7625.5562\n",
      "Epoch 12/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 7566.3086 - val_loss: 7416.9775\n",
      "Epoch 13/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 7340.4136 - val_loss: 7187.3994\n",
      "Epoch 14/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 7100.6240 - val_loss: 6923.9912\n",
      "Epoch 15/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 6851.0488 - val_loss: 6653.5586\n",
      "Epoch 16/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 6588.4976 - val_loss: 6348.0605\n",
      "Epoch 17/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 6312.6807 - val_loss: 6101.7944\n",
      "Epoch 18/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 6027.4414 - val_loss: 5792.6870\n",
      "Epoch 19/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 5736.6113 - val_loss: 5504.4541\n",
      "Epoch 20/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 5435.6831 - val_loss: 5177.6743\n",
      "Epoch 21/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 5129.0239 - val_loss: 4854.4043\n",
      "Epoch 22/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 4818.9814 - val_loss: 4604.6641\n",
      "Epoch 23/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 4504.1357 - val_loss: 4179.9170\n",
      "Epoch 24/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 4189.1060 - val_loss: 3945.7224\n",
      "Epoch 25/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 3878.5757 - val_loss: 3618.8809\n",
      "Epoch 26/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 3571.2913 - val_loss: 3314.0964\n",
      "Epoch 27/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 3280.2971 - val_loss: 3081.9543\n",
      "Epoch 28/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 2983.4629 - val_loss: 2799.9900\n",
      "Epoch 29/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 2725.1123 - val_loss: 2481.6172\n",
      "Epoch 30/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 2503.8438 - val_loss: 2323.1985\n",
      "Epoch 31/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 2317.9243 - val_loss: 2108.7007\n",
      "Epoch 32/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 2152.3145 - val_loss: 2023.1434\n",
      "Epoch 33/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 2040.1362 - val_loss: 1870.2661\n",
      "Epoch 34/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1927.9861 - val_loss: 1759.8468\n",
      "Epoch 35/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1835.8628 - val_loss: 1708.1324\n",
      "Epoch 36/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1767.5479 - val_loss: 1607.8740\n",
      "Epoch 37/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1728.6730 - val_loss: 1581.3043\n",
      "Epoch 38/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1684.1912 - val_loss: 1641.6626\n",
      "Epoch 39/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1657.3292 - val_loss: 1572.6796\n",
      "Epoch 40/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1638.0537 - val_loss: 1558.0396\n",
      "Epoch 41/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1638.9000 - val_loss: 1530.1869\n",
      "Epoch 42/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1603.8948 - val_loss: 1504.1925\n",
      "Epoch 43/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1595.0739 - val_loss: 1478.6992\n",
      "Epoch 44/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1602.6014 - val_loss: 1514.4648\n",
      "Epoch 45/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1590.5353 - val_loss: 1523.7634\n",
      "Epoch 46/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1588.8624 - val_loss: 1474.1801\n",
      "Epoch 47/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1578.4268 - val_loss: 1461.2440\n",
      "Epoch 48/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1567.1932 - val_loss: 1519.7334\n",
      "Epoch 49/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1575.9874 - val_loss: 1461.9297\n",
      "Epoch 50/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1563.6344 - val_loss: 1478.1385\n",
      "Epoch 51/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1558.4691 - val_loss: 1443.7312\n",
      "Epoch 52/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1556.0724 - val_loss: 1507.3291\n",
      "Epoch 53/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1552.7504 - val_loss: 1450.4200\n",
      "Epoch 54/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1540.5774 - val_loss: 1461.0703\n",
      "Epoch 55/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1519.3232 - val_loss: 1431.1598\n",
      "Epoch 56/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1522.7627 - val_loss: 1415.8392\n",
      "Epoch 57/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1514.9836 - val_loss: 1420.2648\n",
      "Epoch 58/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1516.3621 - val_loss: 1445.9742\n",
      "Epoch 59/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1500.8427 - val_loss: 1429.8744\n",
      "Epoch 60/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1496.4376 - val_loss: 1417.3500\n",
      "Epoch 61/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1518.0737 - val_loss: 1439.4506\n",
      "Epoch 62/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1500.5846 - val_loss: 1438.0558\n",
      "Epoch 63/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1492.6561 - val_loss: 1406.1361\n",
      "Epoch 64/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1511.2188 - val_loss: 1401.8290\n",
      "Epoch 65/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1493.4144 - val_loss: 1397.9603\n",
      "Epoch 66/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1471.5256 - val_loss: 1389.7999\n",
      "Epoch 67/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1489.8370 - val_loss: 1379.9047\n",
      "Epoch 68/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1480.2668 - val_loss: 1376.3329\n",
      "Epoch 69/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1490.4823 - val_loss: 1394.9600\n",
      "Epoch 70/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1457.6925 - val_loss: 1385.8340\n",
      "Epoch 71/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1479.9319 - val_loss: 1398.5913\n",
      "Epoch 72/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1479.1152 - val_loss: 1406.0453\n",
      "Epoch 73/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1469.5583 - val_loss: 1389.5828\n",
      "Epoch 74/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1476.5471 - val_loss: 1383.0303\n",
      "Epoch 75/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1456.1969 - val_loss: 1358.0463\n",
      "Epoch 76/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1452.5773 - val_loss: 1385.1691\n",
      "Epoch 77/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1465.6310 - val_loss: 1365.8290\n",
      "Epoch 78/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1445.9597 - val_loss: 1382.6107\n",
      "Epoch 79/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1464.9928 - val_loss: 1380.5194\n",
      "Epoch 80/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1444.5070 - val_loss: 1381.5385\n",
      "Epoch 81/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1444.7285 - val_loss: 1368.9799\n",
      "Epoch 82/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1423.3612 - val_loss: 1377.2744\n",
      "Epoch 83/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1437.1548 - val_loss: 1372.4711\n",
      "Epoch 84/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1429.9768 - val_loss: 1376.3827\n",
      "Epoch 85/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1431.0516 - val_loss: 1382.5872\n",
      "Epoch 86/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1427.6121 - val_loss: 1381.0974\n",
      "Epoch 87/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1439.6340 - val_loss: 1370.3147\n",
      "Epoch 88/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1414.7180 - val_loss: 1421.5627\n",
      "Epoch 89/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1425.3917 - val_loss: 1355.1901\n",
      "Epoch 90/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1422.4865 - val_loss: 1351.0126\n",
      "Epoch 91/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1422.0757 - val_loss: 1383.9037\n",
      "Epoch 92/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1411.3572 - val_loss: 1343.5601\n",
      "Epoch 93/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1421.6865 - val_loss: 1346.4742\n",
      "Epoch 94/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1422.3928 - val_loss: 1391.0811\n",
      "Epoch 95/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1420.1454 - val_loss: 1378.7286\n",
      "Epoch 96/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1400.1980 - val_loss: 1352.8568\n",
      "Epoch 97/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1411.0052 - val_loss: 1348.3165\n",
      "Epoch 98/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1437.9636 - val_loss: 1339.7756\n",
      "Epoch 99/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1375.5723 - val_loss: 1359.1426\n",
      "Epoch 100/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1403.6980 - val_loss: 1362.6783\n",
      "Epoch 101/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1394.3636 - val_loss: 1361.5718\n",
      "Epoch 102/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1388.9380 - val_loss: 1376.7509\n",
      "Epoch 103/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1376.9276 - val_loss: 1375.8207\n",
      "Epoch 104/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1382.6083 - val_loss: 1335.5385\n",
      "Epoch 105/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1389.6713 - val_loss: 1354.7197\n",
      "Epoch 106/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1387.4613 - val_loss: 1323.6309\n",
      "Epoch 107/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1365.7312 - val_loss: 1334.0957\n",
      "Epoch 108/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1378.0828 - val_loss: 1330.1412\n",
      "Epoch 109/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1396.6190 - val_loss: 1341.3959\n",
      "Epoch 110/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1381.2942 - val_loss: 1331.6716\n",
      "Epoch 111/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1362.7527 - val_loss: 1313.0839\n",
      "Epoch 112/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1387.0469 - val_loss: 1375.9012\n",
      "Epoch 113/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1381.2778 - val_loss: 1326.5920\n",
      "Epoch 114/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1352.4600 - val_loss: 1338.1437\n",
      "Epoch 115/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1380.5460 - val_loss: 1343.4348\n",
      "Epoch 116/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1349.8539 - val_loss: 1361.9850\n",
      "Epoch 117/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1363.0924 - val_loss: 1341.3014\n",
      "Epoch 118/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1375.3020 - val_loss: 1325.0596\n",
      "Epoch 119/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1353.6200 - val_loss: 1322.7852\n",
      "Epoch 120/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1367.0533 - val_loss: 1360.4963\n",
      "Epoch 121/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1365.2760 - val_loss: 1350.2153\n",
      "Epoch 122/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1365.1591 - val_loss: 1329.8517\n",
      "Epoch 123/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1361.1278 - val_loss: 1314.7800\n",
      "Epoch 124/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1343.7415 - val_loss: 1331.0085\n",
      "Epoch 125/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1366.5188 - val_loss: 1327.3112\n",
      "Epoch 126/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1366.5758 - val_loss: 1300.2693\n",
      "Epoch 127/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1337.9860 - val_loss: 1297.3490\n",
      "Epoch 128/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1345.2141 - val_loss: 1297.1195\n",
      "Epoch 129/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1334.4937 - val_loss: 1319.0830\n",
      "Epoch 130/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1355.8688 - val_loss: 1292.2231\n",
      "Epoch 131/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1350.7542 - val_loss: 1342.7574\n",
      "Epoch 132/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1348.6263 - val_loss: 1314.4193\n",
      "Epoch 133/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1335.8555 - val_loss: 1326.3221\n",
      "Epoch 134/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1340.3610 - val_loss: 1301.0109\n",
      "Epoch 135/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1343.5475 - val_loss: 1290.3795\n",
      "Epoch 136/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1327.8273 - val_loss: 1292.3496\n",
      "Epoch 137/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1328.2316 - val_loss: 1285.5842\n",
      "Epoch 138/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1341.4103 - val_loss: 1286.0624\n",
      "Epoch 139/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1326.7900 - val_loss: 1308.7942\n",
      "Epoch 140/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1325.6432 - val_loss: 1306.2780\n",
      "Epoch 141/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1305.4436 - val_loss: 1286.7521\n",
      "Epoch 142/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1320.1169 - val_loss: 1302.4731\n",
      "Epoch 143/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1351.5757 - val_loss: 1307.9618\n",
      "Epoch 144/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1328.6273 - val_loss: 1294.4685\n",
      "Epoch 145/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1311.1342 - val_loss: 1338.9031\n",
      "Epoch 146/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1323.9944 - val_loss: 1294.8674\n",
      "Epoch 147/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1299.2382 - val_loss: 1330.6799\n",
      "Epoch 148/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1321.6270 - val_loss: 1290.9675\n",
      "Epoch 149/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1301.8374 - val_loss: 1276.1464\n",
      "Epoch 150/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1302.2365 - val_loss: 1305.6895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1314.3903 - val_loss: 1280.4269\n",
      "Epoch 152/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1314.8994 - val_loss: 1316.9221\n",
      "Epoch 153/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1307.4355 - val_loss: 1290.2885\n",
      "Epoch 154/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1305.2305 - val_loss: 1282.9838\n",
      "Epoch 155/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1294.4337 - val_loss: 1302.1539\n",
      "Epoch 156/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1311.1478 - val_loss: 1283.1184\n",
      "Epoch 157/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1318.8403 - val_loss: 1306.5072\n",
      "Epoch 158/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1296.1859 - val_loss: 1294.4530\n",
      "Epoch 159/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1302.6857 - val_loss: 1292.8075\n",
      "Epoch 160/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1278.6105 - val_loss: 1283.6821\n",
      "Epoch 161/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1304.8347 - val_loss: 1300.3662\n",
      "Epoch 162/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1285.4174 - val_loss: 1302.4932\n",
      "Epoch 163/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1296.0629 - val_loss: 1296.3579\n",
      "Epoch 164/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1290.3922 - val_loss: 1258.2527\n",
      "Epoch 165/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1298.8517 - val_loss: 1288.8158\n",
      "Epoch 166/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1292.0454 - val_loss: 1291.0239\n",
      "Epoch 167/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1304.7760 - val_loss: 1273.8853\n",
      "Epoch 168/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1291.9049 - val_loss: 1331.4778\n",
      "Epoch 169/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1285.0168 - val_loss: 1278.6761\n",
      "Epoch 170/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1282.2609 - val_loss: 1271.1174\n",
      "Epoch 171/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1275.3359 - val_loss: 1344.2909\n",
      "Epoch 172/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1289.5337 - val_loss: 1284.3589\n",
      "Epoch 173/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1270.5775 - val_loss: 1272.9943\n",
      "Epoch 174/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1305.0875 - val_loss: 1288.5923\n",
      "Epoch 175/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1293.2494 - val_loss: 1280.7771\n",
      "Epoch 176/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1277.0721 - val_loss: 1312.0797\n",
      "Epoch 177/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1270.8755 - val_loss: 1293.8281\n",
      "Epoch 178/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1263.0452 - val_loss: 1275.3776\n",
      "Epoch 179/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1298.8931 - val_loss: 1281.9761\n",
      "Epoch 180/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1298.6166 - val_loss: 1282.1001\n",
      "Epoch 181/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1282.2372 - val_loss: 1260.4590\n",
      "Epoch 182/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1276.2139 - val_loss: 1281.1655\n",
      "Epoch 183/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1257.2942 - val_loss: 1239.8783\n",
      "Epoch 184/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1275.6204 - val_loss: 1279.4944\n",
      "Epoch 185/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1273.1724 - val_loss: 1288.0493\n",
      "Epoch 186/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1265.3738 - val_loss: 1299.9999\n",
      "Epoch 187/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1276.5908 - val_loss: 1263.6096\n",
      "Epoch 188/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1278.7163 - val_loss: 1295.2972\n",
      "Epoch 189/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1253.7965 - val_loss: 1285.5978\n",
      "Epoch 190/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1277.3396 - val_loss: 1266.4448\n",
      "Epoch 191/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1273.7596 - val_loss: 1308.5885\n",
      "Epoch 192/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1249.1532 - val_loss: 1286.7050\n",
      "Epoch 193/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1270.4039 - val_loss: 1250.4424\n",
      "Epoch 194/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1275.1741 - val_loss: 1247.1626\n",
      "Epoch 195/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1261.6984 - val_loss: 1242.0410\n",
      "Epoch 196/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1271.1864 - val_loss: 1258.0104\n",
      "Epoch 197/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1251.3669 - val_loss: 1461.9958\n",
      "Epoch 198/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1252.4723 - val_loss: 1289.7448\n",
      "Epoch 199/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1266.1934 - val_loss: 1280.0865\n",
      "Epoch 200/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1239.3530 - val_loss: 1259.3157\n",
      "Epoch 201/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1252.3384 - val_loss: 1301.4838\n",
      "Epoch 202/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1236.5527 - val_loss: 1264.9161\n",
      "Epoch 203/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1252.0496 - val_loss: 1258.8849\n",
      "Epoch 204/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1246.2523 - val_loss: 1278.8215\n",
      "Epoch 205/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1261.8716 - val_loss: 1259.9014\n",
      "Epoch 206/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1245.1134 - val_loss: 1258.3090\n",
      "Epoch 207/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1240.8529 - val_loss: 1276.8735\n",
      "Epoch 208/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1238.4418 - val_loss: 1266.4927\n",
      "Epoch 209/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1246.4347 - val_loss: 1301.4503\n",
      "Epoch 210/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1259.4834 - val_loss: 1245.5131\n",
      "Epoch 211/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1234.1155 - val_loss: 1249.3805\n",
      "Epoch 212/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1215.4250 - val_loss: 1264.7153\n",
      "Epoch 213/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1230.7021 - val_loss: 1257.9832\n",
      "Epoch 214/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1229.3556 - val_loss: 1246.8984\n",
      "Epoch 215/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1239.6824 - val_loss: 1258.3015\n",
      "Epoch 216/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1229.2487 - val_loss: 1272.9579\n",
      "Epoch 217/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1232.7352 - val_loss: 1286.4583\n",
      "Epoch 218/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1227.5608 - val_loss: 1259.3090\n",
      "Epoch 219/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1225.3643 - val_loss: 1243.5676\n",
      "Epoch 220/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1230.9562 - val_loss: 1248.1892\n",
      "Epoch 221/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1230.9410 - val_loss: 1258.3914\n",
      "Epoch 222/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1231.9014 - val_loss: 1247.3781\n",
      "Epoch 223/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1210.4104 - val_loss: 1240.6737\n",
      "Epoch 224/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1227.5820 - val_loss: 1275.3916\n",
      "Epoch 225/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1215.4072 - val_loss: 1250.3707\n",
      "Epoch 226/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1235.3280 - val_loss: 1255.6965\n",
      "Epoch 227/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1232.2123 - val_loss: 1261.2830\n",
      "Epoch 228/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1231.6056 - val_loss: 1241.0620\n",
      "Epoch 229/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1226.2524 - val_loss: 1268.1559\n",
      "Epoch 230/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1230.1278 - val_loss: 1250.3052\n",
      "Epoch 231/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1220.3568 - val_loss: 1237.9407\n",
      "Epoch 232/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1229.2494 - val_loss: 1264.8180\n",
      "Epoch 233/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1218.2128 - val_loss: 1277.1129\n",
      "Epoch 234/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1211.2490 - val_loss: 1242.6072\n",
      "Epoch 235/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1220.7933 - val_loss: 1274.2347\n",
      "Epoch 236/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1208.7684 - val_loss: 1261.1113\n",
      "Epoch 237/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1212.9370 - val_loss: 1266.4011\n",
      "Epoch 238/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1227.5143 - val_loss: 1264.3132\n",
      "Epoch 239/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1221.7073 - val_loss: 1240.1970\n",
      "Epoch 240/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1208.5208 - val_loss: 1264.8160\n",
      "Epoch 241/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1206.3093 - val_loss: 1240.2734\n",
      "Epoch 242/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1211.6981 - val_loss: 1241.6545\n",
      "Epoch 243/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1208.0353 - val_loss: 1241.2500\n",
      "Epoch 244/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1214.8201 - val_loss: 1230.7749\n",
      "Epoch 245/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1202.9056 - val_loss: 1230.5326\n",
      "Epoch 246/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1207.7292 - val_loss: 1237.6393\n",
      "Epoch 247/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1206.2970 - val_loss: 1244.3180\n",
      "Epoch 248/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1206.5950 - val_loss: 1226.4211\n",
      "Epoch 249/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1207.2076 - val_loss: 1233.1533\n",
      "Epoch 250/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1216.4062 - val_loss: 1279.2795\n",
      "Epoch 251/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1202.3823 - val_loss: 1243.9252\n",
      "Epoch 252/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1198.8351 - val_loss: 1233.3201\n",
      "Epoch 253/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1198.6672 - val_loss: 1283.7755\n",
      "Epoch 254/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1184.7238 - val_loss: 1261.4784\n",
      "Epoch 255/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1207.6323 - val_loss: 1252.9531\n",
      "Epoch 256/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1185.9193 - val_loss: 1246.2281\n",
      "Epoch 257/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1183.4712 - val_loss: 1240.1525\n",
      "Epoch 258/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1207.5044 - val_loss: 1224.7152\n",
      "Epoch 259/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1186.4895 - val_loss: 1243.7759\n",
      "Epoch 260/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1189.2074 - val_loss: 1233.0270\n",
      "Epoch 261/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1180.7092 - val_loss: 1240.5422\n",
      "Epoch 262/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1195.6166 - val_loss: 1221.5061\n",
      "Epoch 263/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1194.6288 - val_loss: 1229.2731\n",
      "Epoch 264/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1202.8970 - val_loss: 1256.3662\n",
      "Epoch 265/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1194.2356 - val_loss: 1273.6703\n",
      "Epoch 266/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1187.2262 - val_loss: 1257.1754\n",
      "Epoch 267/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1192.6807 - val_loss: 1235.5414\n",
      "Epoch 268/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1179.3177 - val_loss: 1237.2351\n",
      "Epoch 269/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1177.8632 - val_loss: 1251.1947\n",
      "Epoch 270/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1181.2576 - val_loss: 1229.7275\n",
      "Epoch 271/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1185.1561 - val_loss: 1231.0309\n",
      "Epoch 272/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1179.2838 - val_loss: 1238.7064\n",
      "Epoch 273/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1196.7476 - val_loss: 1243.2556\n",
      "Epoch 274/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1182.7083 - val_loss: 1219.5464\n",
      "Epoch 275/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1184.8495 - val_loss: 1259.3582\n",
      "Epoch 276/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1188.8351 - val_loss: 1246.4622\n",
      "Epoch 277/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1189.9460 - val_loss: 1244.7883\n",
      "Epoch 278/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1176.8243 - val_loss: 1236.5629\n",
      "Epoch 279/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1179.5920 - val_loss: 1226.7656\n",
      "Epoch 280/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1194.1193 - val_loss: 1340.5226\n",
      "Epoch 281/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1168.4088 - val_loss: 1224.0499\n",
      "Epoch 282/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1181.8401 - val_loss: 1247.5107\n",
      "Epoch 283/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1166.4363 - val_loss: 1253.2711\n",
      "Epoch 284/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1180.3054 - val_loss: 1228.5369\n",
      "Epoch 285/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1161.4669 - val_loss: 1247.6002\n",
      "Epoch 286/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1171.5819 - val_loss: 1233.6970\n",
      "Epoch 287/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1185.0551 - val_loss: 1211.3289\n",
      "Epoch 288/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1154.7422 - val_loss: 1233.3442\n",
      "Epoch 289/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1170.5531 - val_loss: 1244.4204\n",
      "Epoch 290/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1156.3346 - val_loss: 1220.5669\n",
      "Epoch 291/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1164.2111 - val_loss: 1264.8795\n",
      "Epoch 292/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1153.7781 - val_loss: 1229.4305\n",
      "Epoch 293/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1170.2391 - val_loss: 1253.4836\n",
      "Epoch 294/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1157.4507 - val_loss: 1249.1744\n",
      "Epoch 295/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1152.6090 - val_loss: 1241.4481\n",
      "Epoch 296/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1152.7887 - val_loss: 1252.0715\n",
      "Epoch 297/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1155.1431 - val_loss: 1233.2914\n",
      "Epoch 298/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1157.7285 - val_loss: 1229.2559\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 2s 6ms/step - loss: 1160.7909 - val_loss: 1235.1514\n",
      "Epoch 300/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1154.0160 - val_loss: 1225.8862\n",
      "Epoch 301/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1146.8965 - val_loss: 1253.8157\n",
      "Epoch 302/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1160.6135 - val_loss: 1215.3157\n",
      "Epoch 303/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1144.2740 - val_loss: 1230.1300\n",
      "Epoch 304/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1162.3385 - val_loss: 1223.0542\n",
      "Epoch 305/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1144.8357 - val_loss: 1253.9814\n",
      "Epoch 306/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1155.7452 - val_loss: 1220.7239\n",
      "Epoch 307/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1161.3015 - val_loss: 1242.8016\n",
      "Epoch 308/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1158.7197 - val_loss: 1207.9078\n",
      "Epoch 309/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1161.5558 - val_loss: 1218.6375\n",
      "Epoch 310/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1154.9625 - val_loss: 1238.6803\n",
      "Epoch 311/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1153.0137 - val_loss: 1224.2430\n",
      "Epoch 312/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1154.4874 - val_loss: 1272.8945\n",
      "Epoch 313/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1155.4661 - val_loss: 1235.1578\n",
      "Epoch 314/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1155.5867 - val_loss: 1252.4186\n",
      "Epoch 315/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1140.4442 - val_loss: 1228.1703\n",
      "Epoch 316/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1133.2362 - val_loss: 1235.1776\n",
      "Epoch 317/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1149.9796 - val_loss: 1244.1594\n",
      "Epoch 318/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1137.1649 - val_loss: 1230.8711\n",
      "Epoch 319/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1137.8792 - val_loss: 1258.3306\n",
      "Epoch 320/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1150.4117 - val_loss: 1242.2417\n",
      "Epoch 321/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1151.5690 - val_loss: 1225.7152\n",
      "Epoch 322/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1145.8337 - val_loss: 1234.6366\n",
      "Epoch 323/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1141.6984 - val_loss: 1243.7507\n",
      "Epoch 324/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1153.8082 - val_loss: 1218.4825\n",
      "Epoch 325/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1142.4910 - val_loss: 1240.2401\n",
      "Epoch 326/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1134.8372 - val_loss: 1228.3885\n",
      "Epoch 327/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1146.7234 - val_loss: 1248.3435\n",
      "Epoch 328/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1141.4830 - val_loss: 1228.8414\n",
      "Epoch 329/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1138.2422 - val_loss: 1220.9589\n",
      "Epoch 330/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1127.4315 - val_loss: 1236.3516\n",
      "Epoch 331/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1128.2693 - val_loss: 1229.7719\n",
      "Epoch 332/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1138.3228 - val_loss: 1224.8473\n",
      "Epoch 333/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1135.9963 - val_loss: 1241.4083\n",
      "Epoch 334/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1131.3289 - val_loss: 1245.0425\n",
      "Epoch 335/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1124.8151 - val_loss: 1236.4921\n",
      "Epoch 336/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1134.5455 - val_loss: 1249.3229\n",
      "Epoch 337/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1116.7866 - val_loss: 1231.1914\n",
      "Epoch 338/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1140.7842 - val_loss: 1226.0380\n",
      "Epoch 339/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1143.5795 - val_loss: 1248.4305\n",
      "Epoch 340/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1142.6470 - val_loss: 1241.9694\n",
      "Epoch 341/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1129.7562 - val_loss: 1215.6720\n",
      "Epoch 342/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1141.9777 - val_loss: 1228.3960\n",
      "Epoch 343/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1126.9988 - val_loss: 1236.5326\n",
      "Epoch 344/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1133.3027 - val_loss: 1224.5929\n",
      "Epoch 345/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1122.9957 - val_loss: 1228.2241\n",
      "Epoch 346/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1116.2181 - val_loss: 1217.5132\n",
      "Epoch 347/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1138.8051 - val_loss: 1256.4941\n",
      "Epoch 348/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1113.7023 - val_loss: 1215.8838\n",
      "Epoch 349/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1116.8892 - val_loss: 1245.1447\n",
      "Epoch 350/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1119.1884 - val_loss: 1228.2134\n",
      "Epoch 351/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1123.1147 - val_loss: 1226.3590\n",
      "Epoch 352/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1119.7080 - val_loss: 1233.1774\n",
      "Epoch 353/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1126.7686 - val_loss: 1222.0658\n",
      "Epoch 354/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1123.7667 - val_loss: 1238.0858\n",
      "Epoch 355/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1119.1239 - val_loss: 1269.5151\n",
      "Epoch 356/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1118.9674 - val_loss: 1211.9539\n",
      "Epoch 357/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1114.5823 - val_loss: 1239.4691\n",
      "Epoch 358/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1135.4594 - val_loss: 1218.9950\n",
      "Epoch 359/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1111.3853 - val_loss: 1227.6681\n",
      "Epoch 360/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1130.6332 - val_loss: 1222.7823\n",
      "Epoch 361/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1115.8378 - val_loss: 1270.6346\n",
      "Epoch 362/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1118.5824 - val_loss: 1231.5669\n",
      "Epoch 363/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1113.2260 - val_loss: 1240.2057\n",
      "Epoch 364/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1120.1150 - val_loss: 1245.6194\n",
      "Epoch 365/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1100.5317 - val_loss: 1228.4984\n",
      "Epoch 366/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1132.6322 - val_loss: 1203.3131\n",
      "Epoch 367/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1118.7495 - val_loss: 1206.0934\n",
      "Epoch 368/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1117.2631 - val_loss: 1227.4496\n",
      "Epoch 369/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1114.7419 - val_loss: 1239.4139\n",
      "Epoch 370/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1108.4009 - val_loss: 1250.3844\n",
      "Epoch 371/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1110.8033 - val_loss: 1256.1293\n",
      "Epoch 372/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1116.6504 - val_loss: 1233.7705\n",
      "Epoch 373/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1117.9261 - val_loss: 1237.3796\n",
      "Epoch 374/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1111.5537 - val_loss: 1229.0128\n",
      "Epoch 375/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1116.9436 - val_loss: 1234.1871\n",
      "Epoch 376/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1103.8633 - val_loss: 1225.7832\n",
      "Epoch 377/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1115.9304 - val_loss: 1236.6079\n",
      "Epoch 378/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1110.2350 - val_loss: 1214.6241\n",
      "Epoch 379/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1094.1997 - val_loss: 1207.8406\n",
      "Epoch 380/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1105.7736 - val_loss: 1222.6674\n",
      "Epoch 381/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1108.9454 - val_loss: 1235.8497\n",
      "Epoch 382/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1115.3489 - val_loss: 1218.8977\n",
      "Epoch 383/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1097.7280 - val_loss: 1227.6842\n",
      "Epoch 384/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1107.7607 - val_loss: 1210.5988\n",
      "Epoch 385/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1095.7856 - val_loss: 1231.6729\n",
      "Epoch 386/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1118.1820 - val_loss: 1256.1136\n",
      "Epoch 387/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1103.7163 - val_loss: 1214.7285\n",
      "Epoch 388/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1105.2357 - val_loss: 1216.5055\n",
      "Epoch 389/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1104.6031 - val_loss: 1223.0200\n",
      "Epoch 390/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1092.2070 - val_loss: 1252.3660\n",
      "Epoch 391/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1099.6394 - val_loss: 1208.2185\n",
      "Epoch 392/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1099.0786 - val_loss: 1285.5044\n",
      "Epoch 393/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1112.9332 - val_loss: 1215.0536\n",
      "Epoch 394/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1099.6487 - val_loss: 1240.1198\n",
      "Epoch 395/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1108.3580 - val_loss: 1259.1648\n",
      "Epoch 396/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1082.3584 - val_loss: 1250.5750\n",
      "Epoch 397/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1097.1362 - val_loss: 1247.3047\n",
      "Epoch 398/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1084.6022 - val_loss: 1247.3691\n",
      "Epoch 399/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1101.2461 - val_loss: 1237.3110\n",
      "Epoch 400/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1100.4009 - val_loss: 1195.5935\n",
      "Epoch 401/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1087.9579 - val_loss: 1226.5925\n",
      "Epoch 402/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1102.2672 - val_loss: 1263.3220\n",
      "Epoch 403/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1101.7396 - val_loss: 1235.7504\n",
      "Epoch 404/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1089.6318 - val_loss: 1233.6345\n",
      "Epoch 405/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1080.0885 - val_loss: 1238.5864\n",
      "Epoch 406/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1099.1111 - val_loss: 1233.6348\n",
      "Epoch 407/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1096.0948 - val_loss: 1271.0498\n",
      "Epoch 408/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1088.8474 - val_loss: 1226.4229\n",
      "Epoch 409/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1098.5095 - val_loss: 1237.7845\n",
      "Epoch 410/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1088.2250 - val_loss: 1238.6180\n",
      "Epoch 411/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1095.9701 - val_loss: 1236.9337\n",
      "Epoch 412/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1094.3711 - val_loss: 1221.7964\n",
      "Epoch 413/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1077.4235 - val_loss: 1251.6823\n",
      "Epoch 414/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1077.0747 - val_loss: 1251.3218\n",
      "Epoch 415/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1094.4222 - val_loss: 1229.1346\n",
      "Epoch 416/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1094.6541 - val_loss: 1240.6575\n",
      "Epoch 417/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1080.1064 - val_loss: 1240.1335\n",
      "Epoch 418/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1076.2799 - val_loss: 1231.1387\n",
      "Epoch 419/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1075.4844 - val_loss: 1237.1028\n",
      "Epoch 420/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1082.0793 - val_loss: 1227.0793\n",
      "Epoch 421/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1092.8588 - val_loss: 1244.4735\n",
      "Epoch 422/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1089.1157 - val_loss: 1228.4504\n",
      "Epoch 423/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1099.8275 - val_loss: 1218.6876\n",
      "Epoch 424/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1082.2078 - val_loss: 1235.4662\n",
      "Epoch 425/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1068.0447 - val_loss: 1229.8508\n",
      "Epoch 426/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1074.8912 - val_loss: 1216.7799\n",
      "Epoch 427/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1094.4915 - val_loss: 1271.9565\n",
      "Epoch 428/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1087.9048 - val_loss: 1223.5707\n",
      "Epoch 429/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1073.7728 - val_loss: 1211.8947\n",
      "Epoch 430/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1093.7444 - val_loss: 1224.4987\n",
      "Epoch 431/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1075.6041 - val_loss: 1206.2679\n",
      "Epoch 432/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1071.8301 - val_loss: 1206.1831\n",
      "Epoch 433/1000\n",
      "268/268 [==============================] - 1s 6ms/step - loss: 1068.6549 - val_loss: 1234.1824\n",
      "Epoch 434/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1087.2087 - val_loss: 1233.0009\n",
      "Epoch 435/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1078.7793 - val_loss: 1244.0654\n",
      "Epoch 436/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1071.6919 - val_loss: 1230.2148\n",
      "Epoch 437/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1075.2561 - val_loss: 1222.9677\n",
      "Epoch 438/1000\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 1072.3234 - val_loss: 1213.0009\n",
      "Epoch 439/1000\n",
      "268/268 [==============================] - 2s 6ms/step - loss: 1080.5585 - val_loss: 1193.4731\n",
      "Epoch 440/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1087.2545 - val_loss: 1215.9705\n",
      "Epoch 441/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1063.7133 - val_loss: 1214.2462\n",
      "Epoch 442/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1077.6732 - val_loss: 1234.2688\n",
      "Epoch 443/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1081.2177 - val_loss: 1204.8751\n",
      "Epoch 444/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1075.4910 - val_loss: 1209.7883\n",
      "Epoch 445/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1065.9857 - val_loss: 1213.7500\n",
      "Epoch 446/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1070.9135 - val_loss: 1219.4175\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 3ms/step - loss: 1063.3757 - val_loss: 1222.9484\n",
      "Epoch 448/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1085.2598 - val_loss: 1211.0660\n",
      "Epoch 449/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1076.1508 - val_loss: 1234.0566\n",
      "Epoch 450/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1080.4440 - val_loss: 1232.1355\n",
      "Epoch 451/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1069.7788 - val_loss: 1218.0880\n",
      "Epoch 452/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1059.8292 - val_loss: 1232.5684\n",
      "Epoch 453/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1066.3423 - val_loss: 1223.8420\n",
      "Epoch 454/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1080.9681 - val_loss: 1195.5686\n",
      "Epoch 455/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1070.6661 - val_loss: 1206.9263\n",
      "Epoch 456/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1067.8457 - val_loss: 1214.2511\n",
      "Epoch 457/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1064.5383 - val_loss: 1240.6158\n",
      "Epoch 458/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1066.0510 - val_loss: 1215.3346\n",
      "Epoch 459/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1056.8748 - val_loss: 1224.2363\n",
      "Epoch 460/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1057.2797 - val_loss: 1217.2379\n",
      "Epoch 461/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1064.1959 - val_loss: 1236.2576\n",
      "Epoch 462/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1064.5140 - val_loss: 1244.3091\n",
      "Epoch 463/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1067.3024 - val_loss: 1225.7897\n",
      "Epoch 464/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1077.3510 - val_loss: 1222.5315\n",
      "Epoch 465/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1059.6637 - val_loss: 1240.4197\n",
      "Epoch 466/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1067.3638 - val_loss: 1214.4443\n",
      "Epoch 467/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1082.3363 - val_loss: 1223.6461\n",
      "Epoch 468/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1069.6403 - val_loss: 1201.9695\n",
      "Epoch 469/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1054.5323 - val_loss: 1223.9227\n",
      "Epoch 470/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1060.9574 - val_loss: 1213.9629\n",
      "Epoch 471/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1060.0073 - val_loss: 1199.9769\n",
      "Epoch 472/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1073.2422 - val_loss: 1218.3243\n",
      "Epoch 473/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1071.5731 - val_loss: 1212.6057\n",
      "Epoch 474/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1074.6832 - val_loss: 1223.8368\n",
      "Epoch 475/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1059.9445 - val_loss: 1195.5468\n",
      "Epoch 476/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1062.5203 - val_loss: 1232.3348\n",
      "Epoch 477/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1057.8612 - val_loss: 1240.8092\n",
      "Epoch 478/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1055.8134 - val_loss: 1222.9266\n",
      "Epoch 479/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1048.2242 - val_loss: 1218.9263\n",
      "Epoch 480/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1063.4169 - val_loss: 1239.2196\n",
      "Epoch 481/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1063.8281 - val_loss: 1211.8274\n",
      "Epoch 482/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1051.7040 - val_loss: 1232.6476\n",
      "Epoch 483/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1051.4828 - val_loss: 1222.2483\n",
      "Epoch 484/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1063.1270 - val_loss: 1245.0378\n",
      "Epoch 485/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1066.1204 - val_loss: 1221.8312\n",
      "Epoch 486/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1049.5706 - val_loss: 1227.7926\n",
      "Epoch 487/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1061.0491 - val_loss: 1245.4712\n",
      "Epoch 488/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1050.0254 - val_loss: 1246.5179\n",
      "Epoch 489/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1058.9580 - val_loss: 1226.1256\n",
      "Epoch 490/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1042.3917 - val_loss: 1238.6847\n",
      "Epoch 491/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1048.5320 - val_loss: 1216.7876\n",
      "Epoch 492/1000\n",
      "268/268 [==============================] - ETA: 0s - loss: 1052.78 - 1s 3ms/step - loss: 1052.6736 - val_loss: 1229.3754\n",
      "Epoch 493/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1061.1938 - val_loss: 1239.6586\n",
      "Epoch 494/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1063.0601 - val_loss: 1236.5645\n",
      "Epoch 495/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1043.0099 - val_loss: 1214.4810\n",
      "Epoch 496/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1039.9297 - val_loss: 1234.5875\n",
      "Epoch 497/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1053.3506 - val_loss: 1216.0886\n",
      "Epoch 498/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1043.7889 - val_loss: 1211.8771\n",
      "Epoch 499/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1057.4470 - val_loss: 1208.5405\n",
      "Epoch 500/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1033.3118 - val_loss: 1267.5114\n",
      "Epoch 501/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1034.6211 - val_loss: 1231.3145\n",
      "Epoch 502/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1073.0166 - val_loss: 1198.8153\n",
      "Epoch 503/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1046.9977 - val_loss: 1212.4894\n",
      "Epoch 504/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1036.3439 - val_loss: 1241.5837\n",
      "Epoch 505/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1058.2748 - val_loss: 1243.0127\n",
      "Epoch 506/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1058.2516 - val_loss: 1234.5961\n",
      "Epoch 507/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1061.8867 - val_loss: 1232.6401\n",
      "Epoch 508/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1032.6868 - val_loss: 1248.5535\n",
      "Epoch 509/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1048.4791 - val_loss: 1225.5740\n",
      "Epoch 510/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1040.4034 - val_loss: 1234.1086\n",
      "Epoch 511/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1048.3413 - val_loss: 1244.4136\n",
      "Epoch 512/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1042.7388 - val_loss: 1237.4883\n",
      "Epoch 513/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1047.7889 - val_loss: 1219.1696\n",
      "Epoch 514/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1045.8184 - val_loss: 1237.0388\n",
      "Epoch 515/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1048.8182 - val_loss: 1212.9645\n",
      "Epoch 516/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1031.0614 - val_loss: 1214.2817\n",
      "Epoch 517/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1026.9603 - val_loss: 1226.0204\n",
      "Epoch 518/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1031.9314 - val_loss: 1228.0731\n",
      "Epoch 519/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1036.2952 - val_loss: 1245.2887\n",
      "Epoch 520/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1047.0824 - val_loss: 1193.3370\n",
      "Epoch 521/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1033.4528 - val_loss: 1220.2683\n",
      "Epoch 522/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1043.0968 - val_loss: 1226.3480\n",
      "Epoch 523/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1047.4489 - val_loss: 1230.2839\n",
      "Epoch 524/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1037.3213 - val_loss: 1243.7822\n",
      "Epoch 525/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1035.3517 - val_loss: 1226.4845\n",
      "Epoch 526/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1035.2428 - val_loss: 1212.3073\n",
      "Epoch 527/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1032.5067 - val_loss: 1233.2765\n",
      "Epoch 528/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1040.0831 - val_loss: 1241.5078\n",
      "Epoch 529/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1050.8527 - val_loss: 1219.7853\n",
      "Epoch 530/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1034.9419 - val_loss: 1217.2515\n",
      "Epoch 531/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1029.8353 - val_loss: 1228.8347\n",
      "Epoch 532/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1048.8054 - val_loss: 1223.3275\n",
      "Epoch 533/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1039.1084 - val_loss: 1221.4940\n",
      "Epoch 534/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1058.6791 - val_loss: 1222.0267\n",
      "Epoch 535/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1045.3513 - val_loss: 1212.8677\n",
      "Epoch 536/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1040.8525 - val_loss: 1234.0601\n",
      "Epoch 537/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1033.0615 - val_loss: 1223.2953\n",
      "Epoch 538/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1029.7961 - val_loss: 1216.7880\n",
      "Epoch 539/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1036.3073 - val_loss: 1232.6420\n",
      "Epoch 540/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1029.7852 - val_loss: 1252.1940\n",
      "Epoch 541/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1017.0234 - val_loss: 1254.4071\n",
      "Epoch 542/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1041.1373 - val_loss: 1232.7859\n",
      "Epoch 543/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1042.5057 - val_loss: 1235.2935\n",
      "Epoch 544/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1039.1948 - val_loss: 1228.4530\n",
      "Epoch 545/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1021.9081 - val_loss: 1203.4364\n",
      "Epoch 546/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1020.9138 - val_loss: 1233.0577\n",
      "Epoch 547/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1042.8932 - val_loss: 1236.2216\n",
      "Epoch 548/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1043.1619 - val_loss: 1246.1501\n",
      "Epoch 549/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1034.2034 - val_loss: 1215.1974\n",
      "Epoch 550/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1040.7538 - val_loss: 1219.0851\n",
      "Epoch 551/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1018.7424 - val_loss: 1260.7856\n",
      "Epoch 552/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1030.9185 - val_loss: 1207.2097\n",
      "Epoch 553/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1031.9045 - val_loss: 1204.5134\n",
      "Epoch 554/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1020.8781 - val_loss: 1208.2688\n",
      "Epoch 555/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1041.6145 - val_loss: 1226.6804\n",
      "Epoch 556/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1028.5310 - val_loss: 1232.2294\n",
      "Epoch 557/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1034.7648 - val_loss: 1227.9558\n",
      "Epoch 558/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1017.1013 - val_loss: 1240.0308\n",
      "Epoch 559/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1024.9434 - val_loss: 1233.4441\n",
      "Epoch 560/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1023.9524 - val_loss: 1227.2239\n",
      "Epoch 561/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1021.6357 - val_loss: 1251.4233\n",
      "Epoch 562/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1030.6703 - val_loss: 1267.6311\n",
      "Epoch 563/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1009.9950 - val_loss: 1245.2211\n",
      "Epoch 564/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1023.5275 - val_loss: 1223.3627\n",
      "Epoch 565/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1033.0345 - val_loss: 1239.4368\n",
      "Epoch 566/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1032.8196 - val_loss: 1227.1848\n",
      "Epoch 567/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1018.0900 - val_loss: 1248.8600\n",
      "Epoch 568/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1016.7112 - val_loss: 1221.3531\n",
      "Epoch 569/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1028.9772 - val_loss: 1249.4312\n",
      "Epoch 570/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1047.2568 - val_loss: 1222.7415\n",
      "Epoch 571/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1014.9718 - val_loss: 1214.9950\n",
      "Epoch 572/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1029.3721 - val_loss: 1238.1531\n",
      "Epoch 573/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1008.4835 - val_loss: 1263.1527\n",
      "Epoch 574/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1027.6443 - val_loss: 1241.1270\n",
      "Epoch 575/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1030.4271 - val_loss: 1228.7661\n",
      "Epoch 576/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1032.6006 - val_loss: 1235.7981\n",
      "Epoch 577/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1025.3994 - val_loss: 1223.5894\n",
      "Epoch 578/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1019.0968 - val_loss: 1240.8829\n",
      "Epoch 579/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1013.1417 - val_loss: 1227.3098\n",
      "Epoch 580/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1022.3424 - val_loss: 1233.7057\n",
      "Epoch 581/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1012.1840 - val_loss: 1243.0735\n",
      "Epoch 582/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1008.2460 - val_loss: 1251.8152\n",
      "Epoch 583/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1018.9443 - val_loss: 1236.0763\n",
      "Epoch 584/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1032.3405 - val_loss: 1246.7789\n",
      "Epoch 585/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1021.3332 - val_loss: 1226.2019\n",
      "Epoch 586/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1022.3360 - val_loss: 1259.9867\n",
      "Epoch 587/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1014.6686 - val_loss: 1220.1249\n",
      "Epoch 588/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1010.9001 - val_loss: 1241.7220\n",
      "Epoch 589/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1011.1461 - val_loss: 1228.5649\n",
      "Epoch 590/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1017.8983 - val_loss: 1245.6472\n",
      "Epoch 591/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1013.1456 - val_loss: 1219.3722\n",
      "Epoch 592/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1030.7939 - val_loss: 1232.2687\n",
      "Epoch 593/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1009.1417 - val_loss: 1234.0509\n",
      "Epoch 594/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1003.0432 - val_loss: 1267.7900\n",
      "Epoch 595/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 4ms/step - loss: 1021.6529 - val_loss: 1216.4487\n",
      "Epoch 596/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1020.7752 - val_loss: 1246.8090\n",
      "Epoch 597/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1006.5392 - val_loss: 1266.6534\n",
      "Epoch 598/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1010.9409 - val_loss: 1230.6354\n",
      "Epoch 599/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1009.2510 - val_loss: 1262.2821\n",
      "Epoch 600/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1013.2780 - val_loss: 1241.4087\n",
      "Epoch 601/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1008.9460 - val_loss: 1224.4415\n",
      "Epoch 602/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1013.2313 - val_loss: 1226.7764\n",
      "Epoch 603/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1001.5063 - val_loss: 1247.5260\n",
      "Epoch 604/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1004.9763 - val_loss: 1250.2443\n",
      "Epoch 605/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1018.3375 - val_loss: 1231.7720\n",
      "Epoch 606/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1011.2581 - val_loss: 1250.1553\n",
      "Epoch 607/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 996.4618 - val_loss: 1262.9919\n",
      "Epoch 608/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1014.4175 - val_loss: 1213.3899\n",
      "Epoch 609/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1022.9233 - val_loss: 1233.4155\n",
      "Epoch 610/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1009.5049 - val_loss: 1242.2937\n",
      "Epoch 611/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1016.6076 - val_loss: 1267.9452\n",
      "Epoch 612/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1017.8622 - val_loss: 1226.9908\n",
      "Epoch 613/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1007.7658 - val_loss: 1239.9398\n",
      "Epoch 614/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 993.4080 - val_loss: 1241.1831\n",
      "Epoch 615/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1002.5608 - val_loss: 1261.3556\n",
      "Epoch 616/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1006.0153 - val_loss: 1257.2494\n",
      "Epoch 617/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1006.5189 - val_loss: 1237.3060\n",
      "Epoch 618/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1005.3498 - val_loss: 1260.4362\n",
      "Epoch 619/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1002.3970 - val_loss: 1236.3505\n",
      "Epoch 620/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1012.1467 - val_loss: 1247.2458\n",
      "Epoch 621/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1003.6650 - val_loss: 1227.0681\n",
      "Epoch 622/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1020.4182 - val_loss: 1223.2949\n",
      "Epoch 623/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 998.4689 - val_loss: 1230.8168\n",
      "Epoch 624/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 998.1637 - val_loss: 1234.3140\n",
      "Epoch 625/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 994.7529 - val_loss: 1281.3666\n",
      "Epoch 626/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1008.4285 - val_loss: 1250.1501\n",
      "Epoch 627/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1000.5936 - val_loss: 1208.6100\n",
      "Epoch 628/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1014.2570 - val_loss: 1207.6791\n",
      "Epoch 629/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1002.6125 - val_loss: 1216.6865\n",
      "Epoch 630/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 996.7305 - val_loss: 1205.4220\n",
      "Epoch 631/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1009.1240 - val_loss: 1202.5110\n",
      "Epoch 632/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1006.3110 - val_loss: 1230.0201\n",
      "Epoch 633/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 1004.5418 - val_loss: 1226.1108\n",
      "Epoch 634/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1022.7401 - val_loss: 1230.9535\n",
      "Epoch 635/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 998.5029 - val_loss: 1224.5468\n",
      "Epoch 636/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 993.2531 - val_loss: 1249.6194\n",
      "Epoch 637/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1004.8804 - val_loss: 1265.5151\n",
      "Epoch 638/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 998.6307 - val_loss: 1237.4545\n",
      "Epoch 639/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 986.3090 - val_loss: 1221.3885\n",
      "Epoch 640/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 995.5145 - val_loss: 1225.6782\n",
      "Epoch 641/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 999.6363 - val_loss: 1237.2457\n",
      "Epoch 642/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1015.2083 - val_loss: 1226.2729\n",
      "Epoch 643/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1005.4906 - val_loss: 1209.0366\n",
      "Epoch 644/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 997.7589 - val_loss: 1227.1157\n",
      "Epoch 645/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1009.1987 - val_loss: 1230.5234\n",
      "Epoch 646/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 996.1662 - val_loss: 1200.9045\n",
      "Epoch 647/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1003.9808 - val_loss: 1220.0358\n",
      "Epoch 648/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1000.0685 - val_loss: 1225.4354\n",
      "Epoch 649/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 998.1526 - val_loss: 1261.8729\n",
      "Epoch 650/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 996.9918 - val_loss: 1201.0475\n",
      "Epoch 651/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1013.2050 - val_loss: 1216.3081\n",
      "Epoch 652/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 994.8306 - val_loss: 1254.9274\n",
      "Epoch 653/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 999.3177 - val_loss: 1233.8918\n",
      "Epoch 654/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1009.1444 - val_loss: 1257.1348\n",
      "Epoch 655/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 982.7136 - val_loss: 1252.9115\n",
      "Epoch 656/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1004.7466 - val_loss: 1209.8794\n",
      "Epoch 657/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 990.4887 - val_loss: 1257.2169\n",
      "Epoch 658/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1005.3870 - val_loss: 1251.0696\n",
      "Epoch 659/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 1008.7657 - val_loss: 1247.3400\n",
      "Epoch 660/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 979.7827 - val_loss: 1234.8746\n",
      "Epoch 661/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 988.3008 - val_loss: 1221.1195\n",
      "Epoch 662/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 988.3437 - val_loss: 1226.7798\n",
      "Epoch 663/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 989.9149 - val_loss: 1223.6219\n",
      "Epoch 664/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 992.7797 - val_loss: 1201.0239\n",
      "Epoch 665/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 988.6606 - val_loss: 1240.4011\n",
      "Epoch 666/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1003.0893 - val_loss: 1253.6696\n",
      "Epoch 667/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 991.7515 - val_loss: 1252.8231\n",
      "Epoch 668/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 987.6325 - val_loss: 1248.2399\n",
      "Epoch 669/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 983.3096 - val_loss: 1225.8208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 670/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 986.9482 - val_loss: 1241.9916\n",
      "Epoch 671/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 996.5451 - val_loss: 1240.2114\n",
      "Epoch 672/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 990.2162 - val_loss: 1234.0968\n",
      "Epoch 673/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 992.5206 - val_loss: 1254.5394\n",
      "Epoch 674/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1000.7878 - val_loss: 1224.8020\n",
      "Epoch 675/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1005.4679 - val_loss: 1215.2864\n",
      "Epoch 676/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 987.0297 - val_loss: 1252.2461\n",
      "Epoch 677/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 979.4286 - val_loss: 1239.9934\n",
      "Epoch 678/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 986.3403 - val_loss: 1222.8806\n",
      "Epoch 679/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1005.3531 - val_loss: 1274.6375\n",
      "Epoch 680/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 979.0414 - val_loss: 1275.9071\n",
      "Epoch 681/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1005.2020 - val_loss: 1243.6141\n",
      "Epoch 682/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 993.9023 - val_loss: 1242.6921\n",
      "Epoch 683/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 997.6702 - val_loss: 1226.4236\n",
      "Epoch 684/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 994.8295 - val_loss: 1243.7843\n",
      "Epoch 685/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 995.6350 - val_loss: 1244.3468\n",
      "Epoch 686/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 991.3163 - val_loss: 1232.0115\n",
      "Epoch 687/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 991.2329 - val_loss: 1221.7417\n",
      "Epoch 688/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1012.3650 - val_loss: 1227.6771\n",
      "Epoch 689/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 973.5259 - val_loss: 1215.2097\n",
      "Epoch 690/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 990.2810 - val_loss: 1218.4148\n",
      "Epoch 691/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 984.6293 - val_loss: 1251.9480\n",
      "Epoch 692/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 971.4375 - val_loss: 1288.8370\n",
      "Epoch 693/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 977.1612 - val_loss: 1259.6537\n",
      "Epoch 694/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 986.8200 - val_loss: 1249.0952\n",
      "Epoch 695/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 987.1842 - val_loss: 1252.1663\n",
      "Epoch 696/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 989.0295 - val_loss: 1243.3845\n",
      "Epoch 697/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 975.1801 - val_loss: 1245.2859\n",
      "Epoch 698/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 989.7977 - val_loss: 1239.2615\n",
      "Epoch 699/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 989.3950 - val_loss: 1229.0839\n",
      "Epoch 700/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 988.9153 - val_loss: 1231.5568\n",
      "Epoch 701/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 984.8298 - val_loss: 1210.0813\n",
      "Epoch 702/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 990.8958 - val_loss: 1225.5406\n",
      "Epoch 703/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 980.0370 - val_loss: 1253.2253\n",
      "Epoch 704/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 986.1106 - val_loss: 1231.0989\n",
      "Epoch 705/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 975.6658 - val_loss: 1254.2146\n",
      "Epoch 706/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 978.2739 - val_loss: 1251.5276\n",
      "Epoch 707/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 972.9617 - val_loss: 1260.9058\n",
      "Epoch 708/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 987.1226 - val_loss: 1225.5482\n",
      "Epoch 709/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 1003.3163 - val_loss: 1235.0164\n",
      "Epoch 710/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 977.8161 - val_loss: 1236.4236\n",
      "Epoch 711/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 980.8684 - val_loss: 1231.8234\n",
      "Epoch 712/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 970.9464 - val_loss: 1271.2582\n",
      "Epoch 713/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 976.5835 - val_loss: 1250.6854\n",
      "Epoch 714/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 985.2457 - val_loss: 1230.3717\n",
      "Epoch 715/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 975.0916 - val_loss: 1247.8479\n",
      "Epoch 716/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 994.3879 - val_loss: 1227.2429\n",
      "Epoch 717/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 968.0126 - val_loss: 1248.6215\n",
      "Epoch 718/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 992.3250 - val_loss: 1231.7910\n",
      "Epoch 719/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 978.3630 - val_loss: 1217.5375\n",
      "Epoch 720/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 970.6515 - val_loss: 1226.6735\n",
      "Epoch 721/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 974.1520 - val_loss: 1240.4534\n",
      "Epoch 722/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 961.9939 - val_loss: 1249.5903\n",
      "Epoch 723/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 967.6282 - val_loss: 1290.4358\n",
      "Epoch 724/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 973.3538 - val_loss: 1247.0773\n",
      "Epoch 725/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 980.3137 - val_loss: 1273.3347\n",
      "Epoch 726/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 975.9270 - val_loss: 1263.1666\n",
      "Epoch 727/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 967.6899 - val_loss: 1245.8942\n",
      "Epoch 728/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 962.8485 - val_loss: 1246.3486\n",
      "Epoch 729/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 974.8859 - val_loss: 1250.1117\n",
      "Epoch 730/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 970.6344 - val_loss: 1247.8872\n",
      "Epoch 731/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 982.1049 - val_loss: 1256.7684\n",
      "Epoch 732/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 971.5790 - val_loss: 1225.9100\n",
      "Epoch 733/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 961.1931 - val_loss: 1247.8713\n",
      "Epoch 734/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 982.3342 - val_loss: 1235.5040\n",
      "Epoch 735/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 963.8774 - val_loss: 1238.4150\n",
      "Epoch 736/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 965.9604 - val_loss: 1245.6848\n",
      "Epoch 737/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 974.4283 - val_loss: 1231.1886\n",
      "Epoch 738/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 982.7450 - val_loss: 1239.6884\n",
      "Epoch 739/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 964.6825 - val_loss: 1253.0908\n",
      "Epoch 740/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 972.0281 - val_loss: 1236.4789\n",
      "Epoch 741/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 964.4944 - val_loss: 1254.1646\n",
      "Epoch 742/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 965.0794 - val_loss: 1245.3490\n",
      "Epoch 743/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 970.2842 - val_loss: 1249.7900\n",
      "Epoch 744/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 964.0192 - val_loss: 1263.7605\n",
      "Epoch 745/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 3ms/step - loss: 962.0128 - val_loss: 1256.3419\n",
      "Epoch 746/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 975.2543 - val_loss: 1244.4786\n",
      "Epoch 747/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 978.7561 - val_loss: 1210.3678\n",
      "Epoch 748/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 977.3333 - val_loss: 1229.3494\n",
      "Epoch 749/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 965.0333 - val_loss: 1236.4379\n",
      "Epoch 750/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 955.1818 - val_loss: 1277.9316\n",
      "Epoch 751/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 956.7241 - val_loss: 1276.6899\n",
      "Epoch 752/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 955.6743 - val_loss: 1235.6847\n",
      "Epoch 753/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 961.6675 - val_loss: 1219.2532\n",
      "Epoch 754/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 972.9249 - val_loss: 1230.1783\n",
      "Epoch 755/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 961.1758 - val_loss: 1252.9055\n",
      "Epoch 756/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 975.6469 - val_loss: 1257.9991\n",
      "Epoch 757/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 975.2969 - val_loss: 1251.1331\n",
      "Epoch 758/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 983.8640 - val_loss: 1262.0436\n",
      "Epoch 759/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 980.3126 - val_loss: 1253.4338\n",
      "Epoch 760/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 960.5402 - val_loss: 1262.0126\n",
      "Epoch 761/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 964.1931 - val_loss: 1261.5076\n",
      "Epoch 762/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 968.1994 - val_loss: 1252.3922\n",
      "Epoch 763/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 966.4669 - val_loss: 1248.9567\n",
      "Epoch 764/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 963.5273 - val_loss: 1223.6406\n",
      "Epoch 765/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 958.4908 - val_loss: 1244.2039\n",
      "Epoch 766/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 957.5745 - val_loss: 1280.1760\n",
      "Epoch 767/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 958.6721 - val_loss: 1241.6982\n",
      "Epoch 768/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 970.8028 - val_loss: 1239.8369\n",
      "Epoch 769/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 957.4072 - val_loss: 1266.1085\n",
      "Epoch 770/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 968.5105 - val_loss: 1245.3474\n",
      "Epoch 771/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 954.9679 - val_loss: 1256.0917\n",
      "Epoch 772/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 977.7618 - val_loss: 1243.1454\n",
      "Epoch 773/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 952.1309 - val_loss: 1258.8345\n",
      "Epoch 774/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 952.2593 - val_loss: 1246.7472\n",
      "Epoch 775/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 960.4108 - val_loss: 1257.7153\n",
      "Epoch 776/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 973.2567 - val_loss: 1258.9061\n",
      "Epoch 777/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 965.9895 - val_loss: 1233.6506\n",
      "Epoch 778/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 972.1658 - val_loss: 1261.4957\n",
      "Epoch 779/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 961.5381 - val_loss: 1229.9572\n",
      "Epoch 780/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 967.6768 - val_loss: 1239.4597\n",
      "Epoch 781/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 975.9708 - val_loss: 1238.6877\n",
      "Epoch 782/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 971.2599 - val_loss: 1232.0763\n",
      "Epoch 783/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 958.0275 - val_loss: 1250.1660\n",
      "Epoch 784/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 955.3175 - val_loss: 1256.4845\n",
      "Epoch 785/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 958.6351 - val_loss: 1272.0067\n",
      "Epoch 786/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 949.8753 - val_loss: 1232.5656\n",
      "Epoch 787/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 965.1777 - val_loss: 1236.6494\n",
      "Epoch 788/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 960.2939 - val_loss: 1244.8378\n",
      "Epoch 789/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 965.7801 - val_loss: 1255.4017\n",
      "Epoch 790/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 948.9909 - val_loss: 1232.6335\n",
      "Epoch 791/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 957.3420 - val_loss: 1242.5172\n",
      "Epoch 792/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 958.7217 - val_loss: 1274.7737\n",
      "Epoch 793/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 957.8193 - val_loss: 1259.0684\n",
      "Epoch 794/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 951.3727 - val_loss: 1251.1960\n",
      "Epoch 795/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 946.6616 - val_loss: 1255.2200\n",
      "Epoch 796/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 958.6463 - val_loss: 1254.5262\n",
      "Epoch 797/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 956.7567 - val_loss: 1273.5336\n",
      "Epoch 798/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 953.8188 - val_loss: 1242.4199\n",
      "Epoch 799/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 967.1414 - val_loss: 1264.6700\n",
      "Epoch 800/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 951.8215 - val_loss: 1235.0876\n",
      "Epoch 801/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 970.9739 - val_loss: 1229.7368\n",
      "Epoch 802/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 947.4833 - val_loss: 1234.4836\n",
      "Epoch 803/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 954.3083 - val_loss: 1267.6978\n",
      "Epoch 804/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 950.0425 - val_loss: 1233.4386\n",
      "Epoch 805/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 949.9534 - val_loss: 1254.0017\n",
      "Epoch 806/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 946.1086 - val_loss: 1261.0216\n",
      "Epoch 807/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 951.0167 - val_loss: 1272.6104\n",
      "Epoch 808/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 960.9321 - val_loss: 1242.6904\n",
      "Epoch 809/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 970.4171 - val_loss: 1275.0997\n",
      "Epoch 810/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 954.0338 - val_loss: 1225.0990\n",
      "Epoch 811/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 947.9875 - val_loss: 1260.7036\n",
      "Epoch 812/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 954.4824 - val_loss: 1270.2423\n",
      "Epoch 813/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 950.2825 - val_loss: 1245.2789\n",
      "Epoch 814/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 950.4114 - val_loss: 1231.1624\n",
      "Epoch 815/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 951.1443 - val_loss: 1251.8231\n",
      "Epoch 816/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 953.8859 - val_loss: 1263.6550\n",
      "Epoch 817/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 956.5078 - val_loss: 1231.7712\n",
      "Epoch 818/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 943.7874 - val_loss: 1251.8815\n",
      "Epoch 819/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 952.5392 - val_loss: 1255.6390\n",
      "Epoch 820/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 962.0168 - val_loss: 1243.0647\n",
      "Epoch 821/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 956.5161 - val_loss: 1252.3478\n",
      "Epoch 822/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 944.6587 - val_loss: 1259.6361\n",
      "Epoch 823/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 949.0306 - val_loss: 1261.2853\n",
      "Epoch 824/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 954.6004 - val_loss: 1231.4755\n",
      "Epoch 825/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 951.2791 - val_loss: 1221.9155\n",
      "Epoch 826/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 953.5654 - val_loss: 1245.0732\n",
      "Epoch 827/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 960.4899 - val_loss: 1233.9110\n",
      "Epoch 828/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 942.2816 - val_loss: 1244.8591\n",
      "Epoch 829/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 942.1718 - val_loss: 1242.7814\n",
      "Epoch 830/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 948.6095 - val_loss: 1260.4181\n",
      "Epoch 831/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 949.3837 - val_loss: 1261.1603\n",
      "Epoch 832/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 951.5922 - val_loss: 1250.8694\n",
      "Epoch 833/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 935.7773 - val_loss: 1231.2682\n",
      "Epoch 834/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 951.3680 - val_loss: 1259.6659\n",
      "Epoch 835/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 965.2177 - val_loss: 1241.9542\n",
      "Epoch 836/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 952.9921 - val_loss: 1238.2708\n",
      "Epoch 837/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 942.7236 - val_loss: 1261.9449\n",
      "Epoch 838/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 938.1173 - val_loss: 1231.0454\n",
      "Epoch 839/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 958.4144 - val_loss: 1234.0342\n",
      "Epoch 840/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 937.8395 - val_loss: 1248.6978\n",
      "Epoch 841/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 950.6562 - val_loss: 1225.5461\n",
      "Epoch 842/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 956.1344 - val_loss: 1224.7036\n",
      "Epoch 843/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 952.4727 - val_loss: 1242.7865\n",
      "Epoch 844/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 947.8600 - val_loss: 1273.4633\n",
      "Epoch 845/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 952.3752 - val_loss: 1260.8715\n",
      "Epoch 846/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 944.1448 - val_loss: 1256.0844\n",
      "Epoch 847/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 948.7774 - val_loss: 1238.1908\n",
      "Epoch 848/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 943.4032 - val_loss: 1256.0750\n",
      "Epoch 849/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 943.8824 - val_loss: 1267.5695\n",
      "Epoch 850/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 951.7484 - val_loss: 1258.6185\n",
      "Epoch 851/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 937.2703 - val_loss: 1245.5302\n",
      "Epoch 852/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 945.9818 - val_loss: 1238.5570\n",
      "Epoch 853/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 948.4045 - val_loss: 1246.0552\n",
      "Epoch 854/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 951.2867 - val_loss: 1225.9633\n",
      "Epoch 855/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 943.9470 - val_loss: 1253.2034\n",
      "Epoch 856/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 944.4005 - val_loss: 1293.1089\n",
      "Epoch 857/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 940.7894 - val_loss: 1242.2952\n",
      "Epoch 858/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 939.1299 - val_loss: 1240.7400\n",
      "Epoch 859/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 948.1575 - val_loss: 1233.8777\n",
      "Epoch 860/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 940.5784 - val_loss: 1244.3339\n",
      "Epoch 861/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 930.7743 - val_loss: 1256.1444\n",
      "Epoch 862/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 933.9543 - val_loss: 1268.1705\n",
      "Epoch 863/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 940.8406 - val_loss: 1261.9314\n",
      "Epoch 864/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 945.8257 - val_loss: 1253.5099\n",
      "Epoch 865/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 941.3789 - val_loss: 1226.6873\n",
      "Epoch 866/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 939.9501 - val_loss: 1266.4431\n",
      "Epoch 867/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 941.5619 - val_loss: 1269.9203\n",
      "Epoch 868/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 953.9520 - val_loss: 1237.5314\n",
      "Epoch 869/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 952.3865 - val_loss: 1240.2601\n",
      "Epoch 870/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 944.0460 - val_loss: 1267.6166\n",
      "Epoch 871/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 946.4993 - val_loss: 1255.8950\n",
      "Epoch 872/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 934.2155 - val_loss: 1251.5574\n",
      "Epoch 873/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 932.8287 - val_loss: 1249.2758\n",
      "Epoch 874/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 949.6555 - val_loss: 1233.7108\n",
      "Epoch 875/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 947.6469 - val_loss: 1230.2162\n",
      "Epoch 876/1000\n",
      "268/268 [==============================] - 1s 5ms/step - loss: 951.0121 - val_loss: 1241.6891\n",
      "Epoch 877/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 934.7622 - val_loss: 1274.5455\n",
      "Epoch 878/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 942.0131 - val_loss: 1260.4027\n",
      "Epoch 879/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 925.3324 - val_loss: 1253.2423\n",
      "Epoch 880/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 935.4504 - val_loss: 1252.4459\n",
      "Epoch 881/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 938.2243 - val_loss: 1221.0010\n",
      "Epoch 882/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 940.8361 - val_loss: 1227.3470\n",
      "Epoch 883/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 940.7170 - val_loss: 1264.1431\n",
      "Epoch 884/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 942.2289 - val_loss: 1234.2454\n",
      "Epoch 885/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 940.5234 - val_loss: 1216.7407\n",
      "Epoch 886/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 944.4175 - val_loss: 1235.8647\n",
      "Epoch 887/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 942.2869 - val_loss: 1235.6199\n",
      "Epoch 888/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 939.7124 - val_loss: 1231.4708\n",
      "Epoch 889/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 938.5034 - val_loss: 1253.0321\n",
      "Epoch 890/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 942.7888 - val_loss: 1239.4578\n",
      "Epoch 891/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 943.5925 - val_loss: 1228.6597\n",
      "Epoch 892/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 933.8129 - val_loss: 1222.6036\n",
      "Epoch 893/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 929.8084 - val_loss: 1219.4287\n",
      "Epoch 894/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 930.9497 - val_loss: 1222.8424\n",
      "Epoch 895/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 3ms/step - loss: 937.6523 - val_loss: 1248.9738\n",
      "Epoch 896/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 933.7269 - val_loss: 1218.3622\n",
      "Epoch 897/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 937.0410 - val_loss: 1224.4343\n",
      "Epoch 898/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 933.4159 - val_loss: 1234.4015\n",
      "Epoch 899/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 936.9584 - val_loss: 1252.1097\n",
      "Epoch 900/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 946.5866 - val_loss: 1216.1598\n",
      "Epoch 901/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 937.7449 - val_loss: 1257.5305\n",
      "Epoch 902/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 936.1230 - val_loss: 1247.1984\n",
      "Epoch 903/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 933.8101 - val_loss: 1238.9117\n",
      "Epoch 904/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 939.2520 - val_loss: 1216.2721\n",
      "Epoch 905/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 938.0547 - val_loss: 1253.9056\n",
      "Epoch 906/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 933.4858 - val_loss: 1227.4266\n",
      "Epoch 907/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 931.6599 - val_loss: 1232.1859\n",
      "Epoch 908/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 931.4662 - val_loss: 1256.9675\n",
      "Epoch 909/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 934.9395 - val_loss: 1241.9366\n",
      "Epoch 910/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 928.8477 - val_loss: 1265.8199\n",
      "Epoch 911/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 942.7758 - val_loss: 1231.1698\n",
      "Epoch 912/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 933.7501 - val_loss: 1240.2069\n",
      "Epoch 913/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 938.9986 - val_loss: 1276.9689\n",
      "Epoch 914/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 938.6588 - val_loss: 1263.6064\n",
      "Epoch 915/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 935.5329 - val_loss: 1217.5251\n",
      "Epoch 916/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 940.0300 - val_loss: 1259.6272\n",
      "Epoch 917/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 932.5770 - val_loss: 1258.5385\n",
      "Epoch 918/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 936.0312 - val_loss: 1250.5101\n",
      "Epoch 919/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 929.1643 - val_loss: 1274.1143\n",
      "Epoch 920/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 933.0684 - val_loss: 1235.5795\n",
      "Epoch 921/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 944.3662 - val_loss: 1259.3867\n",
      "Epoch 922/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 931.3364 - val_loss: 1251.7108\n",
      "Epoch 923/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 920.5078 - val_loss: 1250.9781\n",
      "Epoch 924/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 932.5357 - val_loss: 1286.3485\n",
      "Epoch 925/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 922.2040 - val_loss: 1246.8525\n",
      "Epoch 926/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 922.5767 - val_loss: 1257.9445\n",
      "Epoch 927/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 925.9893 - val_loss: 1268.9066\n",
      "Epoch 928/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 929.2505 - val_loss: 1268.3536\n",
      "Epoch 929/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 935.0408 - val_loss: 1267.6914\n",
      "Epoch 930/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 924.9656 - val_loss: 1265.5074\n",
      "Epoch 931/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 936.6300 - val_loss: 1251.3892\n",
      "Epoch 932/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 930.6524 - val_loss: 1249.6628\n",
      "Epoch 933/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 916.9250 - val_loss: 1236.5955\n",
      "Epoch 934/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 925.1367 - val_loss: 1259.1812\n",
      "Epoch 935/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 924.7194 - val_loss: 1248.4672\n",
      "Epoch 936/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 925.8268 - val_loss: 1238.9103\n",
      "Epoch 937/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 927.9446 - val_loss: 1244.7029\n",
      "Epoch 938/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 932.5931 - val_loss: 1235.1273\n",
      "Epoch 939/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 924.6920 - val_loss: 1261.8297\n",
      "Epoch 940/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 937.9830 - val_loss: 1225.5261\n",
      "Epoch 941/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 936.6204 - val_loss: 1235.6688\n",
      "Epoch 942/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 924.8180 - val_loss: 1274.1752\n",
      "Epoch 943/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 939.4929 - val_loss: 1258.2303\n",
      "Epoch 944/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 920.9637 - val_loss: 1239.3348\n",
      "Epoch 945/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 938.3480 - val_loss: 1247.0662\n",
      "Epoch 946/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 936.2896 - val_loss: 1251.2626\n",
      "Epoch 947/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 925.8491 - val_loss: 1284.0886\n",
      "Epoch 948/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 938.0546 - val_loss: 1250.2529\n",
      "Epoch 949/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 928.2457 - val_loss: 1236.6178\n",
      "Epoch 950/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 937.6940 - val_loss: 1254.2189\n",
      "Epoch 951/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 937.9901 - val_loss: 1242.3763\n",
      "Epoch 952/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 920.8193 - val_loss: 1242.1624\n",
      "Epoch 953/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 925.7726 - val_loss: 1238.7903\n",
      "Epoch 954/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 942.7283 - val_loss: 1253.6014\n",
      "Epoch 955/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 919.5532 - val_loss: 1256.3899\n",
      "Epoch 956/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 923.9908 - val_loss: 1260.4967\n",
      "Epoch 957/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 915.8394 - val_loss: 1263.9016\n",
      "Epoch 958/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 918.7104 - val_loss: 1267.8053\n",
      "Epoch 959/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 930.2014 - val_loss: 1275.6729\n",
      "Epoch 960/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 923.4891 - val_loss: 1267.2568\n",
      "Epoch 961/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 926.6095 - val_loss: 1244.1415\n",
      "Epoch 962/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 924.1351 - val_loss: 1221.2610\n",
      "Epoch 963/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 933.3457 - val_loss: 1245.0933\n",
      "Epoch 964/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 924.2792 - val_loss: 1233.8354\n",
      "Epoch 965/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 918.9464 - val_loss: 1242.5002\n",
      "Epoch 966/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 926.4727 - val_loss: 1248.7244\n",
      "Epoch 967/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 921.0887 - val_loss: 1242.0718\n",
      "Epoch 968/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 925.6741 - val_loss: 1242.0408\n",
      "Epoch 969/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 929.5602 - val_loss: 1242.6093\n",
      "Epoch 970/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 914.0978 - val_loss: 1245.9530\n",
      "Epoch 971/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 916.1640 - val_loss: 1270.3555\n",
      "Epoch 972/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 923.9801 - val_loss: 1251.4376\n",
      "Epoch 973/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 921.7784 - val_loss: 1241.7960\n",
      "Epoch 974/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 920.3542 - val_loss: 1270.0363\n",
      "Epoch 975/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 929.4761 - val_loss: 1239.1069\n",
      "Epoch 976/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 917.8121 - val_loss: 1268.0283\n",
      "Epoch 977/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 919.2944 - val_loss: 1245.9485\n",
      "Epoch 978/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 923.3209 - val_loss: 1260.4424\n",
      "Epoch 979/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 920.3258 - val_loss: 1252.1527\n",
      "Epoch 980/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 926.7889 - val_loss: 1222.4927\n",
      "Epoch 981/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 917.7593 - val_loss: 1252.1410\n",
      "Epoch 982/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 928.2515 - val_loss: 1229.7007\n",
      "Epoch 983/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 916.2386 - val_loss: 1271.7863\n",
      "Epoch 984/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 922.5034 - val_loss: 1232.6833\n",
      "Epoch 985/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 923.2285 - val_loss: 1261.4203\n",
      "Epoch 986/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 934.5979 - val_loss: 1225.7649\n",
      "Epoch 987/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 907.6541 - val_loss: 1227.6790\n",
      "Epoch 988/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 926.9614 - val_loss: 1248.5596\n",
      "Epoch 989/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 934.7767 - val_loss: 1257.0708\n",
      "Epoch 990/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 912.4442 - val_loss: 1267.7977\n",
      "Epoch 991/1000\n",
      "268/268 [==============================] - 1s 4ms/step - loss: 918.1111 - val_loss: 1258.5712\n",
      "Epoch 992/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 921.1324 - val_loss: 1248.2297\n",
      "Epoch 993/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 918.5074 - val_loss: 1250.8911\n",
      "Epoch 994/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 920.9583 - val_loss: 1281.9731\n",
      "Epoch 995/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 916.3394 - val_loss: 1257.9915\n",
      "Epoch 996/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 913.0627 - val_loss: 1245.1682\n",
      "Epoch 997/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 927.7286 - val_loss: 1250.5886\n",
      "Epoch 998/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 914.2684 - val_loss: 1251.5005\n",
      "Epoch 999/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 911.1566 - val_loss: 1290.2731\n",
      "Epoch 1000/1000\n",
      "268/268 [==============================] - 1s 3ms/step - loss: 924.0291 - val_loss: 1261.7458\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model6.h5\", save_best_only=True)\n",
    "\n",
    "model6 = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=X_train.shape[1:]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"elu\"),\n",
    "    keras.layers.Dense(200, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"elu\"),\n",
    "    keras.layers.Dense(150, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"elu\"),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"elu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model6.compile(loss=\"mae\",\n",
    "              optimizer=\"adam\")\n",
    "\n",
    "history6 = model6.fit(X_train, y_train,\n",
    "                     epochs=1000,\n",
    "                     validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3064066684946478\n",
      "0.3752202342939266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_test_predict = model6.predict(X_test)\n",
    "y_train_predict = model6.predict(X_train)\n",
    "print(r2_score(y_train, y_train_predict))\n",
    "print(r2_score(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5486.2905]\n",
      " [ 8460.427 ]\n",
      " [ 3629.445 ]\n",
      " [14784.249 ]\n",
      " [10230.497 ]\n",
      " [13213.16  ]\n",
      " [ 6226.1445]\n",
      " [13913.3955]\n",
      " [13036.2   ]]\n",
      "3544     4959\n",
      "9291     9187\n",
      "5032     3858\n",
      "2483    12898\n",
      "9894    10529\n",
      "346     16079\n",
      "6365     7229\n",
      "7624    10844\n",
      "3393    16289\n",
      "Name: Price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(model5.predict(x_test_scaled[1:10]))\n",
    "print(y_test[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_curves(history6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
